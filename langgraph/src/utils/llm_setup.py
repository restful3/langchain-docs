"""
LLM ì´ˆê¸°í™” ìœ í‹¸ë¦¬í‹°

ì´ ëª¨ë“ˆì€ ë‹¤ì–‘í•œ LLM í”„ë¡œë°”ì´ë”ë¥¼ ì´ˆê¸°í™”í•˜ëŠ” ê³µí†µ í•¨ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
from typing import Optional


def get_llm(
    provider: str = "anthropic",
    model: Optional[str] = None,
    temperature: float = 0,
    **kwargs
):
    """
    LLM ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

    Args:
        provider: LLM í”„ë¡œë°”ì´ë” ("anthropic", "openai", "google" ë“±)
        model: ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ (Noneì´ë©´ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©)
        temperature: ìƒì„± ì˜¨ë„ (0~1)
        **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„°

    Returns:
        ì´ˆê¸°í™”ëœ LLM ì¸ìŠ¤í„´ìŠ¤

    Raises:
        ValueError: ì§€ì›í•˜ì§€ ì•ŠëŠ” í”„ë¡œë°”ì´ë”ì¸ ê²½ìš°
        Exception: API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš°

    Example:
        >>> llm = get_llm("anthropic")
        >>> llm = get_llm("openai", model="gpt-4", temperature=0.7)
    """
    if provider == "anthropic":
        from langchain_anthropic import ChatAnthropic

        # API í‚¤ í™•ì¸
        if not os.getenv("ANTHROPIC_API_KEY"):
            raise Exception(
                "ANTHROPIC_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                ".env íŒŒì¼ì— API í‚¤ë¥¼ ì¶”ê°€í•˜ì„¸ìš”."
            )

        # ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
        if model is None:
            model = "claude-sonnet-4-5-20250929"

        return ChatAnthropic(
            model=model,
            temperature=temperature,
            **kwargs
        )

    elif provider == "openai":
        from langchain_openai import ChatOpenAI

        # API í‚¤ í™•ì¸
        if not os.getenv("OPENAI_API_KEY"):
            raise Exception(
                "OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                ".env íŒŒì¼ì— API í‚¤ë¥¼ ì¶”ê°€í•˜ì„¸ìš”."
            )

        # ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
        if model is None:
            model = "gpt-4"

        return ChatOpenAI(
            model=model,
            temperature=temperature,
            **kwargs
        )

    elif provider == "google":
        from langchain_google_genai import ChatGoogleGenerativeAI

        # API í‚¤ í™•ì¸
        if not os.getenv("GOOGLE_API_KEY"):
            raise Exception(
                "GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                ".env íŒŒì¼ì— API í‚¤ë¥¼ ì¶”ê°€í•˜ì„¸ìš”."
            )

        # ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
        if model is None:
            model = "gemini-pro"

        return ChatGoogleGenerativeAI(
            model=model,
            temperature=temperature,
            **kwargs
        )

    else:
        raise ValueError(
            f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í”„ë¡œë°”ì´ë”ì…ë‹ˆë‹¤: {provider}\n"
            f"ì§€ì›ë˜ëŠ” í”„ë¡œë°”ì´ë”: anthropic, openai, google"
        )


def get_default_llm(**kwargs):
    """
    ê¸°ë³¸ LLM(Anthropic Claude)ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        **kwargs: get_llm()ì— ì „ë‹¬í•  ì¶”ê°€ íŒŒë¼ë¯¸í„°

    Returns:
        ì´ˆê¸°í™”ëœ Claude LLM ì¸ìŠ¤í„´ìŠ¤

    Example:
        >>> llm = get_default_llm()
        >>> llm = get_default_llm(temperature=0.7)
    """
    return get_llm(provider="anthropic", **kwargs)


if __name__ == "__main__":
    """í…ŒìŠ¤íŠ¸ ì½”ë“œ"""
    from dotenv import load_dotenv

    load_dotenv()

    print("=" * 60)
    print("LLM Setup í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    try:
        llm = get_default_llm()
        print(f"âœ… LLM ì´ˆê¸°í™” ì„±ê³µ: {llm.__class__.__name__}")
        print(f"   ëª¨ë¸: {llm.model}")
        print(f"   ì˜¨ë„: {llm.temperature}")

        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
        response = llm.invoke("ì•ˆë…•í•˜ì„¸ìš”!")
        print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ ì‘ë‹µ: {response.content}")

    except Exception as e:
        print(f"âŒ LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
