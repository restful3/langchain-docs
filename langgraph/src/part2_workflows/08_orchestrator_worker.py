"""
[Chapter 8] Orchestrator-Worker íŒ¨í„´

ğŸ“ ì„¤ëª…:
    Orchestrator-Worker íŒ¨í„´ì€ ì¤‘ì•™ì˜ ì¡°ìœ¨ì(Orchestrator)ê°€ ì‘ì—…ì„ ë¶„í•´í•˜ê³ 
    ì—¬ëŸ¬ ì›Œì»¤(Worker)ì—ê²Œ ë¶„ë°°í•œ í›„ ê²°ê³¼ë¥¼ ìˆ˜ì§‘í•˜ëŠ” íŒ¨í„´ì…ë‹ˆë‹¤.
    ë³µì¡í•œ ì‘ì—…ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ¯ í•™ìŠµ ëª©í‘œ:
    - Orchestrator-Worker ì•„í‚¤í…ì²˜ ì´í•´
    - ë™ì  ì‘ì—… ë¶„ë°° êµ¬í˜„
    - LLMì„ ì‚¬ìš©í•œ ì‘ì—… ë¶„í•´
    - ê²°ê³¼ ì§‘ê³„ ë° í•©ì„±

ğŸ“š ê´€ë ¨ ë¬¸ì„œ:
    - docs/Part2-Workflows/08-orchestrator-worker.md
    - ê³µì‹ ë¬¸ì„œ: https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#orchestrator-worker

ğŸ’» ì‹¤í–‰ ë°©ë²•:
    python -m src.part2_workflows.08_orchestrator_worker

ğŸ“¦ í•„ìš”í•œ íŒ¨í‚¤ì§€:
    - langgraph>=0.2.0
    - langchain-anthropic>=0.3.0
"""

import os
from typing import TypedDict, Annotated, List, Optional
from dotenv import load_dotenv
import operator

from langgraph.graph import StateGraph, START, END
from langgraph.types import Send


# =============================================================================
# 1. ê¸°ë³¸ Orchestrator-Worker íŒ¨í„´
# =============================================================================

class OrchestratorState(TypedDict):
    """Orchestrator-Worker State"""
    task: str
    subtasks: List[str]
    current_subtask: str  # Workerìš©
    results: Annotated[List[str], operator.add]
    final_result: str


def orchestrate(state: OrchestratorState) -> OrchestratorState:
    """
    Orchestrator: ì‘ì—…ì„ í•˜ìœ„ ì‘ì—…ìœ¼ë¡œ ë¶„í•´

    ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œëŠ” LLMì„ ì‚¬ìš©í•˜ì—¬ ì‘ì—…ì„ ë¶„í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    task = state["task"]

    # ê°„ë‹¨í•œ ì‘ì—… ë¶„í•´ ë¡œì§
    # ì‹¤ì œë¡œëŠ” LLMì´ ì´ ì—­í• ì„ ìˆ˜í–‰
    subtasks = [
        f"ë¶„ì„: {task}",
        f"ê²€ì¦: {task}",
        f"ìµœì í™”: {task}"
    ]

    return {"subtasks": subtasks}


def distribute_to_workers(state: OrchestratorState) -> List[Send]:
    """ì‘ì—…ì„ ì›Œì»¤ë“¤ì—ê²Œ ë¶„ë°°"""
    return [
        Send("worker", {"current_subtask": subtask})
        for subtask in state["subtasks"]
    ]


def worker(state: OrchestratorState) -> OrchestratorState:
    """Worker: í• ë‹¹ëœ í•˜ìœ„ ì‘ì—… ìˆ˜í–‰"""
    subtask = state["current_subtask"]

    # ê°„ë‹¨í•œ ì‘ì—… ì²˜ë¦¬
    result = f"âœ… ì™„ë£Œ: {subtask}"

    return {"results": [result]}


def synthesize(state: OrchestratorState) -> OrchestratorState:
    """ê²°ê³¼ í•©ì„±"""
    results = state["results"]
    final = f"[ìµœì¢… ê²°ê³¼] {len(results)}ê°œ ì‘ì—… ì™„ë£Œ:\n"
    for r in results:
        final += f"  - {r}\n"
    return {"final_result": final}


def create_basic_orchestrator_graph():
    """ê¸°ë³¸ Orchestrator-Worker ê·¸ë˜í”„ ìƒì„±"""
    graph = StateGraph(OrchestratorState)

    graph.add_node("orchestrate", orchestrate)
    graph.add_node("distribute", distribute_to_workers)
    graph.add_node("worker", worker)
    graph.add_node("synthesize", synthesize)

    graph.add_edge(START, "orchestrate")
    graph.add_edge("orchestrate", "distribute")
    # distributeê°€ Sendë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ workerë¡œ ìë™ ë¶„ê¸°
    graph.add_edge("worker", "synthesize")
    graph.add_edge("synthesize", END)

    return graph.compile()


def run_basic_orchestrator_example():
    """ê¸°ë³¸ Orchestrator ì˜ˆì œ ì‹¤í–‰"""
    print("\n" + "=" * 60)
    print("ì˜ˆì œ 1: ê¸°ë³¸ Orchestrator-Worker")
    print("=" * 60)

    app = create_basic_orchestrator_graph()

    result = app.invoke({
        "task": "ì‹œìŠ¤í…œ ìƒíƒœ ì ê²€",
        "subtasks": [],
        "current_subtask": "",
        "results": [],
        "final_result": ""
    })

    print(f"\nğŸ¯ ì›ë³¸ ì‘ì—…: {result['task']}")
    print(f"\nğŸ“‹ ë¶„í•´ëœ í•˜ìœ„ ì‘ì—…:")
    for subtask in result["subtasks"]:
        print(f"   - {subtask}")
    print(f"\n{result['final_result']}")


# =============================================================================
# 2. LLM ê¸°ë°˜ ì‘ì—… ë¶„í•´
# =============================================================================

class LLMOrchestratorState(TypedDict):
    """LLM Orchestrator State"""
    user_request: str
    plan: List[str]
    current_step: str
    step_results: Annotated[List[str], operator.add]
    final_response: str


def create_llm_orchestrator_graph():
    """LLM ê¸°ë°˜ Orchestrator ê·¸ë˜í”„ ìƒì„±"""

    if not os.getenv("ANTHROPIC_API_KEY"):
        return None

    try:
        from langchain_anthropic import ChatAnthropic
        from langchain_core.messages import HumanMessage, SystemMessage
    except ImportError:
        return None

    llm = ChatAnthropic(model="claude-sonnet-4-5-20250929", temperature=0)

    def plan_tasks(state: LLMOrchestratorState) -> LLMOrchestratorState:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ì‘ì—… ê³„íš ìˆ˜ë¦½"""
        messages = [
            SystemMessage(content="""ì‚¬ìš©ì ìš”ì²­ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ë‹¨ê³„ë³„ ê³„íšì„ ì„¸ìš°ì„¸ìš”.
ê° ë‹¨ê³„ë¥¼ í•œ ì¤„ì”© ë‚˜ì—´í•˜ì„¸ìš”. 3-5ë‹¨ê³„ê°€ ì ì ˆí•©ë‹ˆë‹¤.
ë‹¨ê³„ ë²ˆí˜¸ ì—†ì´ ì‘ì—… ë‚´ìš©ë§Œ ì‘ì„±í•˜ì„¸ìš”."""),
            HumanMessage(content=f"ìš”ì²­: {state['user_request']}")
        ]
        response = llm.invoke(messages)

        # ì¤„ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•˜ì—¬ ê³„íš ì¶”ì¶œ
        plan = [
            step.strip()
            for step in response.content.strip().split("\n")
            if step.strip()
        ]

        return {"plan": plan}

    def distribute_plan(state: LLMOrchestratorState) -> List[Send]:
        """ê³„íšì„ ì›Œì»¤ë“¤ì—ê²Œ ë¶„ë°°"""
        return [
            Send("execute_step", {"current_step": step})
            for step in state["plan"]
        ]

    def execute_step(state: LLMOrchestratorState) -> LLMOrchestratorState:
        """ê° ë‹¨ê³„ ì‹¤í–‰"""
        step = state["current_step"]

        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ì‘ì—… ì‹¤í–‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ê°„ë‹¨íˆ ë³´ê³ í•˜ì„¸ìš”."),
            HumanMessage(content=f"ì‘ì—…: {step}\n\nê²°ê³¼ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ë³´ê³ í•˜ì„¸ìš”.")
        ]
        response = llm.invoke(messages)

        return {"step_results": [f"[{step}]\n{response.content}"]}

    def synthesize_response(state: LLMOrchestratorState) -> LLMOrchestratorState:
        """ìµœì¢… ì‘ë‹µ í•©ì„±"""
        results_text = "\n\n".join(state["step_results"])

        messages = [
            SystemMessage(content="ê° ë‹¨ê³„ì˜ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ìµœì¢… ì‘ë‹µì„ ì‘ì„±í•˜ì„¸ìš”."),
            HumanMessage(content=f"""ì›ë³¸ ìš”ì²­: {state['user_request']}

ê° ë‹¨ê³„ ê²°ê³¼:
{results_text}

ì¢…í•© ì‘ë‹µì„ ì‘ì„±í•˜ì„¸ìš”.""")
        ]
        response = llm.invoke(messages)

        return {"final_response": response.content}

    graph = StateGraph(LLMOrchestratorState)

    graph.add_node("planner", plan_tasks)
    graph.add_node("distributor", distribute_plan)
    graph.add_node("execute_step", execute_step)
    graph.add_node("synthesizer", synthesize_response)

    graph.add_edge(START, "planner")
    graph.add_edge("planner", "distributor")
    graph.add_edge("execute_step", "synthesizer")
    graph.add_edge("synthesizer", END)

    return graph.compile()


def run_llm_orchestrator_example():
    """LLM Orchestrator ì˜ˆì œ ì‹¤í–‰"""
    print("\n" + "=" * 60)
    print("ì˜ˆì œ 2: LLM ê¸°ë°˜ Orchestrator")
    print("=" * 60)

    load_dotenv()
    app = create_llm_orchestrator_graph()

    if app is None:
        print("\nâš ï¸  LLMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    result = app.invoke({
        "user_request": "Pythonìœ¼ë¡œ ê°„ë‹¨í•œ ì›¹ í¬ë¡¤ëŸ¬ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
        "plan": [],
        "current_step": "",
        "step_results": [],
        "final_response": ""
    })

    print(f"\nğŸ¯ ì‚¬ìš©ì ìš”ì²­: {result['user_request']}")
    print(f"\nğŸ“‹ ì‹¤í–‰ ê³„íš:")
    for i, step in enumerate(result["plan"], 1):
        print(f"   {i}. {step}")
    print(f"\nğŸ“ ìµœì¢… ì‘ë‹µ:\n{result['final_response'][:500]}...")


# =============================================================================
# 3. ì „ë¬¸ê°€ íŒ€ íŒ¨í„´
# =============================================================================

class ExpertTeamState(TypedDict):
    """ì „ë¬¸ê°€ íŒ€ State"""
    question: str
    expert_type: str  # ê°œë³„ ì „ë¬¸ê°€ìš©
    expert_opinions: Annotated[List[str], operator.add]
    consensus: str


def assign_experts(state: ExpertTeamState) -> List[Send]:
    """ì§ˆë¬¸ì„ ì—¬ëŸ¬ ì „ë¬¸ê°€ì—ê²Œ í• ë‹¹"""
    experts = ["ê¸°ìˆ  ì „ë¬¸ê°€", "ë¹„ì¦ˆë‹ˆìŠ¤ ì „ë¬¸ê°€", "ë³´ì•ˆ ì „ë¬¸ê°€"]

    return [
        Send("consult_expert", {"expert_type": expert, "question": state["question"]})
        for expert in experts
    ]


def consult_expert(state: ExpertTeamState) -> ExpertTeamState:
    """ì „ë¬¸ê°€ ì˜ê²¬ ìˆ˜ë ´"""
    expert = state["expert_type"]
    question = state["question"]

    # ì „ë¬¸ê°€ë³„ ê´€ì  ì‹œë®¬ë ˆì´ì…˜
    perspectives = {
        "ê¸°ìˆ  ì „ë¬¸ê°€": "ê¸°ìˆ ì  ê´€ì ì—ì„œ êµ¬í˜„ ê°€ëŠ¥ì„±ê³¼ ì•„í‚¤í…ì²˜ë¥¼ ê³ ë ¤í•©ë‹ˆë‹¤.",
        "ë¹„ì¦ˆë‹ˆìŠ¤ ì „ë¬¸ê°€": "ë¹„ìš© íš¨ìœ¨ì„±ê³¼ ì‹œì¥ ê°€ì¹˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.",
        "ë³´ì•ˆ ì „ë¬¸ê°€": "ë³´ì•ˆ ìœ„í—˜ê³¼ ë°ì´í„° ë³´í˜¸ ì¸¡ë©´ì„ ê²€í† í•©ë‹ˆë‹¤."
    }

    opinion = f"[{expert}]\n{perspectives.get(expert, 'ì˜ê²¬ ì—†ìŒ')}\nì§ˆë¬¸ '{question}'ì— ëŒ€í•´: ê¸ì •ì  ê²€í†  ê²°ê³¼."

    return {"expert_opinions": [opinion]}


def reach_consensus(state: ExpertTeamState) -> ExpertTeamState:
    """ì „ë¬¸ê°€ ì˜ê²¬ ì¢…í•©"""
    opinions = state["expert_opinions"]
    consensus = f"ì´ {len(opinions)}ëª…ì˜ ì „ë¬¸ê°€ ì˜ê²¬ ì¢…í•©:\n"
    consensus += "ëª¨ë“  ì „ë¬¸ê°€ê°€ í•´ë‹¹ ì œì•ˆì— ëŒ€í•´ ê¸ì •ì ì¸ ê²€í†  ê²°ê³¼ë¥¼ ì œì‹œí–ˆìŠµë‹ˆë‹¤."

    return {"consensus": consensus}


def create_expert_team_graph():
    """ì „ë¬¸ê°€ íŒ€ ê·¸ë˜í”„ ìƒì„±"""
    graph = StateGraph(ExpertTeamState)

    graph.add_node("assign", assign_experts)
    graph.add_node("consult_expert", consult_expert)
    graph.add_node("consensus", reach_consensus)

    graph.add_edge(START, "assign")
    graph.add_edge("consult_expert", "consensus")
    graph.add_edge("consensus", END)

    return graph.compile()


def run_expert_team_example():
    """ì „ë¬¸ê°€ íŒ€ ì˜ˆì œ ì‹¤í–‰"""
    print("\n" + "=" * 60)
    print("ì˜ˆì œ 3: ì „ë¬¸ê°€ íŒ€ íŒ¨í„´")
    print("=" * 60)

    app = create_expert_team_graph()

    result = app.invoke({
        "question": "AI ì±—ë´‡ì„ ë„ì…í•´ì•¼ í• ê¹Œìš”?",
        "expert_type": "",
        "expert_opinions": [],
        "consensus": ""
    })

    print(f"\nâ“ ì§ˆë¬¸: {result['question']}")
    print(f"\nğŸ‘¥ ì „ë¬¸ê°€ ì˜ê²¬:")
    for opinion in result["expert_opinions"]:
        print(f"\n{opinion}")
    print(f"\nâœ… {result['consensus']}")


# =============================================================================
# 4. ì¬ê·€ì  Orchestrator (ë³µì¡í•œ ì‘ì—…)
# =============================================================================

class RecursiveState(TypedDict):
    """ì¬ê·€ì  ì²˜ë¦¬ë¥¼ ìœ„í•œ State"""
    task: str
    depth: int
    max_depth: int
    all_results: Annotated[List[str], operator.add]


def check_complexity(state: RecursiveState) -> str:
    """ì‘ì—… ë³µì¡ë„ í™•ì¸ ë° ë¼ìš°íŒ…"""
    if state["depth"] >= state["max_depth"]:
        return "execute"
    elif len(state["task"]) > 20:  # ê°„ë‹¨í•œ ë³µì¡ë„ ê¸°ì¤€
        return "decompose"
    else:
        return "execute"


def decompose_task(state: RecursiveState) -> List[Send]:
    """ì‘ì—…ì„ ë” ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„í•´"""
    task = state["task"]
    depth = state["depth"]

    # ê°„ë‹¨í•œ ë¶„í•´ ë¡œì§
    mid = len(task) // 2
    subtasks = [
        task[:mid].strip(),
        task[mid:].strip()
    ]

    return [
        Send("process", {
            "task": subtask,
            "depth": depth + 1,
            "max_depth": state["max_depth"]
        })
        for subtask in subtasks if subtask
    ]


def execute_task(state: RecursiveState) -> RecursiveState:
    """ì‹¤ì œ ì‘ì—… ì‹¤í–‰"""
    result = f"[Depth {state['depth']}] ì‹¤í–‰: {state['task'][:30]}..."
    return {"all_results": [result]}


def create_recursive_orchestrator_graph():
    """ì¬ê·€ì  Orchestrator ê·¸ë˜í”„ ìƒì„±"""
    graph = StateGraph(RecursiveState)

    graph.add_node("check", lambda s: s)  # ë¼ìš°íŒ…ë§Œ ë‹´ë‹¹
    graph.add_node("decompose", decompose_task)
    graph.add_node("execute", execute_task)
    graph.add_node("process", lambda s: s)  # ì§„ì…ì 

    graph.add_edge(START, "process")

    graph.add_conditional_edges(
        "process",
        check_complexity,
        {
            "decompose": "decompose",
            "execute": "execute"
        }
    )

    # decomposeëŠ” Sendë¡œ processë¥¼ ì¬ê·€ í˜¸ì¶œ
    graph.add_edge("execute", END)

    return graph.compile()


def run_recursive_orchestrator_example():
    """ì¬ê·€ì  Orchestrator ì˜ˆì œ ì‹¤í–‰"""
    print("\n" + "=" * 60)
    print("ì˜ˆì œ 4: ì¬ê·€ì  ì‘ì—… ë¶„í•´")
    print("=" * 60)

    app = create_recursive_orchestrator_graph()

    result = app.invoke({
        "task": "ëŒ€ê·œëª¨ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ ë¶„ì„ ë° ìµœì í™” ë³´ê³ ì„œ ì‘ì„±",
        "depth": 0,
        "max_depth": 2,
        "all_results": []
    })

    print(f"\nğŸ“Š ì‹¤í–‰ ê²°ê³¼:")
    for r in result["all_results"]:
        print(f"   {r}")


# =============================================================================
# 5. Orchestrator-Worker íŒ¨í„´ ì •ë¦¬
# =============================================================================

def explain_orchestrator_pattern():
    """Orchestrator-Worker íŒ¨í„´ ì„¤ëª…"""
    print("\n" + "=" * 60)
    print("ğŸ“˜ Orchestrator-Worker íŒ¨í„´ ì •ë¦¬")
    print("=" * 60)

    print("""
Orchestrator-Worker êµ¬ì¡°:

                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Orchestratorâ”‚
                    â”‚   (ë¶„í•´)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼                â–¼                â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Worker 1 â”‚    â”‚ Worker 2 â”‚    â”‚ Worker N â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚                â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Synthesizer â”‚
                    â”‚    (í•©ì„±)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

í•µì‹¬ êµ¬ì„±ìš”ì†Œ:

1. Orchestrator (ì¡°ìœ¨ì)
   - ë³µì¡í•œ ì‘ì—…ì„ í•˜ìœ„ ì‘ì—…ìœ¼ë¡œ ë¶„í•´
   - ì‘ì—… ê³„íš ìˆ˜ë¦½
   - LLMì„ í™œìš©í•œ ì§€ëŠ¥ì  ë¶„í•´ ê°€ëŠ¥

2. Workers (ì‘ì—…ì)
   - ê°œë³„ í•˜ìœ„ ì‘ì—… ìˆ˜í–‰
   - ë…ë¦½ì ìœ¼ë¡œ ë³‘ë ¬ ì‹¤í–‰
   - Send APIë¡œ ë™ì  ìƒì„±

3. Synthesizer (í•©ì„±ê¸°)
   - ì›Œì»¤ ê²°ê³¼ ìˆ˜ì§‘
   - ìµœì¢… ê²°ê³¼ í•©ì„±
   - ì¼ê´€ëœ ì¶œë ¥ ìƒì„±

ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
- ë³µì¡í•œ ë¶„ì„ ì‘ì—…
- ë¬¸ì„œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
- ë‹¤ì¤‘ ì „ë¬¸ê°€ ìƒë‹´
- ëŒ€ê·œëª¨ ë°ì´í„° ì²˜ë¦¬

LLM í™œìš©:
- Orchestrator: ì‘ì—… ê³„íš ìˆ˜ë¦½
- Worker: ì „ë¬¸í™”ëœ ì²˜ë¦¬
- Synthesizer: ê²°ê³¼ ì¢…í•©
""")


# =============================================================================
# ë©”ì¸ ì‹¤í–‰
# =============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("[Chapter 8] Orchestrator-Worker íŒ¨í„´")
    print("=" * 60)

    load_dotenv()

    # ì˜ˆì œ ì‹¤í–‰
    run_basic_orchestrator_example()
    run_llm_orchestrator_example()
    run_expert_team_example()
    run_recursive_orchestrator_example()

    # íŒ¨í„´ ì •ë¦¬
    explain_orchestrator_pattern()

    print("\n" + "=" * 60)
    print("âœ… ëª¨ë“  ì˜ˆì œ ì‹¤í–‰ ì™„ë£Œ!")
    print("   ë‹¤ìŒ ì˜ˆì œ: 09_evaluator_optimizer.py")
    print("=" * 60)


if __name__ == "__main__":
    main()
