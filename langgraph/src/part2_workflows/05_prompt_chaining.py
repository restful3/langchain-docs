"""
[Chapter 5] ì›Œí¬í”Œë¡œìš° íŒ¨í„´ ê°œìš” - Prompt Chaining

ğŸ“ ì„¤ëª…:
    Prompt Chainingì€ ì—¬ëŸ¬ LLM í˜¸ì¶œì„ ìˆœì°¨ì ìœ¼ë¡œ ì—°ê²°í•˜ëŠ” ê°€ì¥ ê¸°ë³¸ì ì¸
    ì›Œí¬í”Œë¡œìš° íŒ¨í„´ì…ë‹ˆë‹¤. ê° ë‹¨ê³„ì˜ ì¶œë ¥ì´ ë‹¤ìŒ ë‹¨ê³„ì˜ ì…ë ¥ì´ ë©ë‹ˆë‹¤.

ğŸ¯ í•™ìŠµ ëª©í‘œ:
    - Workflowì™€ Agentì˜ ì°¨ì´ì  ì´í•´
    - Prompt Chaining íŒ¨í„´ êµ¬í˜„
    - ìˆœì°¨ì  LLM í˜¸ì¶œ ì²´ì¸ êµ¬ì„±
    - Gate(ê²€ì¦) ë‹¨ê³„ ì¶”ê°€ ë°©ë²•

ğŸ“š ê´€ë ¨ ë¬¸ì„œ:
    - docs/Part2-Workflows/05-workflow-patterns.md
    - ê³µì‹ ë¬¸ì„œ: https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#prompt-chaining

ğŸ’» ì‹¤í–‰ ë°©ë²•:
    python -m src.part2_workflows.05_prompt_chaining

ğŸ“¦ í•„ìš”í•œ íŒ¨í‚¤ì§€:
    - langgraph>=0.2.0
    - langchain-anthropic>=0.3.0
"""

import os
from typing import TypedDict, Annotated, Optional
from dotenv import load_dotenv

from langgraph.graph import StateGraph, START, END


# =============================================================================
# 1. Workflow vs Agent ê°œë… ì„¤ëª…
# =============================================================================

def explain_workflow_vs_agent():
    """Workflowì™€ Agentì˜ ì°¨ì´ì  ì„¤ëª…"""
    print("\n" + "=" * 60)
    print("ğŸ“˜ Workflow vs Agent")
    print("=" * 60)

    print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Workflow     â”‚                Agent                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ì •ì  ê²½ë¡œ       â”‚ ë™ì  ê²½ë¡œ (LLMì´ ë‹¤ìŒ ë‹¨ê³„ ê²°ì •)       â”‚
â”‚ ì˜ˆì¸¡ ê°€ëŠ¥       â”‚ ìœ ì—°í•˜ì§€ë§Œ ì˜ˆì¸¡ ì–´ë ¤ì›€                 â”‚
â”‚ ë‹¨ìˆœí•œ ì œì–´     â”‚ ë³µì¡í•œ ì œì–´ íë¦„                       â”‚
â”‚ ë””ë²„ê¹… ì‰¬ì›€     â”‚ ë””ë²„ê¹… ì–´ë ¤ì›€                          â”‚
â”‚ ì œí•œëœ ìœ ì—°ì„±   â”‚ ë†’ì€ ìœ ì—°ì„±                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Workflow íŒ¨í„´ë“¤:
1. Prompt Chaining - ìˆœì°¨ì  LLM í˜¸ì¶œ
2. Routing - ì¡°ê±´ì— ë”°ë¥¸ ë¶„ê¸°
3. Parallelization - ë³‘ë ¬ ì‹¤í–‰
4. Orchestrator-Worker - ì‘ì—… ë¶„ë°° ë° ìˆ˜ì§‘
5. Evaluator-Optimizer - ê²°ê³¼ í‰ê°€ ë° ê°œì„ 

Agent íŒ¨í„´ë“¤:
1. ReAct Agent - ì¶”ë¡ -í–‰ë™ ë£¨í”„
2. Multi-Agent - ì—¬ëŸ¬ Agent í˜‘ì—…
""")


# =============================================================================
# 2. ê¸°ë³¸ Prompt Chaining (LLM ì—†ì´)
# =============================================================================

class TextProcessingState(TypedDict):
    """í…ìŠ¤íŠ¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ State"""
    original_text: str
    step1_result: str
    step2_result: str
    final_result: str


def step1_clean_text(state: TextProcessingState) -> TextProcessingState:
    """Step 1: í…ìŠ¤íŠ¸ ì •ë¦¬"""
    text = state["original_text"]
    cleaned = text.strip().lower()
    return {"step1_result": cleaned}


def step2_transform_text(state: TextProcessingState) -> TextProcessingState:
    """Step 2: í…ìŠ¤íŠ¸ ë³€í™˜"""
    text = state["step1_result"]
    # ë‹¨ì–´ë³„ë¡œ ì²« ê¸€ì ëŒ€ë¬¸ì
    transformed = " ".join(word.capitalize() for word in text.split())
    return {"step2_result": transformed}


def step3_finalize(state: TextProcessingState) -> TextProcessingState:
    """Step 3: ìµœì¢… ì²˜ë¦¬"""
    text = state["step2_result"]
    final = f"[ì²˜ë¦¬ë¨] {text}"
    return {"final_result": final}


def create_basic_chain():
    """ê¸°ë³¸ Prompt Chaining ê·¸ë˜í”„ ìƒì„±"""
    graph = StateGraph(TextProcessingState)

    graph.add_node("clean", step1_clean_text)
    graph.add_node("transform", step2_transform_text)
    graph.add_node("finalize", step3_finalize)

    graph.add_edge(START, "clean")
    graph.add_edge("clean", "transform")
    graph.add_edge("transform", "finalize")
    graph.add_edge("finalize", END)

    return graph.compile()


def run_basic_chain_example():
    """ê¸°ë³¸ ì²´ì´ë‹ ì˜ˆì œ ì‹¤í–‰"""
    print("\n" + "=" * 60)
    print("ì˜ˆì œ 1: ê¸°ë³¸ Prompt Chaining")
    print("=" * 60)

    app = create_basic_chain()

    initial_state = {
        "original_text": "  HELLO WORLD, THIS IS LANGGRAPH!  ",
        "step1_result": "",
        "step2_result": "",
        "final_result": ""
    }

    result = app.invoke(initial_state)

    print(f"\nğŸ“ ì²˜ë¦¬ ê³¼ì •:")
    print(f"   ì›ë³¸: '{initial_state['original_text']}'")
    print(f"   Step 1 (ì •ë¦¬): '{result['step1_result']}'")
    print(f"   Step 2 (ë³€í™˜): '{result['step2_result']}'")
    print(f"   ìµœì¢…: '{result['final_result']}'")


# =============================================================================
# 3. LLMì„ ì‚¬ìš©í•œ Prompt Chaining
# =============================================================================

class JokeState(TypedDict):
    """ë†ë‹´ ìƒì„±ì„ ìœ„í•œ State"""
    topic: str
    initial_joke: str
    critique: str
    improved_joke: str


def create_llm_chain():
    """LLMì„ ì‚¬ìš©í•œ ë†ë‹´ ê°œì„  ì²´ì¸ ìƒì„±"""

    if not os.getenv("ANTHROPIC_API_KEY"):
        return None

    try:
        from langchain_anthropic import ChatAnthropic
        from langchain_core.messages import HumanMessage, SystemMessage
    except ImportError:
        return None

    llm = ChatAnthropic(model="claude-sonnet-4-5-20250929", temperature=0.7)

    def generate_joke(state: JokeState) -> JokeState:
        """Step 1: ì´ˆê¸° ë†ë‹´ ìƒì„±"""
        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ì¬ë¯¸ìˆëŠ” ë†ë‹´ì„ ë§Œë“œëŠ” ì½”ë¯¸ë””ì–¸ì…ë‹ˆë‹¤."),
            HumanMessage(content=f"'{state['topic']}'ì— ëŒ€í•œ ì§§ì€ ë†ë‹´ì„ í•˜ë‚˜ ë§Œë“¤ì–´ì£¼ì„¸ìš”.")
        ]
        response = llm.invoke(messages)
        return {"initial_joke": response.content}

    def critique_joke(state: JokeState) -> JokeState:
        """Step 2: ë†ë‹´ í‰ê°€"""
        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ì½”ë¯¸ë”” ë¹„í‰ê°€ì…ë‹ˆë‹¤."),
            HumanMessage(content=f"""ë‹¤ìŒ ë†ë‹´ì„ í‰ê°€í•˜ê³  ê°œì„ ì ì„ ì œì•ˆí•´ì£¼ì„¸ìš”:

ë†ë‹´: {state['initial_joke']}

ê°œì„ í•  ì ì„ 2-3ê°€ì§€ ì œì•ˆí•´ì£¼ì„¸ìš”.""")
        ]
        response = llm.invoke(messages)
        return {"critique": response.content}

    def improve_joke(state: JokeState) -> JokeState:
        """Step 3: ë†ë‹´ ê°œì„ """
        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ì°½ì˜ì ì¸ ì½”ë¯¸ë””ì–¸ì…ë‹ˆë‹¤."),
            HumanMessage(content=f"""ë‹¤ìŒ í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ ë†ë‹´ì„ ê°œì„ í•´ì£¼ì„¸ìš”:

ì›ë˜ ë†ë‹´: {state['initial_joke']}

í”¼ë“œë°±: {state['critique']}

ê°œì„ ëœ ë†ë‹´ë§Œ ì‘ì„±í•´ì£¼ì„¸ìš”.""")
        ]
        response = llm.invoke(messages)
        return {"improved_joke": response.content}

    graph = StateGraph(JokeState)
    graph.add_node("generate", generate_joke)
    graph.add_node("critique", critique_joke)
    graph.add_node("improve", improve_joke)

    graph.add_edge(START, "generate")
    graph.add_edge("generate", "critique")
    graph.add_edge("critique", "improve")
    graph.add_edge("improve", END)

    return graph.compile()


def run_llm_chain_example():
    """LLM ì²´ì´ë‹ ì˜ˆì œ ì‹¤í–‰"""
    print("\n" + "=" * 60)
    print("ì˜ˆì œ 2: LLM Prompt Chaining (ë†ë‹´ ê°œì„ )")
    print("=" * 60)

    load_dotenv()
    app = create_llm_chain()

    if app is None:
        print("\nâš ï¸  LLMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   ANTHROPIC_API_KEYë¥¼ ì„¤ì •í•˜ê³  langchain-anthropicì„ ì„¤ì¹˜í•˜ì„¸ìš”.")
        return

    result = app.invoke({
        "topic": "í”„ë¡œê·¸ë˜ë°",
        "initial_joke": "",
        "critique": "",
        "improved_joke": ""
    })

    print(f"\nğŸ¯ ì£¼ì œ: '{result['topic']}'")
    print(f"\nğŸ“ Step 1 - ì´ˆê¸° ë†ë‹´:")
    print(f"   {result['initial_joke']}")
    print(f"\nğŸ” Step 2 - í‰ê°€:")
    print(f"   {result['critique'][:200]}...")
    print(f"\nâœ¨ Step 3 - ê°œì„ ëœ ë†ë‹´:")
    print(f"   {result['improved_joke']}")


# =============================================================================
# 4. Gate(ê²€ì¦) ë‹¨ê³„ê°€ ìˆëŠ” ì²´ì´ë‹
# =============================================================================

class GatedState(TypedDict):
    """ê²€ì¦ ë‹¨ê³„ê°€ ìˆëŠ” State"""
    input_text: str
    processed: str
    is_valid: bool
    error_message: str
    final_output: str


def process_input(state: GatedState) -> GatedState:
    """ì…ë ¥ ì²˜ë¦¬"""
    processed = state["input_text"].strip().upper()
    return {"processed": processed}


def validate_input(state: GatedState) -> GatedState:
    """ì…ë ¥ ê²€ì¦ (Gate)"""
    processed = state["processed"]

    # ê²€ì¦ ê·œì¹™
    if len(processed) < 3:
        return {
            "is_valid": False,
            "error_message": "ì…ë ¥ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ (ìµœì†Œ 3ì)"
        }
    if not processed.replace(" ", "").isalnum():
        return {
            "is_valid": False,
            "error_message": "ì˜ìˆ«ìë§Œ í—ˆìš©ë©ë‹ˆë‹¤"
        }

    return {"is_valid": True, "error_message": ""}


def finalize_valid(state: GatedState) -> GatedState:
    """ìœ íš¨í•œ ì…ë ¥ ì²˜ë¦¬"""
    return {"final_output": f"âœ… ì„±ê³µ: {state['processed']}"}


def handle_invalid(state: GatedState) -> GatedState:
    """ìœ íš¨í•˜ì§€ ì•Šì€ ì…ë ¥ ì²˜ë¦¬"""
    return {"final_output": f"âŒ ì‹¤íŒ¨: {state['error_message']}"}


def route_by_validation(state: GatedState) -> str:
    """ê²€ì¦ ê²°ê³¼ì— ë”°ë¼ ë¼ìš°íŒ…"""
    if state["is_valid"]:
        return "finalize"
    return "handle_error"


def create_gated_chain():
    """ê²€ì¦ ë‹¨ê³„ê°€ ìˆëŠ” ì²´ì¸ ìƒì„±"""
    graph = StateGraph(GatedState)

    graph.add_node("process", process_input)
    graph.add_node("validate", validate_input)
    graph.add_node("finalize", finalize_valid)
    graph.add_node("handle_error", handle_invalid)

    graph.add_edge(START, "process")
    graph.add_edge("process", "validate")

    # ì¡°ê±´ë¶€ ì—£ì§€ - ê²€ì¦ ê²°ê³¼ì— ë”°ë¼ ë¶„ê¸°
    graph.add_conditional_edges(
        "validate",
        route_by_validation,
        {
            "finalize": "finalize",
            "handle_error": "handle_error"
        }
    )

    graph.add_edge("finalize", END)
    graph.add_edge("handle_error", END)

    return graph.compile()


def run_gated_chain_example():
    """ê²€ì¦ ì²´ì´ë‹ ì˜ˆì œ ì‹¤í–‰"""
    print("\n" + "=" * 60)
    print("ì˜ˆì œ 3: Gate(ê²€ì¦) ë‹¨ê³„ê°€ ìˆëŠ” ì²´ì´ë‹")
    print("=" * 60)

    app = create_gated_chain()

    test_cases = [
        "Hello World",  # ìœ íš¨
        "AB",           # ë„ˆë¬´ ì§§ìŒ
        "Test@123",     # íŠ¹ìˆ˜ë¬¸ì í¬í•¨
    ]

    for text in test_cases:
        result = app.invoke({
            "input_text": text,
            "processed": "",
            "is_valid": False,
            "error_message": "",
            "final_output": ""
        })
        print(f"\n   ì…ë ¥: '{text}'")
        print(f"   ê²°ê³¼: {result['final_output']}")


# =============================================================================
# 5. ìŠ¤íŠ¸ë¦¬ë°ê³¼ í•¨ê»˜ ì‚¬ìš©
# =============================================================================

class StreamingState(TypedDict):
    """ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ State"""
    steps: Annotated[list, lambda x, y: x + y]
    current_step: int


def step_a(state: StreamingState) -> StreamingState:
    """Step A"""
    return {"steps": ["A ì™„ë£Œ"], "current_step": 1}


def step_b(state: StreamingState) -> StreamingState:
    """Step B"""
    return {"steps": ["B ì™„ë£Œ"], "current_step": 2}


def step_c(state: StreamingState) -> StreamingState:
    """Step C"""
    return {"steps": ["C ì™„ë£Œ"], "current_step": 3}


def create_streaming_chain():
    """ìŠ¤íŠ¸ë¦¬ë° ì²´ì¸ ìƒì„±"""
    graph = StateGraph(StreamingState)

    graph.add_node("step_a", step_a)
    graph.add_node("step_b", step_b)
    graph.add_node("step_c", step_c)

    graph.add_edge(START, "step_a")
    graph.add_edge("step_a", "step_b")
    graph.add_edge("step_b", "step_c")
    graph.add_edge("step_c", END)

    return graph.compile()


def run_streaming_example():
    """ìŠ¤íŠ¸ë¦¬ë° ì˜ˆì œ ì‹¤í–‰"""
    print("\n" + "=" * 60)
    print("ì˜ˆì œ 4: ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë‹¨ê³„ë³„ ì§„í–‰ í™•ì¸")
    print("=" * 60)

    app = create_streaming_chain()

    initial = {"steps": [], "current_step": 0}

    print("\nğŸ”„ ì§„í–‰ ìƒí™©:")

    # stream() ë©”ì„œë“œë¡œ ë‹¨ê³„ë³„ ì¶œë ¥ í™•ì¸
    for event in app.stream(initial):
        for node_name, state_update in event.items():
            print(f"   [{node_name}] ì™„ë£Œ - Step {state_update.get('current_step', '?')}")


# =============================================================================
# 6. Prompt Chaining íŒ¨í„´ ì •ë¦¬
# =============================================================================

def explain_prompt_chaining_patterns():
    """Prompt Chaining íŒ¨í„´ ì„¤ëª…"""
    print("\n" + "=" * 60)
    print("ğŸ“˜ Prompt Chaining íŒ¨í„´ ì •ë¦¬")
    print("=" * 60)

    print("""
Prompt Chainingì˜ íŠ¹ì§•:
1. ì„ í˜•ì  íë¦„ - A â†’ B â†’ C â†’ D
2. ê° ë‹¨ê³„ì˜ ì¶œë ¥ì´ ë‹¤ìŒ ë‹¨ê³„ì˜ ì…ë ¥
3. ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì‹¤í–‰ ìˆœì„œ

ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
- ë¬¸ì„œ ìš”ì•½ í›„ ë²ˆì—­
- ì½”ë“œ ìƒì„± í›„ ë¦¬ë·°
- ë°ì´í„° ì¶”ì¶œ í›„ ë¶„ì„

ì¼ë°˜ì ì¸ íŒ¨í„´:

1. ìˆœì°¨ì  ì²˜ë¦¬
   START â†’ process_1 â†’ process_2 â†’ ... â†’ END

2. Gate(ê²€ì¦) í¬í•¨
   START â†’ process â†’ validate â†’â”¬â†’ success â†’ END
                               â””â†’ failure â†’ END

3. í”¼ë“œë°± ë£¨í”„ (ë‹¤ìŒ ì±•í„°ì—ì„œ ìì„¸íˆ)
   START â†’ generate â†’ evaluate â†’â”¬â†’ END (í•©ê²©)
                     â†‘          â””â†’ improve
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

êµ¬í˜„ íŒ:
- Stateì— ì¤‘ê°„ ê²°ê³¼ë¥¼ ëª¨ë‘ ì €ì¥í•˜ë©´ ë””ë²„ê¹…ì´ ì‰¬ì›€
- stream()ì„ ì‚¬ìš©í•˜ë©´ ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥
- ê° ë‹¨ê³„ë¥¼ ë…ë¦½ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•˜ê²Œ ì„¤ê³„
""")


# =============================================================================
# ë©”ì¸ ì‹¤í–‰
# =============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("[Chapter 5] ì›Œí¬í”Œë¡œìš° íŒ¨í„´ ê°œìš” - Prompt Chaining")
    print("=" * 60)

    # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    load_dotenv()

    # ê°œë… ì„¤ëª…
    explain_workflow_vs_agent()

    # ì˜ˆì œ ì‹¤í–‰
    run_basic_chain_example()
    run_llm_chain_example()
    run_gated_chain_example()
    run_streaming_example()

    # íŒ¨í„´ ì •ë¦¬
    explain_prompt_chaining_patterns()

    print("\n" + "=" * 60)
    print("âœ… ëª¨ë“  ì˜ˆì œ ì‹¤í–‰ ì™„ë£Œ!")
    print("   ë‹¤ìŒ ì˜ˆì œ: 06_routing.py (ì¡°ê±´ë¶€ ë¼ìš°íŒ…)")
    print("=" * 60)


if __name__ == "__main__":
    main()
