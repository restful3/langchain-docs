"""
[Chapter 8 í™•ì¥] Evaluator-Optimizer íŒ¨í„´

ğŸ“ ì„¤ëª…:
    Evaluator-Optimizer íŒ¨í„´ì€ ê²°ê³¼ë¥¼ í‰ê°€í•˜ê³ , ê¸°ì¤€ì„ ì¶©ì¡±í•˜ì§€ ëª»í•˜ë©´
    ê°œì„ í•˜ëŠ” ê³¼ì •ì„ ë°˜ë³µí•˜ëŠ” í”¼ë“œë°± ë£¨í”„ íŒ¨í„´ì…ë‹ˆë‹¤.
    í’ˆì§ˆ í–¥ìƒì´ í•„ìš”í•œ ì‘ì—…ì— ì í•©í•©ë‹ˆë‹¤.

ğŸ¯ í•™ìŠµ ëª©í‘œ:
    - Evaluator-Optimizer ì•„í‚¤í…ì²˜ ì´í•´
    - í”¼ë“œë°± ë£¨í”„ êµ¬í˜„
    - ì¢…ë£Œ ì¡°ê±´ ì„¤ì •
    - LLMì„ ì‚¬ìš©í•œ í‰ê°€ ë° ê°œì„ 

ğŸ“š ê´€ë ¨ ë¬¸ì„œ:
    - docs/Part2-Workflows/08-orchestrator-worker.md
    - ê³µì‹ ë¬¸ì„œ: https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#evaluator-optimizer

ğŸ’» ì‹¤í–‰ ë°©ë²•:
    python -m src.part2_workflows.09_evaluator_optimizer

ğŸ“¦ í•„ìš”í•œ íŒ¨í‚¤ì§€:
    - langgraph>=0.2.0
    - langchain-anthropic>=0.3.0
"""

import os
from typing import TypedDict, Annotated, Literal
from dotenv import load_dotenv
import operator

from langgraph.graph import StateGraph, START, END


# =============================================================================
# 1. ê¸°ë³¸ Evaluator-Optimizer íŒ¨í„´
# =============================================================================

class OptimizationState(TypedDict):
    """ìµœì í™”ë¥¼ ìœ„í•œ State"""
    target: int
    current_value: int
    iteration: int
    max_iterations: int
    history: Annotated[list, operator.add]
    is_optimized: bool


def generate(state: OptimizationState) -> OptimizationState:
    """ê°’ ìƒì„±/ì¡°ì •"""
    current = state["current_value"]
    target = state["target"]

    # ê°„ë‹¨í•œ ìµœì í™” ë¡œì§: ëª©í‘œì— ë” ê°€ê¹ê²Œ ì¡°ì •
    if current < target:
        new_value = min(current + 10, target)
    else:
        new_value = max(current - 10, target)

    return {
        "current_value": new_value,
        "history": [f"Iteration {state['iteration']}: {current} -> {new_value}"]
    }


def evaluate(state: OptimizationState) -> OptimizationState:
    """ê²°ê³¼ í‰ê°€"""
    current = state["current_value"]
    target = state["target"]
    iteration = state["iteration"] + 1

    # ëª©í‘œ ë‹¬ì„± ì—¬ë¶€ í™•ì¸
    is_optimized = current == target

    return {
        "iteration": iteration,
        "is_optimized": is_optimized
    }


def should_continue(state: OptimizationState) -> Literal["generate", "end"]:
    """ê³„ì† ìµœì í™”í• ì§€ ê²°ì •"""
    if state["is_optimized"]:
        return "end"
    if state["iteration"] >= state["max_iterations"]:
        return "end"
    return "generate"


def create_basic_optimizer_graph():
    """ê¸°ë³¸ Evaluator-Optimizer ê·¸ë˜í”„ ìƒì„±"""
    graph = StateGraph(OptimizationState)

    graph.add_node("generate", generate)
    graph.add_node("evaluate", evaluate)

    graph.add_edge(START, "generate")
    graph.add_edge("generate", "evaluate")

    graph.add_conditional_edges(
        "evaluate",
        should_continue,
        {
            "generate": "generate",  # ë£¨í”„ë°±
            "end": END
        }
    )

    return graph.compile()


def run_basic_optimizer_example():
    """ê¸°ë³¸ Optimizer ì˜ˆì œ ì‹¤í–‰"""
    print("\n" + "=" * 60)
    print("ì˜ˆì œ 1: ê¸°ë³¸ Evaluator-Optimizer")
    print("=" * 60)

    app = create_basic_optimizer_graph()

    result = app.invoke({
        "target": 100,
        "current_value": 25,
        "iteration": 0,
        "max_iterations": 20,
        "history": [],
        "is_optimized": False
    })

    print(f"\nğŸ¯ ëª©í‘œ: {result['target']}")
    print(f"ğŸ“Š ìµœì í™” ê³¼ì •:")
    for h in result["history"]:
        print(f"   {h}")
    print(f"\nâœ… ìµœì¢… ê°’: {result['current_value']}")
    print(f"   ë°˜ë³µ íšŸìˆ˜: {result['iteration']}")
    print(f"   ìµœì í™” ì™„ë£Œ: {result['is_optimized']}")


# =============================================================================
# 2. í…ìŠ¤íŠ¸ í’ˆì§ˆ ê°œì„  íŒ¨í„´
# =============================================================================

class TextQualityState(TypedDict):
    """í…ìŠ¤íŠ¸ í’ˆì§ˆ ê°œì„ ì„ ìœ„í•œ State"""
    original_text: str
    current_text: str
    quality_score: int  # 0-100
    feedback: str
    iteration: int
    max_iterations: int
    threshold: int


def improve_text(state: TextQualityState) -> TextQualityState:
    """í…ìŠ¤íŠ¸ ê°œì„ """
    text = state["current_text"]
    feedback = state.get("feedback", "")

    # ê°„ë‹¨í•œ ê°œì„  ë¡œì§
    improvements = []

    # í”¼ë“œë°±ì— ë”°ë¥¸ ê°œì„ 
    if "ëŒ€ë¬¸ì" in feedback or state["iteration"] == 0:
        text = text.capitalize()
        improvements.append("ì²« ê¸€ì ëŒ€ë¬¸ìí™”")

    if "êµ¬ë‘ì " in feedback or "." not in text:
        if not text.endswith("."):
            text = text + "."
            improvements.append("ë§ˆì¹¨í‘œ ì¶”ê°€")

    if "ê³µë°±" in feedback or "  " in text:
        text = " ".join(text.split())
        improvements.append("ê³µë°± ì •ë¦¬")

    # í’ˆì§ˆ ì ìˆ˜ ì¦ê°€
    new_score = min(state["quality_score"] + 20, 100)

    return {
        "current_text": text,
        "quality_score": new_score,
        "feedback": f"ì ìš©ëœ ê°œì„ : {', '.join(improvements) if improvements else 'ì—†ìŒ'}"
    }


def evaluate_quality(state: TextQualityState) -> TextQualityState:
    """í…ìŠ¤íŠ¸ í’ˆì§ˆ í‰ê°€"""
    text = state["current_text"]
    iteration = state["iteration"] + 1

    # í’ˆì§ˆ í‰ê°€ ê¸°ì¤€
    issues = []

    if not text[0].isupper():
        issues.append("ëŒ€ë¬¸ìë¡œ ì‹œì‘í•´ì•¼ í•¨")
    if not text.endswith("."):
        issues.append("êµ¬ë‘ì  í•„ìš”")
    if "  " in text:
        issues.append("ê³µë°± ì •ë¦¬ í•„ìš”")
    if len(text) < 10:
        issues.append("í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŒ")

    feedback = ", ".join(issues) if issues else "í’ˆì§ˆ ê¸°ì¤€ ì¶©ì¡±"

    return {
        "iteration": iteration,
        "feedback": feedback
    }


def should_continue_improving(state: TextQualityState) -> Literal["improve", "end"]:
    """ê³„ì† ê°œì„ í• ì§€ ê²°ì •"""
    if state["quality_score"] >= state["threshold"]:
        return "end"
    if state["iteration"] >= state["max_iterations"]:
        return "end"
    if state["feedback"] == "í’ˆì§ˆ ê¸°ì¤€ ì¶©ì¡±":
        return "end"
    return "improve"


def create_text_quality_graph():
    """í…ìŠ¤íŠ¸ í’ˆì§ˆ ê°œì„  ê·¸ë˜í”„ ìƒì„±"""
    graph = StateGraph(TextQualityState)

    graph.add_node("improve", improve_text)
    graph.add_node("evaluate", evaluate_quality)

    graph.add_edge(START, "improve")
    graph.add_edge("improve", "evaluate")

    graph.add_conditional_edges(
        "evaluate",
        should_continue_improving,
        {
            "improve": "improve",
            "end": END
        }
    )

    return graph.compile()


def run_text_quality_example():
    """í…ìŠ¤íŠ¸ í’ˆì§ˆ ê°œì„  ì˜ˆì œ ì‹¤í–‰"""
    print("\n" + "=" * 60)
    print("ì˜ˆì œ 2: í…ìŠ¤íŠ¸ í’ˆì§ˆ ê°œì„ ")
    print("=" * 60)

    app = create_text_quality_graph()

    result = app.invoke({
        "original_text": "this is  a test   text without proper formatting",
        "current_text": "this is  a test   text without proper formatting",
        "quality_score": 20,
        "feedback": "",
        "iteration": 0,
        "max_iterations": 5,
        "threshold": 80
    })

    print(f"\nğŸ“ ì›ë³¸: '{result['original_text']}'")
    print(f"âœ¨ ê°œì„ : '{result['current_text']}'")
    print(f"ğŸ“Š í’ˆì§ˆ ì ìˆ˜: {result['quality_score']}/100")
    print(f"   ë°˜ë³µ íšŸìˆ˜: {result['iteration']}")


# =============================================================================
# 3. LLM ê¸°ë°˜ ì½˜í…ì¸  ê°œì„ 
# =============================================================================

class LLMContentState(TypedDict):
    """LLM ì½˜í…ì¸  ê°œì„ ì„ ìœ„í•œ State"""
    topic: str
    current_content: str
    evaluation: str
    score: int
    iteration: int
    max_iterations: int


def create_llm_content_graph():
    """LLM ê¸°ë°˜ ì½˜í…ì¸  ê°œì„  ê·¸ë˜í”„ ìƒì„±"""

    if not os.getenv("ANTHROPIC_API_KEY"):
        return None

    try:
        from langchain_anthropic import ChatAnthropic
        from langchain_core.messages import HumanMessage, SystemMessage
    except ImportError:
        return None

    llm = ChatAnthropic(model="claude-sonnet-4-5-20250929", temperature=0.7)

    def generate_content(state: LLMContentState) -> LLMContentState:
        """ì½˜í…ì¸  ìƒì„± ë˜ëŠ” ê°œì„ """
        if not state["current_content"]:
            # ì´ˆê¸° ìƒì„±
            messages = [
                SystemMessage(content="ë‹¹ì‹ ì€ ê¸°ìˆ  ë¸”ë¡œê·¸ ì‘ê°€ì…ë‹ˆë‹¤."),
                HumanMessage(content=f"'{state['topic']}'ì— ëŒ€í•œ ì§§ì€ ì†Œê°œê¸€(2-3ë¬¸ì¥)ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.")
            ]
        else:
            # í”¼ë“œë°± ê¸°ë°˜ ê°œì„ 
            messages = [
                SystemMessage(content="ë‹¹ì‹ ì€ í¸ì§‘ìì…ë‹ˆë‹¤. í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ ê¸€ì„ ê°œì„ í•˜ì„¸ìš”."),
                HumanMessage(content=f"""ì›ë³¸ ê¸€:
{state['current_content']}

í”¼ë“œë°±:
{state['evaluation']}

í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ê°œì„ ëœ ê¸€ë§Œ ì‘ì„±í•˜ì„¸ìš”.""")
            ]

        response = llm.invoke(messages)
        return {"current_content": response.content}

    def evaluate_content(state: LLMContentState) -> LLMContentState:
        """ì½˜í…ì¸  í‰ê°€"""
        messages = [
            SystemMessage(content="""ë‹¹ì‹ ì€ ì½˜í…ì¸  í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ ê¸€ì„ í‰ê°€í•˜ì„¸ìš”:
1. ëª…í™•ì„± (1-10)
2. ì •ë³´ì„± (1-10)
3. í¥ë¯¸ë„ (1-10)

ì´ì (30ì  ë§Œì )ê³¼ ê°œì„ ì ì„ ì œì‹œí•˜ì„¸ìš”.
í˜•ì‹: "ì ìˆ˜: XX/30\nê°œì„ ì : ..."ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."""),
            HumanMessage(content=state["current_content"])
        ]

        response = llm.invoke(messages)
        evaluation = response.content

        # ì ìˆ˜ ì¶”ì¶œ (ê°„ë‹¨í•œ íŒŒì‹±)
        try:
            score_line = [l for l in evaluation.split("\n") if "ì ìˆ˜:" in l][0]
            score = int(score_line.split("/")[0].split(":")[-1].strip())
        except (IndexError, ValueError):
            score = 15  # ê¸°ë³¸ ì ìˆ˜

        return {
            "evaluation": evaluation,
            "score": score,
            "iteration": state["iteration"] + 1
        }

    def should_continue_improving_content(state: LLMContentState) -> Literal["generate", "end"]:
        """ê³„ì† ê°œì„ í• ì§€ ê²°ì •"""
        if state["score"] >= 25:  # 25/30 ì´ìƒì´ë©´ ì¢…ë£Œ
            return "end"
        if state["iteration"] >= state["max_iterations"]:
            return "end"
        return "generate"

    graph = StateGraph(LLMContentState)

    graph.add_node("generate", generate_content)
    graph.add_node("evaluate", evaluate_content)

    graph.add_edge(START, "generate")
    graph.add_edge("generate", "evaluate")

    graph.add_conditional_edges(
        "evaluate",
        should_continue_improving_content,
        {
            "generate": "generate",
            "end": END
        }
    )

    return graph.compile()


def run_llm_content_example():
    """LLM ì½˜í…ì¸  ê°œì„  ì˜ˆì œ ì‹¤í–‰"""
    print("\n" + "=" * 60)
    print("ì˜ˆì œ 3: LLM ê¸°ë°˜ ì½˜í…ì¸  ê°œì„ ")
    print("=" * 60)

    load_dotenv()
    app = create_llm_content_graph()

    if app is None:
        print("\nâš ï¸  LLMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    result = app.invoke({
        "topic": "LangGraph",
        "current_content": "",
        "evaluation": "",
        "score": 0,
        "iteration": 0,
        "max_iterations": 3
    })

    print(f"\nğŸ¯ ì£¼ì œ: {result['topic']}")
    print(f"\nğŸ“ ìµœì¢… ì½˜í…ì¸ :\n{result['current_content']}")
    print(f"\nğŸ“Š ìµœì¢… ì ìˆ˜: {result['score']}/30")
    print(f"   ë°˜ë³µ íšŸìˆ˜: {result['iteration']}")


# =============================================================================
# 4. ë‹¤ë‹¨ê³„ ê²€ì¦ íŒ¨í„´
# =============================================================================

class ValidationState(TypedDict):
    """ë‹¤ë‹¨ê³„ ê²€ì¦ì„ ìœ„í•œ State"""
    data: dict
    validation_results: Annotated[list, operator.add]
    current_stage: int
    all_passed: bool


def validate_format(state: ValidationState) -> ValidationState:
    """í˜•ì‹ ê²€ì¦"""
    data = state["data"]
    results = []

    # í•„ìˆ˜ í•„ë“œ í™•ì¸
    required = ["name", "email", "age"]
    for field in required:
        if field in data:
            results.append(f"âœ… {field}: ì¡´ì¬")
        else:
            results.append(f"âŒ {field}: ëˆ„ë½")

    return {"validation_results": results, "current_stage": 1}


def validate_types(state: ValidationState) -> ValidationState:
    """íƒ€ì… ê²€ì¦"""
    data = state["data"]
    results = []

    if isinstance(data.get("name"), str):
        results.append("âœ… name: ë¬¸ìì—´")
    else:
        results.append("âŒ name: ë¬¸ìì—´ì´ì–´ì•¼ í•¨")

    if isinstance(data.get("age"), int):
        results.append("âœ… age: ì •ìˆ˜")
    else:
        results.append("âŒ age: ì •ìˆ˜ì—¬ì•¼ í•¨")

    return {"validation_results": results, "current_stage": 2}


def validate_business(state: ValidationState) -> ValidationState:
    """ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦"""
    data = state["data"]
    results = []

    # ë‚˜ì´ ë²”ìœ„ í™•ì¸
    age = data.get("age", 0)
    if 0 < age < 150:
        results.append("âœ… age: ìœ íš¨í•œ ë²”ìœ„")
    else:
        results.append("âŒ age: 0-150 ë²”ìœ„ì—¬ì•¼ í•¨")

    # ì´ë©”ì¼ í˜•ì‹ í™•ì¸ (ê°„ë‹¨)
    email = data.get("email", "")
    if "@" in email and "." in email:
        results.append("âœ… email: ìœ íš¨í•œ í˜•ì‹")
    else:
        results.append("âŒ email: ìœ íš¨í•˜ì§€ ì•Šì€ í˜•ì‹")

    # ì „ì²´ ê²°ê³¼ í™•ì¸
    all_passed = all("âœ…" in r for r in state["validation_results"] + results)

    return {
        "validation_results": results,
        "current_stage": 3,
        "all_passed": all_passed
    }


def create_validation_graph():
    """ë‹¤ë‹¨ê³„ ê²€ì¦ ê·¸ë˜í”„ ìƒì„±"""
    graph = StateGraph(ValidationState)

    graph.add_node("validate_format", validate_format)
    graph.add_node("validate_types", validate_types)
    graph.add_node("validate_business", validate_business)

    graph.add_edge(START, "validate_format")
    graph.add_edge("validate_format", "validate_types")
    graph.add_edge("validate_types", "validate_business")
    graph.add_edge("validate_business", END)

    return graph.compile()


def run_validation_example():
    """ë‹¤ë‹¨ê³„ ê²€ì¦ ì˜ˆì œ ì‹¤í–‰"""
    print("\n" + "=" * 60)
    print("ì˜ˆì œ 4: ë‹¤ë‹¨ê³„ ê²€ì¦")
    print("=" * 60)

    app = create_validation_graph()

    test_data = {
        "name": "í™ê¸¸ë™",
        "email": "hong@example.com",
        "age": 30
    }

    result = app.invoke({
        "data": test_data,
        "validation_results": [],
        "current_stage": 0,
        "all_passed": False
    })

    print(f"\nğŸ“‹ ê²€ì¦ ë°ì´í„°: {test_data}")
    print(f"\nğŸ” ê²€ì¦ ê²°ê³¼:")
    for r in result["validation_results"]:
        print(f"   {r}")
    print(f"\n{'âœ… ëª¨ë“  ê²€ì¦ í†µê³¼!' if result['all_passed'] else 'âŒ ì¼ë¶€ ê²€ì¦ ì‹¤íŒ¨'}")


# =============================================================================
# 5. Evaluator-Optimizer íŒ¨í„´ ì •ë¦¬
# =============================================================================

def explain_evaluator_optimizer_pattern():
    """Evaluator-Optimizer íŒ¨í„´ ì„¤ëª…"""
    print("\n" + "=" * 60)
    print("ğŸ“˜ Evaluator-Optimizer íŒ¨í„´ ì •ë¦¬")
    print("=" * 60)

    print("""
Evaluator-Optimizer êµ¬ì¡°:

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Generate   â”‚ â—„â”€â”€â”€â”€â”€â”€â”
    â”‚  (ìƒì„±/ê°œì„ )  â”‚        â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
           â”‚                â”‚
           â–¼                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
    â”‚   Evaluate   â”‚        â”‚
    â”‚    (í‰ê°€)    â”‚        â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
           â”‚                â”‚
           â–¼                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
    â”‚  Should      â”‚â”€â”€â”€YESâ”€â”€â”˜
    â”‚  Continue?   â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ NO
           â–¼
         [END]

í•µì‹¬ êµ¬ì„±ìš”ì†Œ:

1. Generator (ìƒì„±ê¸°)
   - ì´ˆê¸° ê²°ê³¼ ìƒì„±
   - í”¼ë“œë°± ê¸°ë°˜ ê°œì„ 
   - ì ì§„ì  í’ˆì§ˆ í–¥ìƒ

2. Evaluator (í‰ê°€ê¸°)
   - ê²°ê³¼ í’ˆì§ˆ í‰ê°€
   - í”¼ë“œë°± ìƒì„±
   - ì ìˆ˜/ì§€í‘œ ì‚°ì¶œ

3. Continue Condition (ê³„ì† ì¡°ê±´)
   - í’ˆì§ˆ ì„ê³„ê°’ ë„ë‹¬ ì—¬ë¶€
   - ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
   - íƒ€ì„ì•„ì›ƒ

ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
- ì½˜í…ì¸  í’ˆì§ˆ ê°œì„ 
- ì½”ë“œ ìµœì í™”
- ë°ì´í„° ê²€ì¦
- A/B í…ŒìŠ¤íŠ¸ ë°˜ë³µ

ì¢…ë£Œ ì¡°ê±´ ì„¤ì • íŒ:
1. í’ˆì§ˆ ì„ê³„ê°’ ì„¤ì • (ì˜ˆ: 80/100)
2. ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ì œí•œ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
3. íƒ€ì„ì•„ì›ƒ ì„¤ì •
4. ê°œì„ í­ ì²´í¬ (ë” ì´ìƒ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ ì¢…ë£Œ)
""")


# =============================================================================
# ë©”ì¸ ì‹¤í–‰
# =============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("[Chapter 8 í™•ì¥] Evaluator-Optimizer íŒ¨í„´")
    print("=" * 60)

    load_dotenv()

    # ì˜ˆì œ ì‹¤í–‰
    run_basic_optimizer_example()
    run_text_quality_example()
    run_llm_content_example()
    run_validation_example()

    # íŒ¨í„´ ì •ë¦¬
    explain_evaluator_optimizer_pattern()

    print("\n" + "=" * 60)
    print("âœ… Part 2 ì™„ë£Œ!")
    print("   ë‹¤ìŒ: Part 3 - AI Agent êµ¬í˜„")
    print("=" * 60)


if __name__ == "__main__":
    main()
