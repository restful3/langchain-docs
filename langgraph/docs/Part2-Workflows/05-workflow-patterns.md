# Chapter 5: ì›Œí¬í”Œë¡œìš° íŒ¨í„´ ê°œìš”

> ğŸ“Œ **í•™ìŠµ ëª©í‘œ**: ì´ ì¥ì„ ë§ˆì¹˜ë©´ Workflowì™€ Agentì˜ ì°¨ì´ë¥¼ ì´í•´í•˜ê³ , LLM ì¦ê°• ê¸°ë²•ê³¼ Prompt Chaining íŒ¨í„´ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ê°œìš”

LangGraphë¡œ êµ¬ì¶•í•  ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œì€ í¬ê²Œ **Workflow**ì™€ **Agent** ë‘ ê°€ì§€ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- **Workflow(ì›Œí¬í”Œë¡œìš°)**: ë¯¸ë¦¬ ì •í•´ì§„ ì½”ë“œ ê²½ë¡œë¥¼ ë”°ë¥´ë©°, íŠ¹ì • ìˆœì„œëŒ€ë¡œ ì‘ë™
- **Agent(ì—ì´ì „íŠ¸)**: ë™ì ìœ¼ë¡œ ìì‹ ì˜ í”„ë¡œì„¸ìŠ¤ì™€ ë„êµ¬ ì‚¬ìš©ì„ ê²°ì •

```mermaid
graph LR
    subgraph "Workflow (ì •ì )"
        W1[Step 1] --> W2[Step 2]
        W2 --> W3[Step 3]
    end

    subgraph "Agent (ë™ì )"
        A1[LLM] -->|ë„êµ¬ í˜¸ì¶œ| A2[Tool]
        A2 --> A1
        A1 -->|ì™„ë£Œ| A3[END]
    end
```

## í•µì‹¬ ê°œë…

### Workflow vs Agent

| íŠ¹ì„± | Workflow | Agent |
|------|----------|-------|
| **ì‹¤í–‰ ê²½ë¡œ** | ë¯¸ë¦¬ ì •ì˜ë¨ | ë™ì ìœ¼ë¡œ ê²°ì • |
| **ì œì–´** | ê°œë°œìê°€ ì œì–´ | LLMì´ ì œì–´ |
| **ì˜ˆì¸¡ ê°€ëŠ¥ì„±** | ë†’ìŒ | ë‚®ìŒ |
| **ìœ ì—°ì„±** | ë‚®ìŒ | ë†’ìŒ |
| **ì‚¬ìš© ì‚¬ë¡€** | ETL, ë¬¸ì„œ ì²˜ë¦¬, ê²€ì¦ | ëŒ€í™”í˜• ì–´ì‹œìŠ¤í„´íŠ¸, ìë™í™” |

### LLM ì¦ê°• (Augmentation)

LLMì˜ ëŠ¥ë ¥ì„ í™•ì¥í•˜ëŠ” ë°©ë²•ë“¤:

```mermaid
graph TD
    LLM[ê¸°ë³¸ LLM] --> TC[Tool Calling<br>ë„êµ¬ í˜¸ì¶œ]
    LLM --> SO[Structured Output<br>êµ¬ì¡°í™”ëœ ì¶œë ¥]
    LLM --> MEM[Memory<br>ë©”ëª¨ë¦¬]
```

#### 1. Tool Calling (ë„êµ¬ í˜¸ì¶œ)

```python
from langchain.tools import tool

@tool
def multiply(a: int, b: int) -> int:
    """ë‘ ìˆ«ìë¥¼ ê³±í•©ë‹ˆë‹¤."""
    return a * b

# LLMì— ë„êµ¬ ë°”ì¸ë”©
llm_with_tools = llm.bind_tools([multiply])
```

#### 2. Structured Output (êµ¬ì¡°í™”ëœ ì¶œë ¥)

```python
from pydantic import BaseModel, Field

class SearchQuery(BaseModel):
    query: str = Field(description="ê²€ìƒ‰ ì¿¼ë¦¬")
    category: str = Field(description="ê²€ìƒ‰ ì¹´í…Œê³ ë¦¬")

# êµ¬ì¡°í™”ëœ ì¶œë ¥ ì„¤ì •
structured_llm = llm.with_structured_output(SearchQuery)
```

## ì‹¤ìŠµ: Prompt Chaining

**Prompt Chaining**ì€ ê° LLM í˜¸ì¶œì´ ì´ì „ í˜¸ì¶œì˜ ì¶œë ¥ì„ ì²˜ë¦¬í•˜ëŠ” íŒ¨í„´ì…ë‹ˆë‹¤. ì‘ì—…ì„ ë” ì‘ì€ ê²€ì¦ ê°€ëŠ¥í•œ ë‹¨ê³„ë¡œ ë¶„í•´í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.

### ì˜ˆì œ: ë†ë‹´ ìƒì„± íŒŒì´í”„ë¼ì¸

```mermaid
graph LR
    START((START)) --> GEN[ë†ë‹´ ìƒì„±]
    GEN -->|ì¢‹ìŒ| END((END))
    GEN -->|ê°œì„  í•„ìš”| IMP[ë†ë‹´ ê°œì„ ]
    IMP --> POL[ë§ˆë¬´ë¦¬]
    POL --> END
```

### ë‹¨ê³„ 1: State ì •ì˜

```python
# ğŸ“ src/part2_workflows/05_prompt_chaining.py
from typing import TypedDict
from langgraph.graph import StateGraph, START, END


class JokeState(TypedDict):
    """ë†ë‹´ ìƒì„± ì›Œí¬í”Œë¡œìš° ìƒíƒœ"""
    topic: str           # ì£¼ì œ
    joke: str            # ì´ˆê¸° ë†ë‹´
    improved_joke: str   # ê°œì„ ëœ ë†ë‹´
    final_joke: str      # ìµœì¢… ë†ë‹´
```

### ë‹¨ê³„ 2: Node í•¨ìˆ˜ ì‘ì„±

```python
def generate_joke(state: JokeState) -> dict:
    """ì²« ë²ˆì§¸ LLM í˜¸ì¶œ: ì´ˆê¸° ë†ë‹´ ìƒì„±"""
    response = llm.invoke(f"{state['topic']}ì— ëŒ€í•œ ì§§ì€ ë†ë‹´ì„ ë§Œë“¤ì–´ì¤˜")
    return {"joke": response.content}


def check_quality(state: JokeState) -> str:
    """ê²Œì´íŠ¸ í•¨ìˆ˜: ë†ë‹´ í’ˆì§ˆ í™•ì¸"""
    # ê°„ë‹¨í•œ ì²´í¬ - ì§ˆë¬¸ì´ë‚˜ ëŠë‚Œí‘œê°€ ìˆëŠ”ì§€
    if "?" in state["joke"] or "!" in state["joke"]:
        return "pass"
    return "improve"


def improve_joke(state: JokeState) -> dict:
    """ë‘ ë²ˆì§¸ LLM í˜¸ì¶œ: ë†ë‹´ ê°œì„ """
    response = llm.invoke(
        f"ì´ ë†ë‹´ì„ ë§ì¥ë‚œì„ ì¶”ê°€í•´ì„œ ë” ì¬ë¯¸ìˆê²Œ ë§Œë“¤ì–´ì¤˜: {state['joke']}"
    )
    return {"improved_joke": response.content}


def polish_joke(state: JokeState) -> dict:
    """ì„¸ ë²ˆì§¸ LLM í˜¸ì¶œ: ìµœì¢… ë§ˆë¬´ë¦¬"""
    joke_to_polish = state.get("improved_joke") or state["joke"]
    response = llm.invoke(
        f"ì´ ë†ë‹´ì— ë°˜ì „ì„ ì¶”ê°€í•´ì¤˜: {joke_to_polish}"
    )
    return {"final_joke": response.content}
```

### ë‹¨ê³„ 3: ê·¸ë˜í”„ êµ¬ì„±

```python
# ê·¸ë˜í”„ ìƒì„±
workflow = StateGraph(JokeState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("generate", generate_joke)
workflow.add_node("improve", improve_joke)
workflow.add_node("polish", polish_joke)

# ì—£ì§€ ì—°ê²°
workflow.add_edge(START, "generate")

# ì¡°ê±´ë¶€ ì—£ì§€: í’ˆì§ˆì— ë”°ë¼ ë¶„ê¸°
workflow.add_conditional_edges(
    "generate",
    check_quality,
    {
        "pass": END,           # í’ˆì§ˆ í†µê³¼ -> ì¢…ë£Œ
        "improve": "improve"   # ê°œì„  í•„ìš” -> improve ë…¸ë“œë¡œ
    }
)

workflow.add_edge("improve", "polish")
workflow.add_edge("polish", END)

# ì»´íŒŒì¼
app = workflow.compile()
```

### ë‹¨ê³„ 4: ì‹¤í–‰

```python
# ì‹¤í–‰
result = app.invoke({"topic": "í”„ë¡œê·¸ë˜ë¨¸"})

print(f"ì£¼ì œ: {result['topic']}")
print(f"\nì´ˆê¸° ë†ë‹´: {result['joke']}")

if result.get('improved_joke'):
    print(f"\nê°œì„ ëœ ë†ë‹´: {result['improved_joke']}")
    print(f"\nìµœì¢… ë†ë‹´: {result['final_joke']}")
else:
    print("\n(í’ˆì§ˆ í†µê³¼ - ê°œì„  ë¶ˆí•„ìš”)")
```

> ğŸ’¡ **ì „ì²´ ì½”ë“œ**: [src/part2_workflows/05_prompt_chaining.py](../../src/part2_workflows/05_prompt_chaining.py)

## ì‹¬í™”: LLM ì—†ì´ ì‹¤í–‰

ê°œë°œ ì¤‘ì—ëŠ” ë¹„ìš© ì ˆê°ì„ ìœ„í•´ LLM ì—†ì´ ê·¸ë˜í”„ ë¡œì§ë§Œ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
def generate_joke_mock(state: JokeState) -> dict:
    """Mock: ë†ë‹´ ìƒì„±"""
    return {"joke": f"[MOCK] {state['topic']}ì— ëŒ€í•œ ë†ë‹´ì…ë‹ˆë‹¤!"}


def improve_joke_mock(state: JokeState) -> dict:
    """Mock: ë†ë‹´ ê°œì„ """
    return {"improved_joke": f"[IMPROVED] {state['joke']}"}


# Mock ë…¸ë“œë¡œ í…ŒìŠ¤íŠ¸
test_graph = StateGraph(JokeState)
test_graph.add_node("generate", generate_joke_mock)
test_graph.add_node("improve", improve_joke_mock)
# ... ë‚˜ë¨¸ì§€ êµ¬ì„± ë™ì¼
```

## Prompt Chaining ì‚¬ìš© ì‚¬ë¡€

| ì‚¬ìš© ì‚¬ë¡€ | ì„¤ëª… |
|----------|------|
| **ë¬¸ì„œ ë²ˆì—­** | ë²ˆì—­ â†’ ê²€í†  â†’ ìˆ˜ì • |
| **ì½˜í…ì¸  ìƒì„±** | ì´ˆì•ˆ â†’ ê°œì„  â†’ ë§ˆë¬´ë¦¬ |
| **ì½”ë“œ ìƒì„±** | ìƒì„± â†’ ê²€ì¦ â†’ ë¦¬íŒ©í† ë§ |
| **ë°ì´í„° ì²˜ë¦¬** | ì¶”ì¶œ â†’ ë³€í™˜ â†’ ê²€ì¦ |

## ìš”ì•½

- **Workflow**: ì •ì  ì‹¤í–‰ ê²½ë¡œ, ì˜ˆì¸¡ ê°€ëŠ¥, ê²€ì¦ ì‘ì—…ì— ì í•©
- **Agent**: ë™ì  ì‹¤í–‰, LLMì´ ì œì–´, ë³µì¡í•œ ëŒ€í™”í˜• ì‘ì—…ì— ì í•©
- **LLM ì¦ê°•**: Tool Calling, Structured Outputìœ¼ë¡œ LLM ëŠ¥ë ¥ í™•ì¥
- **Prompt Chaining**: ìˆœì°¨ì  LLM í˜¸ì¶œë¡œ ì‘ì—…ì„ ë‹¨ê³„ë³„ë¡œ ì²˜ë¦¬
- **ì¡°ê±´ë¶€ ë¼ìš°íŒ…**: ì¤‘ê°„ ê²°ê³¼ì— ë”°ë¼ ë‹¤ìŒ ë‹¨ê³„ ê²°ì •

## ë‹¤ìŒ ë‹¨ê³„

ë‹¤ìŒ ì¥ì—ì„œëŠ” **ì¡°ê±´ë¶€ ë¼ìš°íŒ…**ì„ ë” ê¹Šì´ í•™ìŠµí•©ë‹ˆë‹¤. Structured Outputì„ í™œìš©í•œ ë¼ìš°íŒ…ê³¼ Command ê°ì²´ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.

ğŸ‘‰ [Chapter 6: ì¡°ê±´ë¶€ ë¼ìš°íŒ…](./06-conditional-routing.md)

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [Workflows and Agents (ê³µì‹ ì˜¨ë¼ì¸)](https://docs.langchain.com/oss/python/langgraph/workflows-agents) - ì›Œí¬í”Œë¡œìš°ì™€ ì—ì´ì „íŠ¸ ê°€ì´ë“œ
- [Workflows and Agents (ë¡œì»¬ ë¬¸ì„œ)](../../official_docs/07-workflows-agents.md) - ë¡œì»¬ ì°¸ì¡°ìš©

### ì‹¤ìŠµ ì½”ë“œ
- [ì „ì²´ ì†ŒìŠ¤](../../src/part2_workflows/05_prompt_chaining.py) - ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ì²´ ì½”ë“œ
- [ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜](../../src/utils/) - ê³µí†µ í—¬í¼ í•¨ìˆ˜

### ê´€ë ¨ ì±•í„°
- [ì´ì „: Chapter 4 - State ê´€ë¦¬ ì‹¬í™”](../Part1-Foundation/04-state-management.md)
- [ë‹¤ìŒ: Chapter 6 - ì¡°ê±´ë¶€ ë¼ìš°íŒ…](./06-conditional-routing.md)
