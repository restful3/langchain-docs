# Chapter 20: ë°°í¬ ì¤€ë¹„

> ğŸ“Œ **í•™ìŠµ ëª©í‘œ**: ì´ ì¥ì„ ë§ˆì¹˜ë©´ LangGraph ì• í”Œë¦¬ì¼€ì´ì…˜ì„ í”„ë¡œë•ì…˜ í™˜ê²½ì— ë°°í¬í•˜ê¸° ìœ„í•œ êµ¬ì¡°, ì„¤ì •, ëª¨ë‹ˆí„°ë§ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ê°œìš”

**ë°°í¬ ì¤€ë¹„**ëŠ” ê°œë°œëœ LangGraph ì• í”Œë¦¬ì¼€ì´ì…˜ì„ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ìš´ì˜í•˜ê¸° ìœ„í•œ ëª¨ë“  ì¤€ë¹„ ê³¼ì •ì…ë‹ˆë‹¤. ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¡°, í™˜ê²½ ì„¤ì •, ëª¨ë‹ˆí„°ë§, ìŠ¤ì¼€ì¼ë§ ë“±ì„ ë‹¤ë£¹ë‹ˆë‹¤.

```mermaid
graph TD
    subgraph "ê°œë°œ"
        DEV[ë¡œì»¬ ê°œë°œ] --> TEST[í…ŒìŠ¤íŠ¸]
    end

    subgraph "ë°°í¬"
        TEST --> BUILD[ë¹Œë“œ]
        BUILD --> DEPLOY[ë°°í¬]
    end

    subgraph "ìš´ì˜"
        DEPLOY --> MONITOR[ëª¨ë‹ˆí„°ë§]
        MONITOR --> SCALE[ìŠ¤ì¼€ì¼ë§]
        SCALE --> MAINTAIN[ìœ ì§€ë³´ìˆ˜]
    end
```

## í•µì‹¬ ê°œë…

### í”„ë¡œë•ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

| í•­ëª© | ì„¤ëª… | ì¤‘ìš”ë„ |
|-----|------|--------|
| **ì—ëŸ¬ í•¸ë“¤ë§** | ì˜ˆì™¸ ì²˜ë¦¬ ë° ë³µêµ¬ | í•„ìˆ˜ |
| **ë¡œê¹…** | êµ¬ì¡°í™”ëœ ë¡œê¹… | í•„ìˆ˜ |
| **ëª¨ë‹ˆí„°ë§** | ë©”íŠ¸ë¦­ ìˆ˜ì§‘ | í•„ìˆ˜ |
| **ë³´ì•ˆ** | ì¸ì¦/ì¸ê°€ | í•„ìˆ˜ |
| **ìŠ¤ì¼€ì¼ë§** | ìˆ˜í‰/ìˆ˜ì§ í™•ì¥ | ê¶Œì¥ |
| **ë°±ì—…** | ìƒíƒœ ë°±ì—… | ê¶Œì¥ |

## ì‹¤ìŠµ 1: í”„ë¡œì íŠ¸ êµ¬ì¡°

```
# ğŸ“ ê¶Œì¥ í”„ë¡œì íŠ¸ êµ¬ì¡°
my_langgraph_app/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py              # ì• í”Œë¦¬ì¼€ì´ì…˜ ì§„ì…ì 
â”‚   â”œâ”€â”€ graphs/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ main_graph.py   # ê·¸ë˜í”„ ì •ì˜
â”‚   â”œâ”€â”€ nodes/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ processors.py   # ë…¸ë“œ í•¨ìˆ˜ë“¤
â”‚   â”œâ”€â”€ state/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ schemas.py      # State ì •ì˜
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ external.py     # ì™¸ë¶€ ë„êµ¬ ì—°ë™
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.py         # ì„¤ì • ê´€ë¦¬
â”‚   â””â”€â”€ logging.yaml        # ë¡œê¹… ì„¤ì •
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_graphs.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env.example
```

```python
# ğŸ“ src/part5_advanced/20_deployment_ready.py
# config/settings.py
from pydantic_settings import BaseSettings
from typing import Optional


class Settings(BaseSettings):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •"""
    # í™˜ê²½
    environment: str = "development"
    debug: bool = False

    # LLM ì„¤ì •
    anthropic_api_key: str
    model_name: str = "claude-sonnet-4-5-20250929"

    # ë°ì´í„°ë² ì´ìŠ¤
    database_url: str = "sqlite:///langgraph.db"

    # Redis (ìºì‹±/í)
    redis_url: Optional[str] = None

    # ê´€ì¸¡ì„±
    langsmith_api_key: Optional[str] = None
    langsmith_project: str = "langgraph-production"

    class Config:
        env_file = ".env"


settings = Settings()
```

> ğŸ’¡ **ì „ì²´ ì½”ë“œ**: [src/part5_advanced/20_deployment_ready.py](../../src/part5_advanced/20_deployment_ready.py)

## ì‹¤ìŠµ 2: ë¡œê¹… ì„¤ì •

```python
# config/logging.yaml
import logging
import logging.config
import yaml


LOGGING_CONFIG = """
version: 1
disable_existing_loggers: false

formatters:
  standard:
    format: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
  json:
    class: pythonjsonlogger.jsonlogger.JsonFormatter
    format: '%(asctime)s %(name)s %(levelname)s %(message)s'

handlers:
  console:
    class: logging.StreamHandler
    level: DEBUG
    formatter: standard
    stream: ext://sys.stdout
  file:
    class: logging.handlers.RotatingFileHandler
    level: INFO
    formatter: json
    filename: logs/app.log
    maxBytes: 10485760  # 10MB
    backupCount: 5

loggers:
  langgraph:
    level: INFO
    handlers: [console, file]
    propagate: false

  app:
    level: DEBUG
    handlers: [console, file]
    propagate: false

root:
  level: WARNING
  handlers: [console]
"""


def setup_logging():
    """ë¡œê¹… ì„¤ì • ì´ˆê¸°í™”"""
    config = yaml.safe_load(LOGGING_CONFIG)
    logging.config.dictConfig(config)


# ì‚¬ìš©
setup_logging()
logger = logging.getLogger("app")
logger.info("ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘")
```

## ì‹¤ìŠµ 3: ì—ëŸ¬ í•¸ë“¤ë§

```python
from typing import TypedDict, Optional
from langgraph.graph import StateGraph, START, END
import logging


logger = logging.getLogger("app")


class RobustState(TypedDict):
    """ê²¬ê³ í•œ State"""
    input: str
    result: Optional[str]
    error: Optional[str]
    retry_count: int


def create_robust_graph():
    """ê²¬ê³ í•œ ì—ëŸ¬ í•¸ë“¤ë§ì´ í¬í•¨ëœ ê·¸ë˜í”„"""

    def process_with_retry(state: RobustState) -> RobustState:
        """ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ì²˜ë¦¬"""
        max_retries = 3
        retry_count = state.get("retry_count", 0)

        try:
            # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
            result = perform_operation(state["input"])
            logger.info(f"ì²˜ë¦¬ ì„±ê³µ: {state['input']}")
            return {"result": result, "error": None}

        except TransientError as e:
            # ì¼ì‹œì  ì˜¤ë¥˜ - ì¬ì‹œë„ ê°€ëŠ¥
            if retry_count < max_retries:
                logger.warning(f"ì¼ì‹œì  ì˜¤ë¥˜, ì¬ì‹œë„ {retry_count + 1}/{max_retries}")
                return {"retry_count": retry_count + 1}
            else:
                logger.error(f"ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼: {e}")
                return {"error": str(e)}

        except PermanentError as e:
            # ì˜êµ¬ ì˜¤ë¥˜ - ì¬ì‹œë„ ë¶ˆê°€
            logger.error(f"ì˜êµ¬ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}

        except Exception as e:
            # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜
            logger.exception(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return {"error": f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {str(e)}"}

    def route_after_process(state: RobustState) -> str:
        """ì²˜ë¦¬ í›„ ë¼ìš°íŒ…"""
        if state.get("error"):
            return "handle_error"
        elif state.get("retry_count", 0) > 0 and not state.get("result"):
            return "process"  # ì¬ì‹œë„
        return "finalize"

    def handle_error(state: RobustState) -> RobustState:
        """ì—ëŸ¬ ì²˜ë¦¬"""
        # ì•Œë¦¼, ë¡œê¹…, í´ë°± ë“±
        return {"result": f"ì—ëŸ¬ ë°œìƒ: {state['error']}"}

    def finalize(state: RobustState) -> RobustState:
        """ì™„ë£Œ ì²˜ë¦¬"""
        return {"result": f"ì™„ë£Œ: {state['result']}"}

    graph = StateGraph(RobustState)
    graph.add_node("process", process_with_retry)
    graph.add_node("handle_error", handle_error)
    graph.add_node("finalize", finalize)

    graph.add_edge(START, "process")
    graph.add_conditional_edges("process", route_after_process)
    graph.add_edge("handle_error", END)
    graph.add_edge("finalize", END)

    return graph.compile()
```

## ì‹¤ìŠµ 4: ëª¨ë‹ˆí„°ë§ ë° ë©”íŠ¸ë¦­

```python
from dataclasses import dataclass
from datetime import datetime
from typing import Dict, Any
import time


@dataclass
class Metrics:
    """ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
    request_count: int = 0
    success_count: int = 0
    error_count: int = 0
    total_duration_ms: float = 0.0

    def record_request(self, success: bool, duration_ms: float):
        """ìš”ì²­ ê¸°ë¡"""
        self.request_count += 1
        self.total_duration_ms += duration_ms
        if success:
            self.success_count += 1
        else:
            self.error_count += 1

    @property
    def avg_duration_ms(self) -> float:
        """í‰ê·  ì‘ë‹µ ì‹œê°„"""
        if self.request_count == 0:
            return 0.0
        return self.total_duration_ms / self.request_count

    @property
    def success_rate(self) -> float:
        """ì„±ê³µë¥ """
        if self.request_count == 0:
            return 0.0
        return self.success_count / self.request_count * 100

    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ ë³€í™˜"""
        return {
            "request_count": self.request_count,
            "success_count": self.success_count,
            "error_count": self.error_count,
            "avg_duration_ms": round(self.avg_duration_ms, 2),
            "success_rate": round(self.success_rate, 2)
        }


# ì „ì—­ ë©”íŠ¸ë¦­ ì¸ìŠ¤í„´ìŠ¤
metrics = Metrics()


def with_metrics(func):
    """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë°ì½”ë ˆì´í„°"""
    def wrapper(*args, **kwargs):
        start = time.time()
        success = True
        try:
            result = func(*args, **kwargs)
            return result
        except Exception as e:
            success = False
            raise
        finally:
            duration_ms = (time.time() - start) * 1000
            metrics.record_request(success, duration_ms)
    return wrapper


# ì‚¬ìš©
@with_metrics
def process_request(data: dict):
    """ìš”ì²­ ì²˜ë¦¬"""
    # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
    pass
```

## ì‹¤ìŠµ 5: LangSmith í†µí•©

```python
import os
from langsmith import Client


def setup_langsmith():
    """LangSmith ê´€ì¸¡ì„± ì„¤ì •"""
    os.environ["LANGCHAIN_TRACING_V2"] = "true"
    os.environ["LANGCHAIN_PROJECT"] = settings.langsmith_project
    os.environ["LANGCHAIN_API_KEY"] = settings.langsmith_api_key


# LangSmith í´ë¼ì´ì–¸íŠ¸
client = Client()


def get_recent_runs(limit: int = 10):
    """ìµœê·¼ ì‹¤í–‰ ì¡°íšŒ"""
    runs = client.list_runs(
        project_name=settings.langsmith_project,
        limit=limit
    )
    return list(runs)


def analyze_performance():
    """ì„±ëŠ¥ ë¶„ì„"""
    runs = get_recent_runs(100)

    total_latency = 0
    error_count = 0

    for run in runs:
        if run.end_time and run.start_time:
            latency = (run.end_time - run.start_time).total_seconds()
            total_latency += latency
        if run.error:
            error_count += 1

    avg_latency = total_latency / len(runs) if runs else 0
    error_rate = error_count / len(runs) * 100 if runs else 0

    return {
        "avg_latency_seconds": round(avg_latency, 3),
        "error_rate_percent": round(error_rate, 2),
        "total_runs": len(runs)
    }
```

## ì‹¤ìŠµ 6: Docker ë°°í¬

```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

# ì˜ì¡´ì„± ì„¤ì¹˜
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì†ŒìŠ¤ ë³µì‚¬
COPY src/ ./src/
COPY config/ ./config/

# í™˜ê²½ ë³€ìˆ˜
ENV PYTHONPATH=/app
ENV ENVIRONMENT=production

# ë¡œê·¸ ë””ë ‰í† ë¦¬
RUN mkdir -p /app/logs

# ë¹„root ì‚¬ìš©ì
RUN useradd -m appuser && chown -R appuser:appuser /app
USER appuser

# ì‹¤í–‰
CMD ["python", "-m", "src.app"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  app:
    build: .
    ports:
      - "8000:8000"
    environment:
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - DATABASE_URL=postgresql://postgres:postgres@db:5432/langgraph
      - REDIS_URL=redis://redis:6379
    depends_on:
      - db
      - redis
    volumes:
      - ./logs:/app/logs
    restart: unless-stopped

  db:
    image: postgres:15
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=langgraph
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    restart: unless-stopped

volumes:
  postgres_data:
```

## ì‹¤ìŠµ 7: í—¬ìŠ¤ ì²´í¬ API

```python
from fastapi import FastAPI, HTTPException
from datetime import datetime


app = FastAPI()


@app.get("/health")
async def health_check():
    """ê¸°ë³¸ í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat()
    }


@app.get("/health/detailed")
async def detailed_health_check():
    """ìƒì„¸ í—¬ìŠ¤ ì²´í¬"""
    checks = {}

    # ë°ì´í„°ë² ì´ìŠ¤ ì²´í¬
    try:
        # db.execute("SELECT 1")
        checks["database"] = "healthy"
    except Exception as e:
        checks["database"] = f"unhealthy: {str(e)}"

    # Redis ì²´í¬
    try:
        # redis.ping()
        checks["redis"] = "healthy"
    except Exception as e:
        checks["redis"] = f"unhealthy: {str(e)}"

    # LLM API ì²´í¬
    try:
        # llm.invoke("test")
        checks["llm_api"] = "healthy"
    except Exception as e:
        checks["llm_api"] = f"unhealthy: {str(e)}"

    # ì „ì²´ ìƒíƒœ ê²°ì •
    all_healthy = all(v == "healthy" for v in checks.values())

    response = {
        "status": "healthy" if all_healthy else "degraded",
        "checks": checks,
        "metrics": metrics.to_dict(),
        "timestamp": datetime.now().isoformat()
    }

    if not all_healthy:
        raise HTTPException(status_code=503, detail=response)

    return response


@app.get("/metrics")
async def get_metrics():
    """ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸"""
    return metrics.to_dict()
```

## ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸

```markdown
## í”„ë¡œë•ì…˜ ë°°í¬ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

### í•„ìˆ˜
- [ ] í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (.env)
- [ ] API í‚¤ ë³´ì•ˆ (ì‹œí¬ë¦¿ ê´€ë¦¬)
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ êµ¬í˜„
- [ ] ë¡œê¹… ì„¤ì •
- [ ] í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •

### ê¶Œì¥
- [ ] LangSmith í†µí•©
- [ ] ë©”íŠ¸ë¦­ ìˆ˜ì§‘
- [ ] ì•Œë¦¼ ì„¤ì • (Slack, PagerDuty ë“±)
- [ ] ë°±ì—… ì •ì±…
- [ ] ìŠ¤ì¼€ì¼ë§ ì„¤ì •
- [ ] CI/CD íŒŒì´í”„ë¼ì¸

### ë¬¸ì„œ
- [ ] API ë¬¸ì„œ
- [ ] ìš´ì˜ ê°€ì´ë“œ
- [ ] ì¥ì•  ëŒ€ì‘ ë§¤ë‰´ì–¼
```

## ìš”ì•½

- **í”„ë¡œì íŠ¸ êµ¬ì¡°**: ëª¨ë“ˆí™”ëœ ë””ë ‰í† ë¦¬ êµ¬ì„±
- **ì„¤ì • ê´€ë¦¬**: í™˜ê²½ë³„ ì„¤ì • ë¶„ë¦¬
- **ë¡œê¹…**: êµ¬ì¡°í™”ëœ ë¡œê¹… ì‹œìŠ¤í…œ
- **ì—ëŸ¬ í•¸ë“¤ë§**: ì¬ì‹œë„, í´ë°±, ë³µêµ¬
- **ëª¨ë‹ˆí„°ë§**: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ê´€ì¸¡ì„±
- **ë°°í¬**: Docker ì»¨í…Œì´ë„ˆí™”

## ë§ˆë¬´ë¦¬

ì´ê²ƒìœ¼ë¡œ LangGraph íŠœí† ë¦¬ì–¼ì˜ ëª¨ë“  í•µì‹¬ ë‚´ìš©ì„ ë‹¤ë£¨ì—ˆìŠµë‹ˆë‹¤. ë¶€ë¡ì—ì„œëŠ” API ë ˆí¼ëŸ°ìŠ¤, ë¬¸ì œ í•´ê²°, ëª¨ë²” ì‚¬ë¡€ë¥¼ ì¶”ê°€ë¡œ ì œê³µí•©ë‹ˆë‹¤.

ğŸ‘‰ [Appendix A: API ë ˆí¼ëŸ°ìŠ¤](../Appendix/A-api-reference.md)

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [Application Structure (ê³µì‹ ì˜¨ë¼ì¸)](https://langchain-ai.github.io/langgraph/concepts/application_structure/) - ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¡°
- [LangGraph Cloud (ê³µì‹ ì˜¨ë¼ì¸)](https://langchain-ai.github.io/langgraph/concepts/langgraph_cloud/) - í´ë¼ìš°ë“œ ë°°í¬

### ì‹¤ìŠµ ì½”ë“œ
- [ì „ì²´ ì†ŒìŠ¤](../../src/part5_advanced/20_deployment_ready.py) - ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ì²´ ì½”ë“œ

### ê´€ë ¨ ì±•í„°
- [ì´ì „: Chapter 19 - Durable Execution](./19-durable-execution.md)
- [ë‹¤ìŒ: Appendix A - API ë ˆí¼ëŸ°ìŠ¤](../Appendix/A-api-reference.md)
