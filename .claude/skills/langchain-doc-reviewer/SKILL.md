---
name: langchain-doc-reviewer
description: LangChain AI Agent Master 교안의 파트별 리뷰를 자동 생성하는 스킬. 교안(docs/partXX_*.md)과 예제 코드(src/partXX_*/)를 분석하여 문서 갈무리, 오류/수정 피드백, 개선 제안, 리뷰어 종합 소견을 포함하는 리뷰 마크다운을 생성한다. 사용자가 "파트 리뷰", "교안 리뷰", "review part", "리뷰 작성" 등을 요청할 때 사용한다.
---

# LangChain 교안 리뷰어

LangChain AI Agent Master 교안 프로젝트의 파트별 교안과 예제 코드를 체계적으로 분석하여, 재현 가능한 품질의 리뷰 마크다운 파일을 생성한다.

## When to Use

- 사용자가 특정 파트의 교안 리뷰를 요청할 때
- "Part 03 리뷰 작성해줘", "파트 5 교안 리뷰", "review part 8" 등의 요청
- 교안이 수정된 후 리뷰를 다시 생성해야 할 때
- 프로젝트 루트가 `langchain-docs/langchain/` 이고, `docs/`, `src/`, `reviews/` 디렉토리가 존재하는 환경

## Step 1: 입력 확인

사용자로부터 다음 2가지 정보를 확인한다. 명시되지 않은 경우 질문한다.

1. **파트 번호** (02~10, 정수 또는 zero-padded 문자열)
2. **리뷰어 이름** (한글 또는 영문, 파일명에 사용됨)

Part 01은 리뷰 대상이 아니다 (소개 파트로 reviews 디렉토리 없음). 요청 시 안내 후 거부한다.

### 파트 매핑 테이블

| Part | Slug | 교안 제목 |
|------|------|----------|
| 02 | fundamentals | LangChain 핵심 구성 요소 |
| 03 | first_agent | 첫 번째 Agent 만들기 |
| 04 | memory | 메모리 시스템 |
| 05 | middleware | 미들웨어 |
| 06 | context | 컨텍스트와 런타임 |
| 07 | multi_agent | 멀티에이전트 시스템 |
| 08 | rag_mcp | RAG와 MCP |
| 09 | production | 프로덕션 |
| 10 | deployment | 배포와 관측성 |

파트 번호로부터 아래 경로들을 도출한다:

- 교안: `docs/part{NN}_{slug}.md`
- 소스: `src/part{NN}_{slug}/`
- 이전 파트 교안: `docs/part{NN-1}_{prev_slug}.md` (Part 02는 part01_introduction.md)
- 다음 파트 교안: `docs/part{NN+1}_{next_slug}.md` (Part 10은 없음)
- 출력: `reviews/part{NN}_{slug}/review_{이름}.md`

## Step 2: 파일 읽기

**병렬 탐색 에이전트 3개** 를 동시에 실행하여 컨텍스트를 수집한다.

### Agent 1: 교안 분석

대상 교안 파일을 전체 읽고 다음을 파싱한다:

- 문서 제목 (첫 번째 `# ` 헤딩)
- 메타데이터 (학습 시간, 난이도, 공식 문서 링크)
- 모든 섹션 헤딩과 줄 범위
- 소스 코드 참조 (예: `> 예제 코드: [파일명](경로) 라인 X-Y`)
- 실습 과제 수와 내용
- 학습 목표 체크리스트
- 코드 블록 내 import 문, API 호출, 모델명

### Agent 2: 소스 코드 분석

`src/part{NN}_{slug}/` 디렉토리의 **모든 .py 파일** 을 읽고 다음을 분석한다:

- 각 파일의 함수 목록과 줄 범위 (특히 `def example_*` 패턴)
- import 문 검사 (deprecated API, 잘못된 경로)
- Pydantic v1 vs v2 호환성 (`validator` vs `field_validator`, `.schema()` vs `.model_json_schema()`)
- 보안 이슈 (`eval()`, `exec()`, SQL injection 등)
- `solutions/` 디렉토리의 파일 존재 여부와 줄 수

### Agent 3: 컨텍스트 수집

다음 파일들을 읽는다:

- 이전 파트 교안 (헤딩과 "다음 단계" 섹션 위주)
- 다음 파트 교안 (헤딩과 "개요"/"학습 목표" 섹션 위주)
- `reviews/TEMPLATE.md` (출력 포맷 확인)
- `reviews/README.md` (리뷰 가이드라인 확인)

## Step 3: 분석 수행

수집된 데이터를 기반으로 7단계 분석을 수행한다.

### 3.1 문서 구조 파싱

- 전체 줄 수, 난이도 표기, 실습 과제 수 기록
- 모든 `##` 레벨 이상 섹션의 제목과 줄 범위 추출
- 각 섹션의 핵심 주제를 2-3문장으로 요약

### 3.2 소스 코드 매핑

각 `.py` 파일이 교안의 어떤 섹션에 대응하는지 매핑 테이블을 작성한다.

- 파일명의 번호(`01_`, `02_` 등)와 교안 섹션 번호가 항상 일치하지는 않으므로, **내용 기반** 으로 매핑한다
- 대응하는 소스 파일이 없는 교안 섹션을 식별한다 (갭 분석)

### 3.3 라인 참조 검증

교안 내 `라인 X-Y` 형식의 참조를 모두 찾아서, 해당 소스 파일의 실제 줄 번호와 대조한다.

- 교안에서 `grep -n '라인'` 으로 모든 라인 참조를 추출
- 참조된 소스 파일을 열어 실제 함수/예제 위치를 확인
- 불일치 항목을 `오류/수정` 으로 기록

### 3.4 파일명 참조 검증

교안 내 소스 파일명 참조가 실제 올바른 파일을 가리키는지 확인한다.

- 예: 교안이 `03_tools_basic.py`를 참조하지만 해당 내용이 `04_tools_advanced.py`에 있는 경우

### 3.5 API/코드 정확성 검사

교안과 소스 코드 모두에서 다음을 점검한다:

- **import 경로**: `from langchain.agents import create_agent` vs `from langgraph.prebuilt import create_react_agent` 등
- **deprecated API**: Pydantic v1 문법(`validator`, `.schema()`), LangChain legacy API
- **모델명 유효성**: `claude-sonnet-4-5-20250929`, `gpt-4.1` 등의 실제 존재 여부
- **보안 이슈**: `eval()`, 하드코딩된 credentials 등

### 3.6 학습 흐름 분석

- 섹션 간 난이도 progression이 자연스러운지 평가
- 섹션 전환부에 브릿지 텍스트가 있는지 확인
- 초급 표기 대비 실제 체감 난이도를 섹션별로 평가

### 3.7 파트 간 연결성 분석

- 이전 파트의 "다음 단계" 섹션이 현재 파트 내용을 적절히 예고하는지
- 현재 파트가 다음 파트에서 필요한 개념을 충분히 다루는지
- Part 02의 경우: Part 01(개념) -> Part 02(구성 요소) -> Part 03(Agent 구축) 전환 분석
- Part 10의 경우: 다음 파트가 없으므로 "다음 단계" 분석만 수행

## Step 4: 리뷰 파일 생성

아래 구조로 마크다운 파일을 작성한다. `references/review_example.md`를 참고하여 동일한 상세도와 톤을 유지한다.

### 출력 경로

`reviews/part{NN}_{slug}/review_{이름}.md`

기존 파일이 있으면 덮어쓰기 전에 사용자에게 확인한다.

### 출력 구조

```markdown
# Part {N}: {교안 제목} 리뷰 - {리뷰어 이름}

> 작성일: YYYY-MM-DD

## 리뷰 범위

- [x] 교안: `docs/part{NN}_{slug}.md`
- [x] 예제 코드: `src/part{NN}_{slug}/`

---

## 문서 갈무리 (전체 요약)

### 문서 개요

분량, 난이도, 소스 파일 수, 실습 과제 수 등 교안의 기본 정보를 정리한다.

### 섹션별 핵심 내용 요약

각 섹션의 제목, 줄 범위, 핵심 내용을 2-3문장으로 요약한다.
형식: **섹션 N. {제목}** (L{시작}~L{끝})

### 소스 코드 매핑

| 소스 파일 | 라인 수 | 대응 교안 섹션 |
|-----------|------:|-------------|
| `01_xxx.py` | NNN | 섹션 N (제목) |
| ...       |       |             |

대응 파일이 없는 섹션이 있으면 주석으로 표기한다.

### 학습 흐름 분석

전체적인 학습 접근 방식(Bottom-up, Top-down 등)을 서술하고, 흐름도를 텍스트로 표현한다.

---

## 교안 피드백 (`docs/part{NN}_{slug}.md`)

### 오류/수정

반드시 고쳐야 할 문제를 체크리스트로 나열한다.
형식: - [ ] L{줄번호}: {문제 설명} -> {수정 방향}

### 개선 제안

논의 후 결정할 사항을 나열한다.
형식: - [ ] 섹션 N / L{줄번호}: {제안 내용}

---

## 예제 코드 피드백 (`src/part{NN}_{slug}/`)

### 오류/수정

형식: - [ ] `{파일명}` L{줄번호}: {문제 설명} -> {수정 방향}

### 개선 제안

형식: - [ ] `{파일명}` 또는 전반: {제안 내용}

---

## 기타 의견 (리뷰어 종합 소견)

### 강점

번호 매긴 리스트로 교안의 잘된 점을 나열한다.

### 구조적 제안

섹션 재배치, 분량 조절, 내용 분리 등 구조적 개선안을 제시한다.

### 난이도 평가

섹션별 체감 난이도를 표로 정리하고, 표기 난이도와의 차이를 분석한다.

| 섹션 | 체감 난이도 | 비고 |
|------|-----------|------|
| ... | ... | ... |

### Part {N-1} -> {N} -> {N+1} 연결성

이전/다음 파트와의 전환이 자연스러운지 분석하고, 개선점을 제안한다.
```

## Step 5: 검증

리뷰 파일 작성 후 다음을 확인한다:

1. **마크다운 구조**: 모든 필수 섹션(리뷰 범위, 교안 피드백, 예제 코드 피드백, 기타 의견)이 포함되었는지
2. **CJK bold 규칙**: `**...(...)** ` 패턴에서 닫는 `**` 뒤에 한글이 바로 오면 공백이 있는지 확인. `grep -Pn '\*\*[^*]*[)":]\*\*[가-힣]'` 로 검사
3. **코드 블록 언어 식별자**: 모든 코드 블록에 언어 식별자(`python`, `bash`, `markdown` 등)가 있는지
4. **파일 존재 확인**: 출력 파일이 올바른 경로에 생성되었는지

## Edge Cases

- **Part 01 요청 시**: "Part 01은 소개 파트로 리뷰 대상이 아닙니다. Part 02~10 중에서 선택해주세요." 안내
- **Part 10**: 다음 파트가 없으므로 연결성 분석에서 "다음 파트" 부분을 생략하고, 대신 전체 교안의 마무리로서의 완성도를 평가
- **Part 02**: 이전 파트(01)는 리뷰 대상이 아니지만 교안은 존재하므로, 연결성 분석에서 Part 01 교안을 참조
- **기존 파일 존재 시**: 덮어쓰기 전 사용자에게 확인
- **교안 미발견**: 파트 번호에 해당하는 파일이 없으면 에러 메시지 출력

## Resources

### references/

- `review_example.md` - Part 02 완성 리뷰 예시. 출력의 상세도, 톤, 구조의 기준점으로 사용한다. 리뷰 작성 시 이 파일을 읽어 동일한 품질을 유지한다.
