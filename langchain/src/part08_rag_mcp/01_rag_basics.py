"""
================================================================================
LangChain AI Agent ë§ˆìŠ¤í„° êµì•ˆ
Part 8: RAG & MCP
================================================================================

íŒŒì¼ëª…: 01_rag_basics.py
ë‚œì´ë„: â­â­â­ (ì¤‘ê¸‰)
ì˜ˆìƒ ì‹œê°„: 30ë¶„

ğŸ“š í•™ìŠµ ëª©í‘œ:
  - RAG (Retrieval Augmented Generation)ì˜ ê°œë… ì´í•´
  - Vector Storeì˜ ì‘ë™ ì›ë¦¬ ì´í•´
  - ìœ ì‚¬ë„ ê²€ìƒ‰ êµ¬í˜„
  - Top-k retrieval ì‚¬ìš©
  - ì‹¤ì „ FAQ ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬ì¶•

ğŸ“– ê³µì‹ ë¬¸ì„œ:
  â€¢ Retrieval: /official/28-retrieval.md
  â€¢ Vector Stores: https://python.langchain.com/docs/concepts/vectorstores/

ğŸ“„ êµì•ˆ ë¬¸ì„œ:
  â€¢ Part 8: /docs/part08_rag_mcp.md

ğŸ”§ í•„ìš”í•œ íŒ¨í‚¤ì§€:
  pip install langchain langchain-openai langchain-community faiss-cpu python-dotenv

ğŸš€ ì‹¤í–‰ ë°©ë²•:
  python 01_rag_basics.py

================================================================================
"""

# ============================================================================
# Imports
# ============================================================================

import os
from dotenv import load_dotenv
from langchain.agents import create_agent
from langchain.tools import tool
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.schema import Document

# ============================================================================
# í™˜ê²½ ì„¤ì •
# ============================================================================

load_dotenv()

if not os.getenv("OPENAI_API_KEY"):
    print("âŒ ì˜¤ë¥˜: OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("ğŸ“ .env íŒŒì¼ì„ í™•ì¸í•˜ê³  API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
    exit(1)

# ============================================================================
# ì˜ˆì œ 1: RAGê°€ í•„ìš”í•œ ì´ìœ  (Before & After)
# ============================================================================

def example_1_why_rag():
    """RAGê°€ ì—†ì„ ë•Œì™€ ìˆì„ ë•Œì˜ ì°¨ì´"""
    print("=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 1: RAGê°€ í•„ìš”í•œ ì´ìœ ")
    print("=" * 70)

    print("""
ğŸ’¡ RAG (Retrieval Augmented Generation)ë€?
   - LLMì˜ ìƒì„± ëŠ¥ë ¥ + ì™¸ë¶€ ì§€ì‹ ê²€ìƒ‰ì„ ê²°í•©
   - LLMì˜ í•œê³„ ê·¹ë³µ:
     1. ìœ í•œí•œ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°
     2. ì •ì ì¸ ì§€ì‹ (í•™ìŠµ ì‹œì  ê³ ì •)

âŒ RAG ì—†ì´:
   - íšŒì‚¬ ë‚´ë¶€ ì •ë³´ ëª¨ë¦„
   - ìµœì‹  ë°ì´í„° ì—†ìŒ
   - ì˜ëª»ëœ ì •ë³´ ìƒì„± ê°€ëŠ¥

âœ… RAG ì‚¬ìš©:
   - ì‹¤ì œ ë¬¸ì„œì—ì„œ ê²€ìƒ‰
   - ì •í™•í•œ ì •ë³´ ì œê³µ
   - ì¶œì²˜ ì¶”ì  ê°€ëŠ¥
    """)

    # ì‹œë‚˜ë¦¬ì˜¤: íšŒì‚¬ ì¬ë¬´ ì •ë³´ ì¡°íšŒ
    company_data = [
        "2024ë…„ Q1 ë§¤ì¶œ: $4.2M, ìˆœì´ìµ: $0.8M",
        "2024ë…„ Q2 ë§¤ì¶œ: $4.8M, ìˆœì´ìµ: $1.1M",
        "2024ë…„ Q3 ë§¤ì¶œ: $5.2M, ìˆœì´ìµ: $1.3M",
        "2024ë…„ ì—°ê°„ ëª©í‘œ: ë§¤ì¶œ $20M, ìˆœì´ìµ $5M",
        "2024ë…„ ì‹ ê·œ ê³ ê°: Q1 125ëª…, Q2 180ëª…, Q3 210ëª…"
    ]

    print("\nğŸ“Š íšŒì‚¬ ë°ì´í„°:")
    for data in company_data:
        print(f"  â€¢ {data}")

    # RAG ì—†ì´ (LLMë§Œ ì‚¬ìš©)
    print("\n" + "=" * 70)
    print("âŒ RAG ì—†ì´ - LLMë§Œ ì‚¬ìš©")
    print("=" * 70)

    agent_without_rag = create_agent(
        model="gpt-4o-mini",
        tools=[],  # ë„êµ¬ ì—†ìŒ
    )

    response = agent_without_rag.invoke({
        "messages": [{"role": "user", "content": "ìš°ë¦¬ íšŒì‚¬ì˜ 2024ë…„ Q3 ë§¤ì¶œì€ ì–¼ë§ˆì¸ê°€ìš”?"}]
    })

    print(f"\nğŸ¤– Agent ë‹µë³€ (RAG ì—†ìŒ):")
    print(f"{response['messages'][-1].content}")
    print("\nâš ï¸  ê²°ê³¼: LLMì€ íšŒì‚¬ ë‚´ë¶€ ë°ì´í„°ë¥¼ ëª¨ë¥´ë¯€ë¡œ ì •í™•í•œ ë‹µë³€ ë¶ˆê°€")

    # RAG ì‚¬ìš©
    print("\n" + "=" * 70)
    print("âœ… RAG ì‚¬ìš© - Vector Storeë¡œ ê²€ìƒ‰")
    print("=" * 70)

    # 1. Embeddings ìƒì„±
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

    # 2. Vector Store ìƒì„±
    vectorstore = FAISS.from_texts(
        texts=company_data,
        embedding=embeddings
    )

    # 3. ê²€ìƒ‰ ë„êµ¬ ìƒì„±
    @tool
    def search_company_data(query: str) -> str:
        """íšŒì‚¬ ì¬ë¬´ ë°ì´í„° ê²€ìƒ‰"""
        docs = vectorstore.similarity_search(query, k=2)
        return "\n".join([d.page_content for d in docs])

    # 4. Agentì— ê²€ìƒ‰ ë„êµ¬ ì¶”ê°€
    agent_with_rag = create_agent(
        model="gpt-4o-mini",
        tools=[search_company_data],
        system_prompt="ë‹¹ì‹ ì€ íšŒì‚¬ ì¬ë¬´ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
    )

    response = agent_with_rag.invoke({
        "messages": [{"role": "user", "content": "ìš°ë¦¬ íšŒì‚¬ì˜ 2024ë…„ Q3 ë§¤ì¶œì€ ì–¼ë§ˆì¸ê°€ìš”?"}]
    })

    print(f"\nğŸ¤– Agent ë‹µë³€ (RAG ì‚¬ìš©):")
    print(f"{response['messages'][-1].content}")
    print("\nâœ… ê²°ê³¼: Vector Storeì—ì„œ ì •í™•í•œ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì •í™•í•œ ë‹µë³€ ì œê³µ")

    print("\n" + "=" * 70)


# ============================================================================
# ì˜ˆì œ 2: Vector Store ê¸°ë³¸ - ìœ ì‚¬ë„ ê²€ìƒ‰
# ============================================================================

def example_2_similarity_search():
    """Vector Storeë¥¼ ì‚¬ìš©í•œ ìœ ì‚¬ë„ ê²€ìƒ‰"""
    print("\n" + "=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 2: ìœ ì‚¬ë„ ê²€ìƒ‰ (Similarity Search)")
    print("=" * 70)

    print("""
ğŸ’¡ ìœ ì‚¬ë„ ê²€ìƒ‰ì´ë€?
   - ì¿¼ë¦¬ì™€ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë¬¸ì„œ ì°¾ê¸°
   - ë²¡í„° ê°„ ê±°ë¦¬(ì½”ì‚¬ì¸ ìœ ì‚¬ë„) ê³„ì‚°
   - ê°€ì¥ ê°€ê¹Œìš´ kê°œ ë¬¸ì„œ ë°˜í™˜

ì‘ë™ ê³¼ì •:
   1. í…ìŠ¤íŠ¸ â†’ ë²¡í„° ë³€í™˜ (Embedding)
   2. ì¿¼ë¦¬ â†’ ë²¡í„° ë³€í™˜
   3. ë²¡í„° ê°„ ìœ ì‚¬ë„ ê³„ì‚°
   4. ìƒìœ„ kê°œ ë°˜í™˜
    """)

    # ìƒ˜í”Œ ë¬¸ì„œ
    documents = [
        "íŒŒì´ì¬ì€ ê°„ê²°í•˜ê³  ì½ê¸° ì‰¬ìš´ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.",
        "ìë°”ëŠ” ê°ì²´ì§€í–¥ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ ë§ì€ ê¸°ì—…ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤.",
        "ë¨¸ì‹ ëŸ¬ë‹ì€ ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì„ í•™ìŠµí•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.",
        "ë”¥ëŸ¬ë‹ì€ ì¸ê³µì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ì˜ í•œ ë¶„ì•¼ì…ë‹ˆë‹¤.",
        "ìì—°ì–´ì²˜ë¦¬ëŠ” ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ê³  ì²˜ë¦¬í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.",
        "ê°•ì•„ì§€ëŠ” ì¶©ì„±ìŠ¤ëŸ½ê³  ì‚¬ëŒì„ ì¢‹ì•„í•˜ëŠ” ì• ì™„ë™ë¬¼ì…ë‹ˆë‹¤.",
        "ê³ ì–‘ì´ëŠ” ë…ë¦½ì ì´ê³  ê¹¨ë—í•œ ì• ì™„ë™ë¬¼ì…ë‹ˆë‹¤.",
        "ReactëŠ” ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ë¥¼ ë§Œë“¤ê¸° ìœ„í•œ ìë°”ìŠ¤í¬ë¦½íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.",
    ]

    print("\nğŸ“š ë¬¸ì„œ ëª©ë¡:")
    for i, doc in enumerate(documents, 1):
        print(f"  {i}. {doc}")

    # Vector Store ìƒì„±
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    vectorstore = FAISS.from_texts(documents, embeddings)

    # ë‹¤ì–‘í•œ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰
    queries = [
        "í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
        "AIì™€ ë¨¸ì‹ ëŸ¬ë‹ì´ë€?",
        "ì• ì™„ë™ë¬¼ ì¶”ì²œí•´ì£¼ì„¸ìš”"
    ]

    for query in queries:
        print("\n" + "-" * 70)
        print(f"ğŸ” ì¿¼ë¦¬: {query}")
        print("-" * 70)

        # ìœ ì‚¬ë„ ê²€ìƒ‰ (k=2)
        results = vectorstore.similarity_search(query, k=2)

        print("\nğŸ“„ ê²€ìƒ‰ ê²°ê³¼ (ìƒìœ„ 2ê°œ):")
        for i, doc in enumerate(results, 1):
            print(f"  {i}. {doc.page_content}")

    print("\n" + "=" * 70)


# ============================================================================
# ì˜ˆì œ 3: ìœ ì‚¬ë„ ì ìˆ˜ì™€ í•¨ê»˜ ê²€ìƒ‰
# ============================================================================

def example_3_search_with_scores():
    """ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ í•¨ê»˜ ë°˜í™˜í•˜ëŠ” ê²€ìƒ‰"""
    print("\n" + "=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 3: ìœ ì‚¬ë„ ì ìˆ˜ì™€ í•¨ê»˜ ê²€ìƒ‰")
    print("=" * 70)

    print("""
ğŸ’¡ ìœ ì‚¬ë„ ì ìˆ˜ë€?
   - ì¿¼ë¦¬ì™€ ë¬¸ì„œ ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ìˆ«ìë¡œ í‘œí˜„
   - ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬í•¨ (ê±°ë¦¬ ê¸°ë°˜)
   - ì„ê³„ê°’ ì„¤ì •ìœ¼ë¡œ í’ˆì§ˆ ê´€ë¦¬ ê°€ëŠ¥
    """)

    # ê¸°ìˆ  ë¬¸ì„œ
    tech_docs = [
        "DockerëŠ” ì»¨í…Œì´ë„ˆ ê¸°ë°˜ ê°€ìƒí™” í”Œë«í¼ì…ë‹ˆë‹¤.",
        "KubernetesëŠ” ì»¨í…Œì´ë„ˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë„êµ¬ì…ë‹ˆë‹¤.",
        "Gitì€ ë¶„ì‚° ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.",
        "PostgreSQLì€ ì˜¤í”ˆì†ŒìŠ¤ ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.",
        "MongoDBëŠ” NoSQL ë¬¸ì„œ ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.",
        "RedisëŠ” ì¸ë©”ëª¨ë¦¬ í‚¤-ê°’ ì €ì¥ì†Œì…ë‹ˆë‹¤.",
    ]

    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    vectorstore = FAISS.from_texts(tech_docs, embeddings)

    query = "ì»¨í…Œì´ë„ˆ ê´€ë ¨ ê¸°ìˆ "

    print(f"\nğŸ” ì¿¼ë¦¬: {query}\n")

    # ìœ ì‚¬ë„ ì ìˆ˜ì™€ í•¨ê»˜ ê²€ìƒ‰
    results_with_scores = vectorstore.similarity_search_with_score(query, k=4)

    print("ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ (ì ìˆ˜ í¬í•¨):")
    for i, (doc, score) in enumerate(results_with_scores, 1):
        relevance = "ë†’ìŒ" if score < 0.3 else "ì¤‘ê°„" if score < 0.5 else "ë‚®ìŒ"
        print(f"\n  {i}. ì ìˆ˜: {score:.4f} (ê´€ë ¨ì„±: {relevance})")
        print(f"     ë‚´ìš©: {doc.page_content}")

    # ì„ê³„ê°’ ì ìš©
    threshold = 0.4
    print(f"\n" + "-" * 70)
    print(f"ğŸ“Œ ì„ê³„ê°’ {threshold} ì´í•˜ë§Œ í•„í„°ë§:")
    print("-" * 70)

    filtered_results = [
        (doc, score) for doc, score in results_with_scores
        if score < threshold
    ]

    if filtered_results:
        for i, (doc, score) in enumerate(filtered_results, 1):
            print(f"\n  {i}. ì ìˆ˜: {score:.4f}")
            print(f"     {doc.page_content}")
    else:
        print("  âš ï¸  ì„ê³„ê°’ì„ í†µê³¼í•œ ê²°ê³¼ ì—†ìŒ")

    print("\n" + "=" * 70)


# ============================================================================
# ì˜ˆì œ 4: Top-k Retrieval ë¹„êµ
# ============================================================================

def example_4_topk_retrieval():
    """ë‹¤ì–‘í•œ k ê°’ì— ë”°ë¥¸ ê²€ìƒ‰ ê²°ê³¼ ë¹„êµ"""
    print("\n" + "=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 4: Top-k Retrieval")
    print("=" * 70)

    print("""
ğŸ’¡ Top-kë€?
   - ìƒìœ„ kê°œì˜ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ë°˜í™˜
   - k ê°’ ì„ íƒì´ ì¤‘ìš”:
     â€¢ kê°€ ë„ˆë¬´ ì‘ìœ¼ë©´: ì¶©ë¶„í•œ ì •ë³´ ë¶€ì¡±
     â€¢ kê°€ ë„ˆë¬´ í¬ë©´: ê´€ë ¨ ì—†ëŠ” ì •ë³´ í¬í•¨, ë¹„ìš© ì¦ê°€

ê¶Œì¥ k ê°’:
   - ê°„ë‹¨í•œ ì§ˆë¬¸: k=3
   - ë³µì¡í•œ ì§ˆë¬¸: k=5~10
   - ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ê³ ë ¤ í•„ìš”
    """)

    # ì˜í™” ë¦¬ë·° ë°ì´í„°
    movie_reviews = [
        "ì–´ë²¤ì ¸ìŠ¤ëŠ” ì•¡ì…˜ê³¼ ìŠ¤í† ë¦¬ê°€ ì™„ë²½í•œ ìŠˆí¼íˆì–´ë¡œ ì˜í™”ì…ë‹ˆë‹¤.",
        "ì¸í„°ìŠ¤í…”ë¼ëŠ” ê°ë™ì ì¸ SF ê±¸ì‘ì…ë‹ˆë‹¤.",
        "ê¸°ìƒì¶©ì€ ì‚¬íšŒ ê³„ì¸µì„ ë‹¤ë£¬ ë›°ì–´ë‚œ í•œêµ­ ì˜í™”ì…ë‹ˆë‹¤.",
        "íƒ€ì´íƒ€ë‹‰ì€ ë¡œë§¨ìŠ¤ì™€ ì¬ë‚œì„ ê²°í•©í•œ ê°ë™ì ì¸ ì˜í™”ì…ë‹ˆë‹¤.",
        "ì¡°ì»¤ëŠ” ë¹ŒëŸ°ì˜ ì‹¬ë¦¬ë¥¼ ê¹Šì´ ìˆê²Œ íƒêµ¬í•œ ì‘í’ˆì…ë‹ˆë‹¤.",
        "ì¸ì…‰ì…˜ì€ ë³µì¡í•œ ìŠ¤í† ë¦¬ êµ¬ì¡°ì˜ SF ìŠ¤ë¦´ëŸ¬ì…ë‹ˆë‹¤.",
        "ë¼ë¼ëœë“œëŠ” ìŒì•…ê³¼ ë¡œë§¨ìŠ¤ê°€ ì•„ë¦„ë‹¤ìš´ ë®¤ì§€ì»¬ ì˜í™”ì…ë‹ˆë‹¤.",
        "ë§¤ë“œë§¥ìŠ¤ëŠ” ê°•ë ¬í•œ ì•¡ì…˜ì˜ í¬ìŠ¤íŠ¸ ì•„í¬ì¹¼ë¦½ìŠ¤ ì˜í™”ì…ë‹ˆë‹¤.",
        "ìœ„í”Œë˜ì‰¬ëŠ” ì¬ì¦ˆ ë“œëŸ¬ë¨¸ì˜ ì—´ì •ì„ ê·¸ë¦° ë“œë¼ë§ˆì…ë‹ˆë‹¤.",
        "ê·¸ë˜ë¹„í‹°ëŠ” ìš°ì£¼ë¥¼ ë°°ê²½ìœ¼ë¡œ í•œ ìƒì¡´ ìŠ¤ë¦´ëŸ¬ì…ë‹ˆë‹¤.",
    ]

    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    vectorstore = FAISS.from_texts(movie_reviews, embeddings)

    query = "SF ì˜í™” ì¶”ì²œí•´ì£¼ì„¸ìš”"

    print(f"\nğŸ” ì¿¼ë¦¬: {query}\n")

    # ë‹¤ì–‘í•œ k ê°’ìœ¼ë¡œ ê²€ìƒ‰
    k_values = [1, 3, 5]

    for k in k_values:
        print(f"\n{'=' * 70}")
        print(f"ğŸ“Œ k={k}ê°œ ê²€ìƒ‰ ê²°ê³¼:")
        print("=" * 70)

        results = vectorstore.similarity_search(query, k=k)

        for i, doc in enumerate(results, 1):
            print(f"\n  {i}. {doc.page_content}")

        # k ê°’ì— ë”°ë¥¸ í‰ê°€
        if k == 1:
            print("\n  ğŸ’¡ k=1: ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë‹¨ì¼ ê²°ê³¼. ë¹ ë¥´ì§€ë§Œ ì •ë³´ ë¶€ì¡± ê°€ëŠ¥.")
        elif k == 3:
            print("\n  âœ… k=3: ê· í˜•ì¡íŒ ì„ íƒ. ì¶©ë¶„í•œ ì •ë³´ + ê´€ë ¨ì„± ìœ ì§€.")
        elif k == 5:
            print("\n  ğŸ“š k=5: ë” ë§ì€ ì»¨í…ìŠ¤íŠ¸. ë³µì¡í•œ ì§ˆë¬¸ì— ì í•©.")

    print("\n" + "=" * 70)


# ============================================================================
# ì˜ˆì œ 5: ì‹¤ì „ - FAQ ê²€ìƒ‰ ì‹œìŠ¤í…œ
# ============================================================================

def example_5_faq_search_system():
    """ì‹¤ì „ FAQ ê²€ìƒ‰ Agent ì‹œìŠ¤í…œ"""
    print("\n" + "=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 5: ì‹¤ì „ FAQ ê²€ìƒ‰ ì‹œìŠ¤í…œ")
    print("=" * 70)

    print("""
ğŸ’¡ ì‹¤ì „ ì‹œë‚˜ë¦¬ì˜¤:
   - ê³ ê° ì§€ì› FAQ ì‹œìŠ¤í…œ
   - ì§ˆë¬¸ ì…ë ¥ â†’ ê´€ë ¨ FAQ ê²€ìƒ‰ â†’ ë‹µë³€ ìƒì„±
   - Agentê°€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€

êµ¬í˜„ ë‹¨ê³„:
   1. FAQ ë°ì´í„° ì¤€ë¹„
   2. Vector Store êµ¬ì¶•
   3. ê²€ìƒ‰ ë„êµ¬ ìƒì„±
   4. Agent ìƒì„±
   5. ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬
    """)

    # FAQ ë°ì´í„° (Document í˜•íƒœë¡œ ë©”íƒ€ë°ì´í„° í¬í•¨)
    faq_data = [
        Document(
            page_content="Q: ë°°ì†¡ì€ ì–¼ë§ˆë‚˜ ê±¸ë¦¬ë‚˜ìš”?\nA: ì¼ë°˜ ë°°ì†¡ì€ 2-3ì¼, ë¹ ë¥¸ ë°°ì†¡ì€ 1ì¼ ì†Œìš”ë©ë‹ˆë‹¤.",
            metadata={"category": "ë°°ì†¡", "id": 1}
        ),
        Document(
            page_content="Q: ë°˜í’ˆì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?\nA: êµ¬ë§¤ í›„ 7ì¼ ì´ë‚´ ë¯¸ê°œë´‰ ìƒí’ˆì— í•œí•´ ë°˜í’ˆ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
            metadata={"category": "ë°˜í’ˆ", "id": 2}
        ),
        Document(
            page_content="Q: ê²°ì œ ìˆ˜ë‹¨ì€ ë¬´ì—‡ì´ ìˆë‚˜ìš”?\nA: ì‹ ìš©ì¹´ë“œ, ê³„ì¢Œì´ì²´, ë¬´í†µì¥ì…ê¸ˆ, ì¹´ì¹´ì˜¤í˜ì´ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.",
            metadata={"category": "ê²°ì œ", "id": 3}
        ),
        Document(
            page_content="Q: íšŒì›ê°€ì… í˜œíƒì€ ë¬´ì—‡ì¸ê°€ìš”?\nA: ì²« êµ¬ë§¤ 10% í• ì¸, ì ë¦½ê¸ˆ 5% ì§€ê¸‰, ìƒì¼ ì¿ í° ì œê³µë©ë‹ˆë‹¤.",
            metadata={"category": "íšŒì›", "id": 4}
        ),
        Document(
            page_content="Q: ì¬ê³ ê°€ ì—†ìœ¼ë©´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\nA: ì¬ì…ê³  ì•Œë¦¼ ì‹ ì²­ ì‹œ ì…ê³ ë˜ë©´ ì´ë©”ì¼ë¡œ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.",
            metadata={"category": "ìƒí’ˆ", "id": 5}
        ),
        Document(
            page_content="Q: ë°°ì†¡ë¹„ëŠ” ì–¼ë§ˆì¸ê°€ìš”?\nA: 3ë§Œì› ì´ìƒ ë¬´ë£Œë°°ì†¡, ë¯¸ë§Œ ì‹œ 3,000ì›ì…ë‹ˆë‹¤.",
            metadata={"category": "ë°°ì†¡", "id": 6}
        ),
        Document(
            page_content="Q: êµí™˜ì€ ê°€ëŠ¥í•œê°€ìš”?\nA: ì‚¬ì´ì¦ˆ ë¶ˆë§Œì¡± ì‹œ 7ì¼ ì´ë‚´ 1íšŒ ë¬´ë£Œ êµí™˜ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
            metadata={"category": "ë°˜í’ˆ", "id": 7}
        ),
        Document(
            page_content="Q: ì ë¦½ê¸ˆì€ ì–¸ì œ ì‚¬ìš© ê°€ëŠ¥í•œê°€ìš”?\nA: êµ¬ë§¤ í™•ì • í›„ 3ì¼ ë’¤ë¶€í„° ì‚¬ìš© ê°€ëŠ¥í•˜ë©°, ìœ íš¨ê¸°ê°„ì€ 1ë…„ì…ë‹ˆë‹¤.",
            metadata={"category": "íšŒì›", "id": 8}
        ),
    ]

    print("\nğŸ“š FAQ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì¤‘...")

    # Vector Store ìƒì„±
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    vectorstore = FAISS.from_documents(faq_data, embeddings)

    print("âœ… Vector Store êµ¬ì¶• ì™„ë£Œ!")

    # ê²€ìƒ‰ ë„êµ¬ ìƒì„±
    @tool
    def search_faq(question: str) -> str:
        """FAQ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì§ˆë¬¸ ê²€ìƒ‰"""
        docs = vectorstore.similarity_search(question, k=3)
        results = []
        for i, doc in enumerate(docs, 1):
            results.append(f"[FAQ {i}]\n{doc.page_content}\n(ì¹´í…Œê³ ë¦¬: {doc.metadata['category']})")
        return "\n\n".join(results)

    # Agent ìƒì„±
    agent = create_agent(
        model="gpt-4o-mini",
        tools=[search_faq],
        system_prompt="""ë‹¹ì‹ ì€ ì¹œì ˆí•œ ê³ ê° ì§€ì› ìƒë‹´ì›ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•  ë•Œ:
1. search_faq ë„êµ¬ë¡œ ê´€ë ¨ FAQë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”
2. ê²€ìƒ‰ëœ FAQë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”
3. ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ê³ , ì¶”ê°€ ì§ˆë¬¸ì´ ìˆëŠ”ì§€ ë¬¼ì–´ë³´ì„¸ìš”
"""
    )

    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
    test_questions = [
        "ë°°ì†¡ì€ ì–¼ë§ˆë‚˜ ê±¸ë¦¬ë‚˜ìš”?",
        "ë°˜í’ˆí•˜ê³  ì‹¶ì€ë° ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?",
        "íšŒì›ê°€ì…í•˜ë©´ ì–´ë–¤ í˜œíƒì´ ìˆë‚˜ìš”?",
    ]

    print("\n" + "=" * 70)
    print("ğŸ¤– FAQ ê²€ìƒ‰ Agent í…ŒìŠ¤íŠ¸")
    print("=" * 70)

    for question in test_questions:
        print(f"\n{'=' * 70}")
        print(f"â“ ì‚¬ìš©ì ì§ˆë¬¸: {question}")
        print("=" * 70)

        response = agent.invoke({
            "messages": [{"role": "user", "content": question}]
        })

        answer = response['messages'][-1].content
        print(f"\nğŸ¤– Agent ë‹µë³€:\n{answer}")

    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    print("\n" + "=" * 70)
    print("ğŸ’¬ ì§ì ‘ ì§ˆë¬¸í•´ë³´ì„¸ìš” (ì¢…ë£Œ: 'quit' ì…ë ¥)")
    print("=" * 70)

    user_question = input("\nâ“ ì§ˆë¬¸: ").strip()

    if user_question and user_question.lower() != 'quit':
        print("\nğŸ” ê²€ìƒ‰ ì¤‘...")

        response = agent.invoke({
            "messages": [{"role": "user", "content": user_question}]
        })

        answer = response['messages'][-1].content
        print(f"\nğŸ¤– Agent ë‹µë³€:\n{answer}")

    print("\n" + "=" * 70)
    print("âœ… FAQ ê²€ìƒ‰ ì‹œìŠ¤í…œ ì™„ë£Œ!")


# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("\n")
    print("=" * 70)
    print("Part 8: RAG ê¸°ì´ˆ (01_rag_basics.py)")
    print("=" * 70)

    while True:
        print("\nğŸ“š ì‹¤í–‰í•  ì˜ˆì œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
        print("  1. RAGê°€ í•„ìš”í•œ ì´ìœ  (Before & After)")
        print("  2. ìœ ì‚¬ë„ ê²€ìƒ‰ (Similarity Search)")
        print("  3. ìœ ì‚¬ë„ ì ìˆ˜ì™€ í•¨ê»˜ ê²€ìƒ‰")
        print("  4. Top-k Retrieval ë¹„êµ")
        print("  5. ì‹¤ì „ FAQ ê²€ìƒ‰ ì‹œìŠ¤í…œ â­")
        print("  0. ì¢…ë£Œ")

        choice = input("\nì„ íƒ (0-5): ").strip()

        if choice == "1":
            example_1_why_rag()
        elif choice == "2":
            example_2_similarity_search()
        elif choice == "3":
            example_3_search_with_scores()
        elif choice == "4":
            example_4_topk_retrieval()
        elif choice == "5":
            example_5_faq_search_system()
        elif choice == "0":
            print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        else:
            print("\nâŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ë‹¤ì‹œ ì„ íƒí•´ì£¼ì„¸ìš”.")


if __name__ == "__main__":
    main()
