"""
================================================================================
LangChain AI Agent ë§ˆìŠ¤í„° êµì•ˆ
Part 10: ë°°í¬ì™€ ê´€ì¸¡ì„± (Deployment & Observability)
================================================================================

íŒŒì¼ëª…: 05_deployment.py
ë‚œì´ë„: â­â­â­â­â­ (ì „ë¬¸ê°€)
ì˜ˆìƒ ì‹œê°„: 30ë¶„

ğŸ“š í•™ìŠµ ëª©í‘œ:
  - Docker ì»¨í…Œì´ë„ˆí™”
  - API ì„œë²„ êµ¬ì¶•
  - ìŠ¤ì¼€ì¼ë§ ì „ëµ
  - í™˜ê²½ ì„¤ì • ê´€ë¦¬
  - í”„ë¡œë•ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

ğŸ“– ê³µì‹ ë¬¸ì„œ:
  â€¢ LangServe: https://python.langchain.com/docs/langserve
  â€¢ Deployment: https://python.langchain.com/docs/deployment

ğŸ“„ êµì•ˆ ë¬¸ì„œ:
  â€¢ Part 10 ê°œìš”: /docs/part10_deployment.md

ğŸ”§ í•„ìš”í•œ íŒ¨í‚¤ì§€:
  pip install langchain langchain-openai fastapi uvicorn

ğŸ”‘ í•„ìš”í•œ í™˜ê²½ë³€ìˆ˜:
  - OPENAI_API_KEY

ğŸš€ ì‹¤í–‰ ë°©ë²•:
  python 05_deployment.py

================================================================================
"""

# ============================================================================
# Imports
# ============================================================================

import os
import sys
from typing import Dict, Any
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.agents import create_agent
from langchain.tools import tool

# ============================================================================
# í™˜ê²½ ì„¤ì •
# ============================================================================

load_dotenv()

if not os.getenv("OPENAI_API_KEY"):
    print("âŒ ì˜¤ë¥˜: OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    sys.exit(1)

# ============================================================================
# ì˜ˆì œ 1: Docker ì»¨í…Œì´ë„ˆí™”
# ============================================================================

def example_1_docker():
    """Docker ì»¨í…Œì´ë„ˆí™”"""
    print("=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 1: Docker ì»¨í…Œì´ë„ˆí™”")
    print("=" * 70)

    print("""
ğŸ³ Dockerë€?

ì •ì˜:
  ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì»¨í…Œì´ë„ˆë¡œ íŒ¨í‚¤ì§•í•˜ì—¬
  ì–´ë””ì„œë‚˜ ë™ì¼í•˜ê²Œ ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” í”Œë«í¼

ì™œ Dockerë¥¼ ì‚¬ìš©í•˜ëŠ”ê°€?
  1ï¸âƒ£ í™˜ê²½ ì¼ê´€ì„±
     â€¢ ê°œë°œ/ìŠ¤í…Œì´ì§•/í”„ë¡œë•ì…˜ ë™ì¼ í™˜ê²½
     â€¢ "ë‚´ ì»´í“¨í„°ì—ì„œëŠ” ë˜ëŠ”ë°?" ë¬¸ì œ í•´ê²°

  2ï¸âƒ£ ì´ì‹ì„±
     â€¢ ëª¨ë“  í´ë¼ìš°ë“œ í”Œë«í¼ì—ì„œ ì‹¤í–‰
     â€¢ ë¡œì»¬ -> AWS/GCP/Azure ì‰¬ìš´ ì´ë™

  3ï¸âƒ£ ê²©ë¦¬ì„±
     â€¢ ê° ì„œë¹„ìŠ¤ ë…ë¦½ ì‹¤í–‰
     â€¢ ì˜ì¡´ì„± ì¶©ëŒ ë°©ì§€

  4ï¸âƒ£ í™•ì¥ì„±
     â€¢ ì»¨í…Œì´ë„ˆ ë³µì œë¡œ ì‰¬ìš´ ìŠ¤ì¼€ì¼ë§
     â€¢ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ (Kubernetes) ê°€ëŠ¥

Docker í•µì‹¬ ê°œë…:
  â€¢ Image: ì‹¤í–‰ ê°€ëŠ¥í•œ íŒ¨í‚¤ì§€
  â€¢ Container: Imageì˜ ì‹¤í–‰ ì¸ìŠ¤í„´ìŠ¤
  â€¢ Dockerfile: Image ë¹Œë“œ ëª…ë ¹ì„œ
  â€¢ Docker Compose: ë‹¤ì¤‘ ì»¨í…Œì´ë„ˆ ê´€ë¦¬
    """)

    print("\nğŸ”¹ Dockerfile ì˜ˆì œ:")
    print("-" * 70)

    print("""
ğŸ“„ Dockerfile (Python LangChain Agent):
""")
    print('''
# ë² ì´ìŠ¤ ì´ë¯¸ì§€
FROM python:3.11-slim

# ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •
WORKDIR /app

# ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜
RUN apt-get update && apt-get install -y \\
    gcc \\
    && rm -rf /var/lib/apt/lists/*

# Python ì˜ì¡´ì„± íŒŒì¼ ë³µì‚¬
COPY requirements.txt .

# ì˜ì¡´ì„± ì„¤ì¹˜
RUN pip install --no-cache-dir -r requirements.txt

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬
COPY . .

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ê¸°ë³¸ê°’)
ENV PORT=8000
ENV WORKERS=4

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8000

# í—¬ìŠ¤ì²´í¬ (ì„ íƒ)
HEALTHCHECK --interval=30s --timeout=3s \\
  CMD curl -f http://localhost:8000/health || exit 1

# ì‹¤í–‰ ëª…ë ¹
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
''')

    print("\nğŸ“„ .dockerignore:")
    print('''
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
venv/
.venv/

# Tests
.pytest_cache/
.coverage
htmlcov/

# IDEs
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Git
.git/
.gitignore

# Secrets
.env
*.key
*.pem

# Others
*.log
tmp/
temp/
''')

    print("\nğŸ“„ requirements.txt:")
    print('''
langchain==0.1.0
langchain-openai==0.0.5
fastapi==0.109.0
uvicorn[standard]==0.27.0
pydantic==2.5.0
python-dotenv==1.0.0
langsmith==0.0.87
''')

    print("\nğŸ”¹ Docker ëª…ë ¹ì–´:")
    print("-" * 70)
    print("""
# 1. ì´ë¯¸ì§€ ë¹Œë“œ
docker build -t my-langchain-agent:latest .

# 2. ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
docker images | grep my-langchain-agent

# 3. ì»¨í…Œì´ë„ˆ ì‹¤í–‰
docker run -d \\
  --name langchain-agent \\
  -p 8000:8000 \\
  -e OPENAI_API_KEY=sk-xxx \\
  -e LANGSMITH_API_KEY=lsv2_xxx \\
  my-langchain-agent:latest

# 4. ë¡œê·¸ í™•ì¸
docker logs -f langchain-agent

# 5. ì»¨í…Œì´ë„ˆ ë‚´ë¶€ ì ‘ì†
docker exec -it langchain-agent bash

# 6. ì»¨í…Œì´ë„ˆ ì¤‘ì§€
docker stop langchain-agent

# 7. ì»¨í…Œì´ë„ˆ ì œê±°
docker rm langchain-agent

# 8. ì´ë¯¸ì§€ í‘¸ì‹œ (Docker Hub)
docker tag my-langchain-agent:latest username/my-langchain-agent:latest
docker push username/my-langchain-agent:latest
    """)

    print("\nğŸ“„ docker-compose.yml (ë‹¤ì¤‘ ì„œë¹„ìŠ¤):")
    print('''
version: '3.8'

services:
  agent:
    build: .
    ports:
      - "8000:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - LANGSMITH_API_KEY=${LANGSMITH_API_KEY}
      - REDIS_URL=redis://redis:6379
    depends_on:
      - redis
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - agent
    restart: unless-stopped

volumes:
  redis_data:
''')

    print("\nğŸ”¹ Docker Compose ëª…ë ¹ì–´:")
    print('''
# 1. ì „ì²´ ìŠ¤íƒ ì‹œì‘
docker-compose up -d

# 2. ë¡œê·¸ ë³´ê¸°
docker-compose logs -f

# 3. íŠ¹ì • ì„œë¹„ìŠ¤ë§Œ ì¬ì‹œì‘
docker-compose restart agent

# 4. ì „ì²´ ì¤‘ì§€ ë° ì œê±°
docker-compose down

# 5. ë³¼ë¥¨ê¹Œì§€ ì œê±°
docker-compose down -v
    ''')

    print("\nğŸ’¡ Docker ìµœì í™” íŒ:")
    print("   â€¢ Multi-stage buildë¡œ ì´ë¯¸ì§€ í¬ê¸° ìµœì†Œí™”")
    print("   â€¢ .dockerignoreë¡œ ë¶ˆí•„ìš”í•œ íŒŒì¼ ì œì™¸")
    print("   â€¢ ë ˆì´ì–´ ìºì‹± í™œìš© (ìì£¼ ë³€ê²½ë˜ëŠ” íŒŒì¼ì€ ë‚˜ì¤‘ì—)")
    print("   â€¢ ë³´ì•ˆ: ë¹„ë°€í‚¤ëŠ” í™˜ê²½ ë³€ìˆ˜ë‚˜ Secrets ì‚¬ìš©")
    print("   â€¢ í—¬ìŠ¤ì²´í¬ ì¶”ê°€í•˜ì—¬ ì»¨í…Œì´ë„ˆ ìƒíƒœ ëª¨ë‹ˆí„°ë§")


# ============================================================================
# ì˜ˆì œ 2: FastAPI ì„œë²„ êµ¬ì¶•
# ============================================================================

def example_2_api_server():
    """API ì„œë²„ êµ¬ì¶•"""
    print("\n" + "=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 2: FastAPI ì„œë²„ êµ¬ì¶•")
    print("=" * 70)

    print("""
ğŸš€ FastAPIë€?

ì •ì˜:
  ê³ ì„±ëŠ¥ Python ì›¹ í”„ë ˆì„ì›Œí¬

ì¥ì :
  â€¢ ë¹ ë¦„ (Starlette ê¸°ë°˜)
  â€¢ ìë™ API ë¬¸ì„œ (Swagger/OpenAPI)
  â€¢ íƒ€ì… íŒíŠ¸ ì§€ì›
  â€¢ ë¹„ë™ê¸° ì²˜ë¦¬
  â€¢ Pydantic ê²€ì¦

LangChain + FastAPI:
  â€¢ Agentë¥¼ REST APIë¡œ ì œê³µ
  â€¢ í”„ë¡ íŠ¸ì—”ë“œì™€ ì‰½ê²Œ í†µí•©
  â€¢ ì—¬ëŸ¬ í´ë¼ì´ì–¸íŠ¸ ë™ì‹œ ì²˜ë¦¬
    """)

    print("\nğŸ”¹ FastAPI ì„œë²„ ì½”ë“œ ì˜ˆì œ:")
    print("-" * 70)

    print("""
ğŸ“„ main.py (FastAPI ì„œë²„):
""")
    print('''
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
from langchain.agents import create_agent
from langchain.tools import tool
from langchain_openai import ChatOpenAI
import os

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="LangChain Agent API",
    description="AI Agent REST API",
    version="1.0.0"
)

# CORS ì„¤ì • (í”„ë¡ íŠ¸ì—”ë“œ ì ‘ê·¼ í—ˆìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” êµ¬ì²´ì ìœ¼ë¡œ ì§€ì •
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Tools ì •ì˜
@tool
def search_docs(query: str) -> str:
    """ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    return f"{query}ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼"

@tool
def calculate(expression: str) -> str:
    """ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    try:
        result = eval(expression, {"__builtins__": {}}, {})
        return str(result)
    except Exception as e:
        return f"ì˜¤ë¥˜: {e}"

# Agent ìƒì„± (ì „ì—­)
agent = create_agent(
    model="gpt-4o-mini",
    tools=[search_docs, calculate],
)

# Request/Response ëª¨ë¸
class ChatRequest(BaseModel):
    message: str
    session_id: Optional[str] = None
    metadata: Optional[dict] = None

class ChatResponse(BaseModel):
    response: str
    session_id: Optional[str] = None
    metadata: Optional[dict] = None

# ì—”ë“œí¬ì¸íŠ¸
@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {"message": "LangChain Agent API", "status": "running"}

@app.get("/health")
async def health():
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {"status": "healthy"}

@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸"""
    try:
        response = agent.invoke({
            "messages": [{"role": "user", "content": request.message}]
        })

        answer = response['messages'][-1].content

        return ChatResponse(
            response=answer,
            session_id=request.session_id,
            metadata=request.metadata
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/info")
async def info():
    """API ì •ë³´"""
    return {
        "name": "LangChain Agent API",
        "version": "1.0.0",
        "tools": ["search_docs", "calculate"],
        "model": "gpt-4o-mini"
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
''')

    print("\nğŸ”¹ ì‹¤ì œ ì„œë²„ ì‹œë®¬ë ˆì´ì…˜:")
    print("-" * 70)

    # ê°„ë‹¨í•œ Agent ìƒì„±
    @tool
    def demo_search(query: str) -> str:
        """ë°ëª¨ ê²€ìƒ‰"""
        return f"'{query}' ê²€ìƒ‰ ê²°ê³¼"

    agent = create_agent(
        model="gpt-4o-mini",
        tools=[demo_search],
    )

    print("\nì‹œë®¬ë ˆì´ì…˜: API ìš”ì²­ ì²˜ë¦¬")
    print()

    # ìš”ì²­ ì‹œë®¬ë ˆì´ì…˜
    test_requests = [
        {"message": "ì¸ê³µì§€ëŠ¥ì´ë€?", "session_id": "sess-001"},
        {"message": "LangChain ì‚¬ìš©ë²•", "session_id": "sess-002"},
    ]

    for i, req in enumerate(test_requests, 1):
        print(f"[ìš”ì²­ {i}]")
        print(f"  POST /chat")
        print(f"  Body: {req}")

        try:
            response = agent.invoke({
                "messages": [{"role": "user", "content": req['message']}]
            })
            answer = response['messages'][-1].content

            print(f"  ì‘ë‹µ: {{")
            print(f"    'response': '{answer[:60]}...',")
            print(f"    'session_id': '{req['session_id']}'")
            print(f"  }}")
            print(f"  ìƒíƒœ: 200 OK\n")
        except Exception as e:
            print(f"  ì˜¤ë¥˜: {e}")
            print(f"  ìƒíƒœ: 500 Internal Server Error\n")

    print("-" * 70)

    print("\nğŸ“„ í´ë¼ì´ì–¸íŠ¸ ì˜ˆì œ (Python):")
    print('''
import requests

# API ê¸°ë³¸ URL
API_URL = "http://localhost:8000"

# ì±„íŒ… ìš”ì²­
response = requests.post(
    f"{API_URL}/chat",
    json={
        "message": "ì•ˆë…•í•˜ì„¸ìš”!",
        "session_id": "user-123",
        "metadata": {"source": "web"}
    }
)

print(response.json())
# {'response': 'ì•ˆë…•í•˜ì„¸ìš”! ...', 'session_id': 'user-123', ...}
    ''')

    print("\nğŸ“„ í´ë¼ì´ì–¸íŠ¸ ì˜ˆì œ (JavaScript):")
    print('''
// Fetch API
fetch('http://localhost:8000/chat', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    message: 'ì•ˆë…•í•˜ì„¸ìš”!',
    session_id: 'user-123',
    metadata: { source: 'web' }
  })
})
.then(response => response.json())
.then(data => console.log(data));
    ''')

    print("\nğŸ’¡ API ì„œë²„ ëª¨ë²” ì‚¬ë¡€:")
    print("   â€¢ ì¸ì¦/ì¸ê°€ ì¶”ê°€ (JWT, API Key)")
    print("   â€¢ Rate Limiting (ê³¼ë„í•œ ìš”ì²­ ë°©ì§€)")
    print("   â€¢ ì—ëŸ¬ ì²˜ë¦¬ ë° ìƒì„¸ ë©”ì‹œì§€")
    print("   â€¢ API ë²„ì €ë‹ (/v1/chat, /v2/chat)")
    print("   â€¢ ìë™ API ë¬¸ì„œ í™œìš© (/docs)")
    print("   â€¢ ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§")
    print("   â€¢ CORS ì •ì±… ì ì ˆíˆ ì„¤ì •")


# ============================================================================
# ì˜ˆì œ 3: ìŠ¤ì¼€ì¼ë§ ì „ëµ
# ============================================================================

def example_3_scaling():
    """ìŠ¤ì¼€ì¼ë§ ì „ëµ"""
    print("\n" + "=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 3: ìŠ¤ì¼€ì¼ë§ ì „ëµ")
    print("=" * 70)

    print("""
ğŸ“ˆ ìŠ¤ì¼€ì¼ë§ (Scaling)ì´ë€?

ì •ì˜:
  íŠ¸ë˜í”½ ì¦ê°€ì— ëŒ€ì‘í•˜ì—¬ ì‹œìŠ¤í…œ ìš©ëŸ‰ì„ í™•ì¥í•˜ëŠ” ê²ƒ

ìŠ¤ì¼€ì¼ë§ ë°©ì‹:

1ï¸âƒ£ ìˆ˜ì§ ìŠ¤ì¼€ì¼ë§ (Vertical Scaling / Scale Up)
   â€¢ ì •ì˜: ì„œë²„ ì‚¬ì–‘ ì—…ê·¸ë ˆì´ë“œ
   â€¢ ì˜ˆ: CPU 2 â†’ 8 ì½”ì–´, RAM 4GB â†’ 32GB
   â€¢ ì¥ì : ê°„ë‹¨, ì½”ë“œ ë³€ê²½ ë¶ˆí•„ìš”
   â€¢ ë‹¨ì : ë¬¼ë¦¬ì  í•œê³„, ë¹„ìš© ê¸‰ì¦, ë‹¨ì¼ ì¥ì• ì 

2ï¸âƒ£ ìˆ˜í‰ ìŠ¤ì¼€ì¼ë§ (Horizontal Scaling / Scale Out)
   â€¢ ì •ì˜: ì„œë²„ ê°œìˆ˜ ì¦ê°€
   â€¢ ì˜ˆ: ì„œë²„ 1ëŒ€ â†’ 5ëŒ€
   â€¢ ì¥ì : ë¬´í•œ í™•ì¥ ê°€ëŠ¥, ê³ ê°€ìš©ì„±
   â€¢ ë‹¨ì : ë³µì¡ì„±, ìƒíƒœ ê´€ë¦¬ í•„ìš”

LangChain Agent ìŠ¤ì¼€ì¼ë§:
  â€¢ Stateless ì„¤ê³„ (ì„¸ì…˜ì€ ì™¸ë¶€ ì €ì¥)
  â€¢ ë¡œë“œ ë°¸ëŸ°ì„œ ì‚¬ìš©
  â€¢ ì»¨í…Œì´ë„ˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ (Kubernetes)
  â€¢ ìºì‹± (Redis)
  â€¢ ë¹„ë™ê¸° ì²˜ë¦¬ (Celery, RabbitMQ)

ìŠ¤ì¼€ì¼ë§ ì§€í‘œ:
  â€¢ CPU ì‚¬ìš©ë¥  > 70%
  â€¢ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  > 80%
  â€¢ ì‘ë‹µ ì‹œê°„ > SLA
  â€¢ ì—ëŸ¬ìœ¨ ì¦ê°€
    """)

    print("\nğŸ”¹ ë¡œë“œ ë°¸ëŸ°ì„œ ì„¤ì • (Nginx):")
    print("-" * 70)

    print("""
ğŸ“„ nginx.conf:
""")
    print('''
http {
    # Upstream ì„œë²„ ê·¸ë£¹ ì •ì˜
    upstream agent_backend {
        # ë¡œë“œ ë°¸ëŸ°ì‹± ì•Œê³ ë¦¬ì¦˜ (ê¸°ë³¸: round-robin)
        # least_conn;  # ì—°ê²° ìˆ˜ê°€ ì ì€ ì„œë²„ ìš°ì„ 
        # ip_hash;     # ê°™ì€ IPëŠ” ê°™ì€ ì„œë²„ë¡œ

        server agent-1:8000 weight=3;
        server agent-2:8000 weight=2;
        server agent-3:8000 weight=1;
        server agent-4:8000 backup;  # ë°±ì—… ì„œë²„
    }

    server {
        listen 80;
        server_name api.example.com;

        # í—¬ìŠ¤ì²´í¬
        location /health {
            access_log off;
            return 200 "healthy\\n";
        }

        # API í”„ë¡ì‹œ
        location / {
            proxy_pass http://agent_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

            # íƒ€ì„ì•„ì›ƒ ì„¤ì •
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
        }
    }
}
''')

    print("\nğŸ“„ Kubernetes Deployment:")
    print('''
apiVersion: apps/v1
kind: Deployment
metadata:
  name: langchain-agent
spec:
  replicas: 3  # ì´ˆê¸° Pod ìˆ˜
  selector:
    matchLabels:
      app: langchain-agent
  template:
    metadata:
      labels:
        app: langchain-agent
    spec:
      containers:
      - name: agent
        image: myregistry/langchain-agent:latest
        ports:
        - containerPort: 8000
        env:
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: api-secrets
              key: openai-key
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: langchain-agent-service
spec:
  selector:
    app: langchain-agent
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: LoadBalancer

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: langchain-agent-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: langchain-agent
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
''')

    print("\nğŸ”¹ ìºì‹± ì „ëµ (Redis):")
    print('''
from redis import Redis
from functools import lru_cache
import hashlib
import json

# Redis í´ë¼ì´ì–¸íŠ¸
redis_client = Redis(host='localhost', port=6379, db=0)

def get_cache_key(query: str) -> str:
    """ìºì‹œ í‚¤ ìƒì„±"""
    return f"agent:response:{hashlib.md5(query.encode()).hexdigest()}"

def get_cached_response(query: str):
    """ìºì‹œì—ì„œ ì‘ë‹µ ì¡°íšŒ"""
    key = get_cache_key(query)
    cached = redis_client.get(key)
    if cached:
        return json.loads(cached)
    return None

def set_cached_response(query: str, response: str, ttl: int = 3600):
    """ì‘ë‹µì„ ìºì‹œì— ì €ì¥"""
    key = get_cache_key(query)
    redis_client.setex(key, ttl, json.dumps(response))

# ì‚¬ìš© ì˜ˆ
@app.post("/chat")
async def chat(request: ChatRequest):
    # 1. ìºì‹œ í™•ì¸
    cached = get_cached_response(request.message)
    if cached:
        return ChatResponse(response=cached, from_cache=True)

    # 2. Agent ì‹¤í–‰
    response = agent.invoke(...)
    answer = response['messages'][-1].content

    # 3. ìºì‹œ ì €ì¥
    set_cached_response(request.message, answer)

    return ChatResponse(response=answer, from_cache=False)
    ''')

    print("\nğŸ’¡ ìŠ¤ì¼€ì¼ë§ ëª¨ë²” ì‚¬ë¡€:")
    print("   â€¢ Stateless ì•„í‚¤í…ì²˜ (ì„¸ì…˜ì€ Redis ë“±ì— ì €ì¥)")
    print("   â€¢ ìë™ ìŠ¤ì¼€ì¼ë§ (HPA) ì„¤ì •")
    print("   â€¢ í—¬ìŠ¤ì²´í¬ í•„ìˆ˜ êµ¬í˜„")
    print("   â€¢ ë¡œë“œ ë°¸ëŸ°ì„œ ë’¤ì— ì—¬ëŸ¬ ì¸ìŠ¤í„´ìŠ¤")
    print("   â€¢ ìºì‹±ìœ¼ë¡œ ì¤‘ë³µ ìš”ì²­ ìµœì í™”")
    print("   â€¢ ë¹„ë™ê¸° ì‘ì—…ì€ í ì‹œìŠ¤í…œ ì‚¬ìš©")
    print("   â€¢ ëª¨ë‹ˆí„°ë§ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§ ì‹œì  íŒŒì•…")


# ============================================================================
# ì˜ˆì œ 4: í™˜ê²½ ì„¤ì • ê´€ë¦¬
# ============================================================================

def example_4_config_management():
    """í™˜ê²½ ì„¤ì • ê´€ë¦¬"""
    print("\n" + "=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 4: í™˜ê²½ ì„¤ì • ê´€ë¦¬")
    print("=" * 70)

    print("""
âš™ï¸ í™˜ê²½ ì„¤ì • ê´€ë¦¬:

ì™œ ì¤‘ìš”í•œê°€?
  â€¢ í™˜ê²½ë³„ ì„¤ì • ë¶„ë¦¬ (dev/staging/prod)
  â€¢ ë³´ì•ˆ (ë¹„ë°€í‚¤ ë³´í˜¸)
  â€¢ ìœ ì§€ë³´ìˆ˜ì„±
  â€¢ ë°°í¬ ìœ ì—°ì„±

í™˜ê²½ ì„¤ì • ê³„ì¸µ:
  1ï¸âƒ£ ê¸°ë³¸ ì„¤ì • (config.py)
  2ï¸âƒ£ í™˜ê²½ ë³€ìˆ˜ (.env)
  3ï¸âƒ£ ë¹„ë°€ ê´€ë¦¬ (Secrets Manager)
  4ï¸âƒ£ ëª…ë ¹ì¤„ ì¸ì

ì„¤ì • ìš°ì„ ìˆœìœ„:
  ëª…ë ¹ì¤„ > í™˜ê²½ ë³€ìˆ˜ > ì„¤ì • íŒŒì¼ > ê¸°ë³¸ê°’

ë„êµ¬:
  â€¢ python-dotenv (ë¡œì»¬)
  â€¢ AWS Secrets Manager (í”„ë¡œë•ì…˜)
  â€¢ HashiCorp Vault (ì—”í„°í”„ë¼ì´ì¦ˆ)
  â€¢ Kubernetes ConfigMap/Secrets
    """)

    print("\nğŸ”¹ ì„¤ì • ê´€ë¦¬ ì½”ë“œ:")
    print("-" * 70)

    print("""
ğŸ“„ config.py (ì„¤ì • í´ë˜ìŠ¤):
""")
    print('''
from pydantic_settings import BaseSettings
from typing import Optional

class Settings(BaseSettings):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •"""

    # API ì„¤ì •
    api_title: str = "LangChain Agent API"
    api_version: str = "1.0.0"
    api_host: str = "0.0.0.0"
    api_port: int = 8000

    # í™˜ê²½
    environment: str = "development"  # development, staging, production
    debug: bool = False

    # LLM ì„¤ì •
    openai_api_key: str
    openai_model: str = "gpt-4o-mini"
    openai_temperature: float = 0.7
    openai_max_tokens: int = 1000

    # LangSmith
    langsmith_api_key: Optional[str] = None
    langsmith_project: Optional[str] = None
    langsmith_tracing: bool = False

    # Redis
    redis_host: str = "localhost"
    redis_port: int = 6379
    redis_db: int = 0
    redis_password: Optional[str] = None

    # ë³´ì•ˆ
    api_key_enabled: bool = False
    api_keys: list[str] = []
    cors_origins: list[str] = ["*"]

    # ì„±ëŠ¥
    max_concurrent_requests: int = 100
    request_timeout: int = 60
    cache_ttl: int = 3600

    # ë¡œê¹…
    log_level: str = "INFO"
    log_format: str = "json"

    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"
        case_sensitive = False

# ì„¤ì • ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤)
settings = Settings()
''')

    print("\nğŸ“„ .env.example (í…œí”Œë¦¿):")
    print('''
# API ì„¤ì •
API_HOST=0.0.0.0
API_PORT=8000

# í™˜ê²½
ENVIRONMENT=development
DEBUG=true

# OpenAI
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4o-mini
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=1000

# LangSmith (ì„ íƒ)
LANGSMITH_API_KEY=
LANGSMITH_PROJECT=my-project
LANGSMITH_TRACING=false

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=

# ë³´ì•ˆ
API_KEY_ENABLED=false
API_KEYS=key1,key2,key3
CORS_ORIGINS=http://localhost:3000,https://example.com

# ì„±ëŠ¥
MAX_CONCURRENT_REQUESTS=100
REQUEST_TIMEOUT=60
CACHE_TTL=3600

# ë¡œê¹…
LOG_LEVEL=INFO
LOG_FORMAT=json
''')

    print("\nğŸ“„ í™˜ê²½ë³„ ì„¤ì • íŒŒì¼:")
    print('''
# .env.development
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=DEBUG

# .env.staging
ENVIRONMENT=staging
DEBUG=false
LOG_LEVEL=INFO

# .env.production
ENVIRONMENT=production
DEBUG=false
LOG_LEVEL=WARNING
API_KEY_ENABLED=true
LANGSMITH_TRACING=true
''')

    print("\nğŸ”¹ ì‚¬ìš© ì˜ˆì œ:")
    print('''
from config import settings
from fastapi import FastAPI, Depends, HTTPException, Security
from fastapi.security import APIKeyHeader

app = FastAPI(
    title=settings.api_title,
    version=settings.api_version,
    debug=settings.debug
)

# API Key ì¸ì¦
api_key_header = APIKeyHeader(name="X-API-Key", auto_error=False)

async def verify_api_key(api_key: str = Security(api_key_header)):
    """API Key ê²€ì¦"""
    if not settings.api_key_enabled:
        return True

    if api_key not in settings.api_keys:
        raise HTTPException(status_code=403, detail="Invalid API Key")

    return True

# ì„¤ì • ì‚¬ìš©
@app.post("/chat", dependencies=[Depends(verify_api_key)])
async def chat(request: ChatRequest):
    # OpenAI ì„¤ì • ì‚¬ìš©
    llm = ChatOpenAI(
        model=settings.openai_model,
        temperature=settings.openai_temperature,
        max_tokens=settings.openai_max_tokens
    )
    ...
''')

    print("\nğŸ”¹ í˜„ì¬ ì„¤ì • ì‹œë®¬ë ˆì´ì…˜:")
    print("-" * 70)

    # ê°„ë‹¨í•œ ì„¤ì • ì‹œë®¬ë ˆì´ì…˜
    config = {
        "environment": os.getenv("ENVIRONMENT", "development"),
        "api_host": os.getenv("API_HOST", "0.0.0.0"),
        "api_port": int(os.getenv("API_PORT", "8000")),
        "openai_model": os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
        "debug": os.getenv("DEBUG", "false").lower() == "true",
        "log_level": os.getenv("LOG_LEVEL", "INFO"),
    }

    print("\ní˜„ì¬ í™˜ê²½ ì„¤ì •:")
    for key, value in config.items():
        print(f"  â€¢ {key}: {value}")

    print("\n" + "-" * 70)

    print("\nğŸ’¡ í™˜ê²½ ì„¤ì • ëª¨ë²” ì‚¬ë¡€:")
    print("   â€¢ ë¹„ë°€í‚¤ëŠ” ì ˆëŒ€ Gitì— ì»¤ë°‹í•˜ì§€ ì•Šê¸°")
    print("   â€¢ .env.example ì œê³µ (í…œí”Œë¦¿)")
    print("   â€¢ í™˜ê²½ë³„ ì„¤ì • íŒŒì¼ ë¶„ë¦¬")
    print("   â€¢ Pydanticìœ¼ë¡œ ì„¤ì • ê²€ì¦")
    print("   â€¢ í”„ë¡œë•ì…˜ì—ì„œëŠ” Secrets Manager ì‚¬ìš©")
    print("   â€¢ ì„¤ì • ë³€ê²½ ì‹œ ì¬ì‹œì‘ ë¶ˆí•„ìš”í•˜ê²Œ ì„¤ê³„")
    print("   â€¢ ë¯¼ê° ì •ë³´ëŠ” ë¡œê·¸ì— ì¶œë ¥í•˜ì§€ ì•Šê¸°")


# ============================================================================
# ì˜ˆì œ 5: í”„ë¡œë•ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸
# ============================================================================

def example_5_production_checklist():
    """í”„ë¡œë•ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸"""
    print("\n" + "=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 5: í”„ë¡œë•ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸")
    print("=" * 70)

    print("""
âœ… í”„ë¡œë•ì…˜ ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸:

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ”’ ë³´ì•ˆ (Security)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  â˜ API Key / JWT ì¸ì¦ êµ¬í˜„
  â˜ Rate Limiting ì„¤ì •
  â˜ CORS ì •ì±… ì ì ˆíˆ ì œí•œ
  â˜ HTTPS ì ìš© (SSL/TLS)
  â˜ í™˜ê²½ ë³€ìˆ˜ë¡œ ë¹„ë°€í‚¤ ê´€ë¦¬
  â˜ SQL Injection ë°©ì§€
  â˜ XSS ë°©ì§€
  â˜ CSRF ë³´í˜¸
  â˜ ì…ë ¥ ê²€ì¦ (Pydantic)
  â˜ ì˜ì¡´ì„± ë³´ì•ˆ ì·¨ì•½ì  ìŠ¤ìº”

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš¡ ì„±ëŠ¥ (Performance)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  â˜ ë¡œë“œ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
  â˜ ìºì‹± ì „ëµ êµ¬í˜„
  â˜ ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ìŠ¤ ìµœì í™”
  â˜ ë¹„ë™ê¸° ì²˜ë¦¬ êµ¬í˜„
  â˜ ì •ì  íŒŒì¼ CDN ì‚¬ìš©
  â˜ ì‘ë‹µ ì••ì¶• (gzip)
  â˜ Connection Pooling
  â˜ ë¶ˆí•„ìš”í•œ ë¡œê¹… ì œê±°
  â˜ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í™•ì¸
  â˜ íƒ€ì„ì•„ì›ƒ ì„¤ì •

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ” ê´€ì¸¡ì„± (Observability)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  â˜ êµ¬ì¡°í™”ëœ ë¡œê¹… (JSON)
  â˜ ë¡œê·¸ ë ˆë²¨ ì ì ˆíˆ ì„¤ì •
  â˜ í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
  â˜ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (Prometheus)
  â˜ ë¶„ì‚° íŠ¸ë ˆì´ì‹± (Jaeger)
  â˜ ì—ëŸ¬ ì¶”ì  (Sentry)
  â˜ LangSmith íŠ¸ë ˆì´ì‹±
  â˜ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•
  â˜ ì•Œë¦¼ ì„¤ì • (Slack/PagerDuty)
  â˜ APM ë„êµ¬ (Datadog/New Relic)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ§ª í…ŒìŠ¤íŠ¸ (Testing)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  â˜ ìœ ë‹› í…ŒìŠ¤íŠ¸ (80%+ ì»¤ë²„ë¦¬ì§€)
  â˜ í†µí•© í…ŒìŠ¤íŠ¸
  â˜ E2E í…ŒìŠ¤íŠ¸
  â˜ ë¡œë“œ í…ŒìŠ¤íŠ¸
  â˜ ë³´ì•ˆ í…ŒìŠ¤íŠ¸
  â˜ CI/CD íŒŒì´í”„ë¼ì¸
  â˜ ìë™í™”ëœ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
  â˜ ìŠ¤í…Œì´ì§• í™˜ê²½ ê²€ì¦
  â˜ ì¹´ë‚˜ë¦¬ ë°°í¬
  â˜ ë¡¤ë°± ê³„íš

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“¦ ë°°í¬ (Deployment)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  â˜ Docker ì´ë¯¸ì§€ ìµœì í™”
  â˜ Kubernetes ë§¤ë‹ˆí˜ìŠ¤íŠ¸
  â˜ ìë™ ìŠ¤ì¼€ì¼ë§ (HPA)
  â˜ ë¡œë“œ ë°¸ëŸ°ì„œ ì„¤ì •
  â˜ ë¸”ë£¨-ê·¸ë¦° ë°°í¬ or ì¹´ë‚˜ë¦¬
  â˜ í—¬ìŠ¤ì²´í¬ ë° Readiness Probe
  â˜ ë¦¬ì†ŒìŠ¤ ì œí•œ ì„¤ì •
  â˜ í™˜ê²½ë³„ ì„¤ì • ë¶„ë¦¬
  â˜ ì‹œí¬ë¦¿ ê´€ë¦¬
  â˜ ë°±ì—… ë° ë³µêµ¬ ê³„íš

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“– ë¬¸ì„œí™” (Documentation)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  â˜ API ë¬¸ì„œ (Swagger/OpenAPI)
  â˜ README.md
  â˜ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨
  â˜ ë°°í¬ ê°€ì´ë“œ
  â˜ ìš´ì˜ ë§¤ë‰´ì–¼
  â˜ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ
  â˜ í™˜ê²½ ë³€ìˆ˜ ë¬¸ì„œ
  â˜ ì˜ì¡´ì„± ëª©ë¡
  â˜ ë³€ê²½ ì´ë ¥ (CHANGELOG)
  â˜ ë¼ì´ì„¼ìŠ¤

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ›¡ï¸ ì•ˆì •ì„± (Reliability)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  â˜ ì¬ì‹œë„ ë¡œì§
  â˜ Circuit Breaker
  â˜ Graceful Shutdown
  â˜ ë°ì´í„° ë°±ì—…
  â˜ ì¬í•´ ë³µêµ¬ ê³„íš
  â˜ ë‹¤ì¤‘ AZ ë°°í¬
  â˜ ëª¨ë‹ˆí„°ë§ ì•Œë¦¼
  â˜ SLA ì •ì˜
  â˜ ì¸ì‹œë˜íŠ¸ ëŒ€ì‘ í”„ë¡œì„¸ìŠ¤
  â˜ ì •ê¸° ì ê²€ ê³„íš

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ’° ë¹„ìš© (Cost)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  â˜ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
  â˜ ë¶ˆí•„ìš”í•œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
  â˜ ì˜ˆì‚° ì•Œë¦¼ ì„¤ì •
  â˜ í† í° ì‚¬ìš©ëŸ‰ ì¶”ì 
  â˜ ìºì‹±ìœ¼ë¡œ ë¹„ìš© ì ˆê°
  â˜ ì˜¤í†  ìŠ¤ì¼€ì¼ë§ ìµœì í™”
  â˜ Reserved Instances ê³ ë ¤
  â˜ Spot Instances í™œìš©
  â˜ ë¹„ìš© ëŒ€ì‹œë³´ë“œ
  â˜ ì •ê¸° ë¹„ìš© ë¦¬ë·°

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ‘¥ íŒ€ í˜‘ì—… (Collaboration)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  â˜ Git ë¸Œëœì¹˜ ì „ëµ
  â˜ Code Review í”„ë¡œì„¸ìŠ¤
  â˜ ì½”ë“œ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ
  â˜ Pre-commit Hooks
  â˜ ì´ìŠˆ íŠ¸ë˜í‚¹
  â˜ ë²„ì „ ê´€ë¦¬ ì „ëµ
  â˜ ë°°í¬ ìŠ¹ì¸ í”„ë¡œì„¸ìŠ¤
  â˜ On-call ë¡œí…Œì´ì…˜
  â˜ ì§€ì‹ ê³µìœ  ì„¸ì…˜
  â˜ í¬ìŠ¤íŠ¸ëª¨í…œ ë¬¸í™”
    """)

    print("\nğŸ”¹ í”„ë¡œë•ì…˜ ë°°í¬ ì „ ìµœì¢… ì²´í¬:")
    print("-" * 70)

    # ê°„ë‹¨í•œ í—¬ìŠ¤ì²´í¬ ì‹œë®¬ë ˆì´ì…˜
    checks = {
        "í™˜ê²½ ë³€ìˆ˜ ì„¤ì •": bool(os.getenv("OPENAI_API_KEY")),
        "Dependencies ì„¤ì¹˜": True,  # ì‹¤ì œë¡œëŠ” import í…ŒìŠ¤íŠ¸
        "ì„¤ì • íŒŒì¼ ì¡´ì¬": os.path.exists(".env") if os.path.exists(".env") else False,
        "Debug ëª¨ë“œ off": os.getenv("DEBUG", "false").lower() == "false",
        "ë¡œê·¸ ë ˆë²¨ ì ì ˆ": os.getenv("LOG_LEVEL", "INFO") in ["INFO", "WARNING", "ERROR"],
    }

    print("\nìë™ ì²´í¬ ê²°ê³¼:")
    all_passed = True
    for check, result in checks.items():
        status = "âœ…" if result else "âŒ"
        print(f"  {status} {check}")
        if not result:
            all_passed = False

    print("\n" + "-" * 70)

    if all_passed:
        print("\nğŸ‰ ëª¨ë“  ì²´í¬ í†µê³¼! ë°°í¬ ì¤€ë¹„ ì™„ë£Œ")
        print("\në‹¤ìŒ ë‹¨ê³„:")
        print("  1. ìŠ¤í…Œì´ì§• í™˜ê²½ì— ë°°í¬")
        print("  2. ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
        print("  3. í”„ë¡œë•ì…˜ ë°°í¬ (ì¹´ë‚˜ë¦¬ or ë¸”ë£¨-ê·¸ë¦°)")
        print("  4. ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ í™•ì¸")
        print("  5. ì•Œë¦¼ ì±„ë„ ì¤€ë¹„")
    else:
        print("\nâš ï¸  ì¼ë¶€ ì²´í¬ ì‹¤íŒ¨. ë¬¸ì œë¥¼ í•´ê²°í•œ í›„ ì¬ì‹œë„í•˜ì„¸ìš”.")

    print("\nğŸ’¡ í”„ë¡œë•ì…˜ ìš´ì˜ íŒ:")
    print("   â€¢ ì‘ì€ ë³€ê²½ë„ ìŠ¤í…Œì´ì§•ì—ì„œ ë¨¼ì € í…ŒìŠ¤íŠ¸")
    print("   â€¢ ë°°í¬ ì‹œê°„ëŒ€ ê³ ë ¤ (íŠ¸ë˜í”½ ë‚®ì€ ì‹œê°„)")
    print("   â€¢ ë¡¤ë°± ê³„íš í•­ìƒ ì¤€ë¹„")
    print("   â€¢ ëª¨ë‹ˆí„°ë§ ì•Œë¦¼ ì¦‰ì‹œ ëŒ€ì‘")
    print("   â€¢ ì •ê¸°ì ì¸ ë³´ì•ˆ íŒ¨ì¹˜")
    print("   â€¢ ì¸ì‹œë˜íŠ¸ í›„ í¬ìŠ¤íŠ¸ëª¨í…œ ì‘ì„±")
    print("   â€¢ ì§€ì†ì ì¸ ì„±ëŠ¥ ìµœì í™”")


# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("\n" + "=" * 70)
    print("ğŸ“ LangChain AI Agent ë§ˆìŠ¤í„° êµì•ˆ")
    print("ğŸ“– Part 10: ë°°í¬ì™€ ê´€ì¸¡ì„± - ë°°í¬")
    print("=" * 70 + "\n")

    # ì˜ˆì œ ì‹¤í–‰
    example_1_docker()
    input("\nâ ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")

    example_2_api_server()
    input("\nâ ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")

    example_3_scaling()
    input("\nâ ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")

    example_4_config_management()
    input("\nâ ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")

    example_5_production_checklist()

    # ë§ˆë¬´ë¦¬
    print("\n" + "=" * 70)
    print("ğŸ‰ Part 10-05: ë°°í¬ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤!")
    print("=" * 70)
    print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print("  1. 06_observability.py - ê´€ì¸¡ì„±")
    print("\nğŸ“š í•µì‹¬ ìš”ì•½:")
    print("  â€¢ Dockerë¡œ ì• í”Œë¦¬ì¼€ì´ì…˜ ì»¨í…Œì´ë„ˆí™”")
    print("  â€¢ FastAPIë¡œ REST API ì„œë²„ êµ¬ì¶•")
    print("  â€¢ ìˆ˜í‰ ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ íŠ¸ë˜í”½ ëŒ€ì‘")
    print("  â€¢ í™˜ê²½ë³„ ì„¤ì • ë¶„ë¦¬ ë° ê´€ë¦¬")
    print("  â€¢ í”„ë¡œë•ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì¤€ìˆ˜")
    print("\n" + "=" * 70 + "\n")


# ============================================================================
# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
# ============================================================================

if __name__ == "__main__":
    main()


# ============================================================================
# ğŸ“š ì¶”ê°€ í•™ìŠµ í¬ì¸íŠ¸
# ============================================================================
#
# 1. ì»¨í…Œì´ë„ˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜:
#    - Kubernetes
#    - Docker Swarm
#    - AWS ECS/EKS
#    - Google GKE
#
# 2. CI/CD:
#    - GitHub Actions
#    - GitLab CI
#    - Jenkins
#    - ArgoCD (GitOps)
#
# 3. í´ë¼ìš°ë“œ í”Œë«í¼:
#    - AWS (Lambda, ECS, API Gateway)
#    - Google Cloud (Cloud Run, GKE)
#    - Azure (Container Apps)
#    - Vercel, Fly.io
#
# 4. ì„œë¹„ìŠ¤ ë©”ì‹œ:
#    - Istio
#    - Linkerd
#    - Consul
#
# 5. ë°°í¬ ì „ëµ:
#    - Blue-Green Deployment
#    - Canary Deployment
#    - Rolling Update
#    - Feature Flags
#
# ============================================================================
