"""
================================================================================
LangChain AI Agent ë§ˆìŠ¤í„° êµì•ˆ
Part 4: Memory System - Message Trim
================================================================================

íŒŒì¼ëª…: 03_message_trim.py
ë‚œì´ë„: â­â­â­â˜†â˜† (ì¤‘ê¸‰)
ì˜ˆìƒ ì‹œê°„: 20ë¶„

ğŸ“š í•™ìŠµ ëª©í‘œ:
  - Context Window ë¬¸ì œ ì´í•´
  - before_model ë¯¸ë“¤ì›¨ì–´ë¡œ ë©”ì‹œì§€ Trim êµ¬í˜„
  - ë‹¤ì–‘í•œ Trim ì „ëµ í•™ìŠµ
  - Delete vs Trim ì°¨ì´ ì´í•´
  - Message í•„í„°ë§ ê¸°ë²•

ğŸ“– ê³µì‹ ë¬¸ì„œ:
  â€¢ Short-term Memory: /official/10-short-term-memory.md

ğŸ“„ êµì•ˆ ë¬¸ì„œ:
  â€¢ Part 4 ë©”ëª¨ë¦¬: /docs/part04_memory.md (Section 3)

ğŸ”§ í•„ìš”í•œ íŒ¨í‚¤ì§€:
  pip install langchain langchain-openai langgraph python-dotenv

ğŸ”‘ í•„ìš”í•œ í™˜ê²½ë³€ìˆ˜:
  - OPENAI_API_KEY

ğŸš€ ì‹¤í–‰ ë°©ë²•:
  python 03_message_trim.py

================================================================================
"""

# ============================================================================
# Imports
# ============================================================================

import os
from typing import Any
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.agents import create_agent, AgentState
from langchain.agents.middleware import before_model, after_model
from langchain_core.messages import RemoveMessage
from langgraph.graph.message import REMOVE_ALL_MESSAGES
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.runtime import Runtime
from langchain_core.runnables import RunnableConfig

# ============================================================================
# í™˜ê²½ ì„¤ì •
# ============================================================================

load_dotenv()

if not os.getenv("OPENAI_API_KEY"):
    print("âŒ ì˜¤ë¥˜: OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    exit(1)

# ============================================================================
# ì˜ˆì œ 1: Context Window ë¬¸ì œ ì‹œì—°
# ============================================================================

def example_1_context_overflow():
    """Context Windowê°€ ê°€ë“ ì°¼ì„ ë•Œì˜ ë¬¸ì œ"""
    print("=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 1: Context Window ë¬¸ì œ")
    print("=" * 70)
    print("\nğŸ’¡ ê¸´ ëŒ€í™”ëŠ” Context Windowë¥¼ ì´ˆê³¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n")

    checkpointer = InMemorySaver()
    agent = create_agent(
        model="gpt-4o-mini",
        tools=[],
        checkpointer=checkpointer,
    )

    config: RunnableConfig = {"configurable": {"thread_id": "overflow-test"}}

    # ë§ì€ ë©”ì‹œì§€ ìƒì„± (ì‹œë®¬ë ˆì´ì…˜)
    print("=" * 50)
    print("ğŸ“ ê¸´ ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜")
    print("=" * 50)

    topics = [
        "íŒŒì´ì¬ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.",
        "ìë°”ìŠ¤í¬ë¦½íŠ¸ëŠ” ì–´ë–¤ê°€ìš”?",
        "ëŸ¬ìŠ¤íŠ¸ì— ëŒ€í•´ì„œë„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "Go ì–¸ì–´ëŠ” ì–´ë–¤ íŠ¹ì§•ì´ ìˆë‚˜ìš”?",
        "ì½”í‹€ë¦°ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.",
        "íƒ€ì…ìŠ¤í¬ë¦½íŠ¸ëŠ” ì™œ ì¸ê¸°ê°€ ìˆë‚˜ìš”?",
        "ìŠ¤ìœ„í”„íŠ¸ì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "C++ëŠ” ì•„ì§ë„ ë§ì´ ì“°ì´ë‚˜ìš”?",
    ]

    for i, topic in enumerate(topics, 1):
        print(f"\nëŒ€í™” {i}:")
        print(f"ğŸ‘¤ ì‚¬ìš©ì: {topic}")

        result = agent.invoke(
            {"messages": [{"role": "user", "content": topic}]},
            config
        )

        # ì‘ë‹µ ê¸¸ì´ ì œí•œí•˜ì—¬ ì¶œë ¥
        response = result['messages'][-1].content
        print(f"ğŸ¤– AI: {response[:100]}...")

    # í˜„ì¬ ìƒíƒœ í™•ì¸
    state = agent.get_state(config)
    messages = state.values["messages"]

    print(f"\nğŸ“Š í˜„ì¬ ìƒíƒœ:")
    print(f"   - ì „ì²´ ë©”ì‹œì§€ ìˆ˜: {len(messages)}")
    print(f"   - ì‚¬ìš©ì ë©”ì‹œì§€: {sum(1 for m in messages if m.type == 'human')}")
    print(f"   - AI ë©”ì‹œì§€: {sum(1 for m in messages if m.type == 'ai')}")

    # ëŒ€ëµì ì¸ í† í° ìˆ˜ ì¶”ì •
    total_chars = sum(len(m.content) for m in messages if hasattr(m, 'content'))
    estimated_tokens = total_chars // 4  # ëŒ€ëµ 4ì = 1í† í°

    print(f"   - ì´ ë¬¸ì ìˆ˜: {total_chars:,}")
    print(f"   - ì˜ˆìƒ í† í° ìˆ˜: ~{estimated_tokens:,}")

    print("\nâš ï¸  ë¬¸ì œì :")
    print("   - ë©”ì‹œì§€ê°€ ê³„ì† ìŒ“ì´ë©´ Context Window ì´ˆê³¼")
    print("   - LLM ì„±ëŠ¥ ì €í•˜ (ê¸´ ì»¨í…ìŠ¤íŠ¸)")
    print("   - API ë¹„ìš© ì¦ê°€")
    print("   - ì‘ë‹µ ì†ë„ ì €í•˜")

    print("\nğŸ’¡ í•´ê²°ì±…:")
    print("   - Message Trim: ì˜¤ë˜ëœ ë©”ì‹œì§€ ì œê±°")
    print("   - Message Summarization: ìš”ì•½ ìƒì„±")
    print("   - Message Delete: ì˜êµ¬ ì‚­ì œ")


# ============================================================================
# ì˜ˆì œ 2: before_modelë¡œ ë©”ì‹œì§€ Trim
# ============================================================================

def example_2_trim_messages():
    """before_model ë¯¸ë“¤ì›¨ì–´ë¡œ ë©”ì‹œì§€ ì œí•œ"""
    print("\n" + "=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 2: before_modelë¡œ ë©”ì‹œì§€ Trim")
    print("=" * 70)
    print("\nğŸ’¡ LLM í˜¸ì¶œ ì „ì— ë©”ì‹œì§€ ê°œìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤.\n")

    # Trim ë¯¸ë“¤ì›¨ì–´ ì •ì˜
    @before_model
    def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
        """ìµœê·¼ Nê°œì˜ ë©”ì‹œì§€ë§Œ ìœ ì§€"""
        messages = state["messages"]

        # ë©”ì‹œì§€ê°€ 5ê°œ ì´í•˜ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€
        if len(messages) <= 5:
            return None

        # ì²« ë©”ì‹œì§€(ì‹œìŠ¤í…œ ë©”ì‹œì§€) + ìµœê·¼ 4ê°œ ë©”ì‹œì§€
        # í™€ìˆ˜/ì§ìˆ˜ ì¡°ì • (ì‚¬ìš©ì-AI ìŒ ìœ ì§€)
        if len(messages) % 2 == 0:
            recent = messages[-4:]
        else:
            recent = messages[-3:]

        print(f"âœ‚ï¸  Trim: {len(messages)}ê°œ â†’ {len(recent) + 1}ê°œ ë©”ì‹œì§€")

        # REMOVE_ALL_MESSAGESë¡œ ì „ì²´ ì‚­ì œ í›„ ì¬êµ¬ì„±
        return {
            "messages": [
                RemoveMessage(id=REMOVE_ALL_MESSAGES),
                messages[0],  # ì²« ë©”ì‹œì§€ ìœ ì§€ (ì‹œìŠ¤í…œ ë©”ì‹œì§€)
                *recent
            ]
        }

    checkpointer = InMemorySaver()
    agent = create_agent(
        model="gpt-4o-mini",
        tools=[],
        middleware=[trim_messages],  # ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€
        checkpointer=checkpointer,
        system_prompt="ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."
    )

    config: RunnableConfig = {"configurable": {"thread_id": "trim-test"}}

    # ì—¬ëŸ¬ ëŒ€í™” ì§„í–‰
    conversations = [
        "ì•ˆë…•í•˜ì„¸ìš”!",
        "ì œ ì´ë¦„ì€ ê¹€ì² ìˆ˜ì…ë‹ˆë‹¤.",
        "ì €ëŠ” ì„œìš¸ì— ì‚´ì•„ìš”.",
        "íŒŒì´ì¬ì„ ì¢‹ì•„í•©ë‹ˆë‹¤.",
        "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”.",
        "ì €ë… ë©”ë‰´ ì¶”ì²œí•´ì£¼ì„¸ìš”.",
        "ì œ ì´ë¦„ì´ ë­ì˜€ì£ ?",  # ì´ˆê¸° ì •ë³´ëŠ” ìŠì–´ë²„ë¦¼
    ]

    for i, msg in enumerate(conversations, 1):
        print(f"\nëŒ€í™” {i}:")
        print(f"ğŸ‘¤ ì‚¬ìš©ì: {msg}")

        result = agent.invoke(
            {"messages": [{"role": "user", "content": msg}]},
            config
        )

        print(f"ğŸ¤– AI: {result['messages'][-1].content}")

        # í˜„ì¬ ë©”ì‹œì§€ ìˆ˜
        state = agent.get_state(config)
        msg_count = len(state.values["messages"])
        print(f"   ğŸ“Š í˜„ì¬ ë©”ì‹œì§€ ìˆ˜: {msg_count}")

    print("\nğŸ’¡ ê²°ê³¼:")
    print("   - Trimìœ¼ë¡œ ë©”ì‹œì§€ ìˆ˜ê°€ ì œí•œë¨")
    print("   - ì˜¤ë˜ëœ ì •ë³´ëŠ” ê¸°ì–µí•˜ì§€ ëª»í•¨")
    print("   - Context Window ì´ˆê³¼ ë°©ì§€")


# ============================================================================
# ì˜ˆì œ 3: ì²« ë©”ì‹œì§€ + ìµœê·¼ Nê°œ ìœ ì§€ ì „ëµ
# ============================================================================

def example_3_keep_first_and_recent():
    """ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ìµœê·¼ ë©”ì‹œì§€ ëª¨ë‘ ìœ ì§€"""
    print("\n" + "=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 3: ì²« ë©”ì‹œì§€ + ìµœê·¼ ë©”ì‹œì§€ ìœ ì§€ ì „ëµ")
    print("=" * 70)
    print("\nğŸ’¡ ì¤‘ìš”í•œ ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” í•­ìƒ ìœ ì§€í•©ë‹ˆë‹¤.\n")

    @before_model
    def smart_trim(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
        """ì‹œìŠ¤í…œ ë©”ì‹œì§€ + ìµœê·¼ ëŒ€í™” ìœ ì§€"""
        messages = state["messages"]

        MAX_RECENT = 6  # ìµœê·¼ 6ê°œ ìœ ì§€

        if len(messages) <= MAX_RECENT + 1:
            return None

        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ë“¤ (ì²˜ìŒ Nê°œ)
        system_messages = []
        for msg in messages:
            if msg.type == "system":
                system_messages.append(msg)
            else:
                break

        # ìµœê·¼ ë©”ì‹œì§€ë“¤
        recent_messages = messages[-MAX_RECENT:]

        print(f"âœ‚ï¸  Smart Trim:")
        print(f"   - ì‹œìŠ¤í…œ ë©”ì‹œì§€: {len(system_messages)}ê°œ")
        print(f"   - ìµœê·¼ ë©”ì‹œì§€: {len(recent_messages)}ê°œ")
        print(f"   - ì‚­ì œëœ ë©”ì‹œì§€: {len(messages) - len(system_messages) - len(recent_messages)}ê°œ")

        return {
            "messages": [
                RemoveMessage(id=REMOVE_ALL_MESSAGES),
                *system_messages,
                *recent_messages
            ]
        }

    checkpointer = InMemorySaver()
    agent = create_agent(
        model="gpt-4o-mini",
        tools=[],
        middleware=[smart_trim],
        checkpointer=checkpointer,
        system_prompt="ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìë¥¼ ì¡´ì¤‘í•˜ë©° ëŒ€í™”í•˜ì„¸ìš”."
    )

    config: RunnableConfig = {"configurable": {"thread_id": "smart-trim-test"}}

    # ê¸´ ëŒ€í™”
    for i in range(1, 11):
        msg = f"ë©”ì‹œì§€ ë²ˆí˜¸ {i}ì…ë‹ˆë‹¤."
        print(f"\nğŸ‘¤ ì‚¬ìš©ì: {msg}")

        result = agent.invoke(
            {"messages": [{"role": "user", "content": msg}]},
            config
        )

        print(f"ğŸ¤– AI: {result['messages'][-1].content[:50]}...")


# ============================================================================
# ì˜ˆì œ 4: after_modelë¡œ ë©”ì‹œì§€ ì˜êµ¬ ì‚­ì œ
# ============================================================================

def example_4_delete_messages():
    """after_modelë¡œ ë©”ì‹œì§€ë¥¼ ì˜êµ¬ì ìœ¼ë¡œ ì‚­ì œ"""
    print("\n" + "=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 4: ë©”ì‹œì§€ ì˜êµ¬ ì‚­ì œ (Delete)")
    print("=" * 70)
    print("\nğŸ’¡ after_modelì€ ë©”ì‹œì§€ë¥¼ Checkpointerì—ì„œë„ ì œê±°í•©ë‹ˆë‹¤.\n")

    @after_model
    def delete_old_messages(state: AgentState, runtime: Runtime) -> dict | None:
        """ì˜¤ë˜ëœ ë©”ì‹œì§€ ì˜êµ¬ ì‚­ì œ"""
        messages = state["messages"]

        # ë©”ì‹œì§€ê°€ 8ê°œ ì´ˆê³¼ ì‹œ ê°€ì¥ ì˜¤ë˜ëœ 2ê°œ ì‚­ì œ
        if len(messages) > 8:
            to_delete = messages[1:3]  # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” ì œì™¸
            print(f"ğŸ—‘ï¸  ì˜êµ¬ ì‚­ì œ: {len(to_delete)}ê°œ ë©”ì‹œì§€")

            return {
                "messages": [RemoveMessage(id=msg.id) for msg in to_delete]
            }

        return None

    checkpointer = InMemorySaver()
    agent = create_agent(
        model="gpt-4o-mini",
        tools=[],
        middleware=[delete_old_messages],
        checkpointer=checkpointer,
    )

    config: RunnableConfig = {"configurable": {"thread_id": "delete-test"}}

    print("=" * 50)
    print("ğŸ“ ëŒ€í™” ì§„í–‰ ë° ë©”ì‹œì§€ ì‚­ì œ")
    print("=" * 50)

    for i in range(1, 8):
        msg = f"ëŒ€í™” {i}"
        print(f"\nğŸ‘¤ ì‚¬ìš©ì: {msg}")

        result = agent.invoke(
            {"messages": [{"role": "user", "content": msg}]},
            config
        )

        print(f"ğŸ¤– AI: {result['messages'][-1].content[:50]}...")

        # ìƒíƒœ í™•ì¸
        state = agent.get_state(config)
        msg_count = len(state.values["messages"])
        print(f"   ğŸ“Š ë©”ì‹œì§€ ìˆ˜: {msg_count}")

    print("\nğŸ’¡ Trim vs Delete:")
    print("   - Trim: í˜„ì¬ í˜¸ì¶œì—ë§Œ ì ìš©, ë‹¤ìŒ í˜¸ì¶œì—” ë³µì›")
    print("   - Delete: Checkpointerì—ì„œ ì˜êµ¬ ì œê±°, ë³µêµ¬ ë¶ˆê°€")


# ============================================================================
# ì˜ˆì œ 5: ê³ ê¸‰ í•„í„°ë§ ì „ëµ
# ============================================================================

def example_5_message_filtering():
    """ë©”ì‹œì§€ íƒ€ì…ë³„ í•„í„°ë§"""
    print("\n" + "=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 5: ê³ ê¸‰ ë©”ì‹œì§€ í•„í„°ë§")
    print("=" * 70)
    print("\nğŸ’¡ íŠ¹ì • ì¡°ê±´ì˜ ë©”ì‹œì§€ë§Œ ì„ íƒì ìœ¼ë¡œ ìœ ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n")

    @before_model
    def filter_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
        """Tool ë©”ì‹œì§€ë¥¼ ì œê±°í•˜ê³  ëŒ€í™”ë§Œ ìœ ì§€"""
        messages = state["messages"]

        if len(messages) <= 10:
            return None

        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ëŒ€í™” ë©”ì‹œì§€ë§Œ ìœ ì§€ (Tool ë©”ì‹œì§€ ì œì™¸)
        filtered = []
        for msg in messages:
            if msg.type in ["system", "human", "ai"]:
                # Tool callì´ ì—†ëŠ” AI ë©”ì‹œì§€ë§Œ í¬í•¨
                if msg.type == "ai":
                    if not hasattr(msg, "tool_calls") or not msg.tool_calls:
                        filtered.append(msg)
                else:
                    filtered.append(msg)

        # ë„ˆë¬´ ë§ìœ¼ë©´ ìµœê·¼ ê²ƒë§Œ
        if len(filtered) > 10:
            filtered = [filtered[0]] + filtered[-9:]

        print(f"ğŸ” í•„í„°ë§:")
        print(f"   - ì›ë³¸: {len(messages)}ê°œ")
        print(f"   - í•„í„°ë§ í›„: {len(filtered)}ê°œ")

        return {
            "messages": [
                RemoveMessage(id=REMOVE_ALL_MESSAGES),
                *filtered
            ]
        }

    from langchain.tools import tool

    @tool
    def get_info(query: str) -> str:
        """ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
        return f"'{query}'ì— ëŒ€í•œ ì •ë³´ì…ë‹ˆë‹¤."

    checkpointer = InMemorySaver()
    agent = create_agent(
        model="gpt-4o-mini",
        tools=[get_info],
        middleware=[filter_messages],
        checkpointer=checkpointer,
    )

    config: RunnableConfig = {"configurable": {"thread_id": "filter-test"}}

    # Toolì„ ì‚¬ìš©í•˜ëŠ” ëŒ€í™”
    conversations = [
        "ì•ˆë…•í•˜ì„¸ìš”!",
        "ë‚ ì”¨ ì •ë³´ë¥¼ ì¡°íšŒí•´ì£¼ì„¸ìš”.",
        "ë‰´ìŠ¤ë„ í™•ì¸í•´ì£¼ì„¸ìš”.",
        "ì˜¤ëŠ˜ ì¼ì •ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
        "ê°ì‚¬í•©ë‹ˆë‹¤.",
    ]

    for msg in conversations:
        print(f"\nğŸ‘¤ ì‚¬ìš©ì: {msg}")
        result = agent.invoke(
            {"messages": [{"role": "user", "content": msg}]},
            config
        )
        print(f"ğŸ¤– AI: {result['messages'][-1].content[:80]}...")

    print("\nğŸ’¡ í•„í„°ë§ ì „ëµ:")
    print("   - Tool ë©”ì‹œì§€ ì œê±°ë¡œ í† í° ì ˆì•½")
    print("   - í•µì‹¬ ëŒ€í™” ë‚´ìš©ë§Œ ìœ ì§€")
    print("   - Context Window íš¨ìœ¨ì  ì‚¬ìš©")


# ============================================================================
# ë³´ë„ˆìŠ¤: í† í° ê¸°ë°˜ Trim
# ============================================================================

def bonus_token_based_trim():
    """í† í° ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë©”ì‹œì§€ Trim"""
    print("\n" + "=" * 70)
    print("ğŸ ë³´ë„ˆìŠ¤: í† í° ê¸°ë°˜ Trim")
    print("=" * 70)
    print("\nğŸ’¡ ë©”ì‹œì§€ ê°œìˆ˜ê°€ ì•„ë‹Œ í† í° ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì œí•œí•©ë‹ˆë‹¤.\n")

    def estimate_tokens(messages) -> int:
        """ê°„ë‹¨í•œ í† í° ìˆ˜ ì¶”ì • (ì‹¤ì œë¡œëŠ” tiktoken ì‚¬ìš© ê¶Œì¥)"""
        total_chars = sum(
            len(m.content) for m in messages
            if hasattr(m, 'content') and m.content
        )
        return total_chars // 4  # ëŒ€ëµ 4ì = 1í† í°

    @before_model
    def trim_by_tokens(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
        """í† í° ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ Trim"""
        messages = state["messages"]
        MAX_TOKENS = 500  # ìµœëŒ€ í† í° ìˆ˜

        current_tokens = estimate_tokens(messages)

        if current_tokens <= MAX_TOKENS:
            return None

        # ë’¤ì—ì„œë¶€í„° ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•˜ë©´ì„œ í† í° ìˆ˜ í™•ì¸
        kept_messages = [messages[0]]  # ì‹œìŠ¤í…œ ë©”ì‹œì§€
        current_tokens = estimate_tokens([messages[0]])

        for msg in reversed(messages[1:]):
            msg_tokens = estimate_tokens([msg])
            if current_tokens + msg_tokens <= MAX_TOKENS:
                kept_messages.insert(1, msg)
                current_tokens += msg_tokens
            else:
                break

        print(f"ğŸ“Š í† í° ê¸°ë°˜ Trim:")
        print(f"   - ì›ë³¸ í† í°: ~{estimate_tokens(messages)}")
        print(f"   - Trim í›„: ~{estimate_tokens(kept_messages)}")
        print(f"   - ìœ ì§€ ë©”ì‹œì§€: {len(kept_messages)}/{len(messages)}")

        return {
            "messages": [
                RemoveMessage(id=REMOVE_ALL_MESSAGES),
                *kept_messages
            ]
        }

    checkpointer = InMemorySaver()
    agent = create_agent(
        model="gpt-4o-mini",
        tools=[],
        middleware=[trim_by_tokens],
        checkpointer=checkpointer,
    )

    config: RunnableConfig = {"configurable": {"thread_id": "token-trim-test"}}

    # ë‹¤ì–‘í•œ ê¸¸ì´ì˜ ë©”ì‹œì§€
    long_messages = [
        "ì§§ì€ ë©”ì‹œì§€",
        "ì´ê²ƒì€ ì¡°ê¸ˆ ë” ê¸´ ë©”ì‹œì§€ì…ë‹ˆë‹¤. " * 5,
        "ë˜ ë‹¤ë¥¸ ë©”ì‹œì§€",
        "ì´ê²ƒì€ ë§¤ìš° ê¸´ ë©”ì‹œì§€ì…ë‹ˆë‹¤. " * 10,
        "ë§ˆì§€ë§‰ ë©”ì‹œì§€"
    ]

    for i, msg in enumerate(long_messages, 1):
        print(f"\nëŒ€í™” {i}: (ê¸¸ì´: {len(msg)}ì)")
        print(f"ğŸ‘¤ ì‚¬ìš©ì: {msg[:50]}...")

        result = agent.invoke(
            {"messages": [{"role": "user", "content": msg}]},
            config
        )

        print(f"ğŸ¤– AI: {result['messages'][-1].content[:50]}...")


# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("\n")
    print("ğŸ“ LangChain AI Agent ë§ˆìŠ¤í„° êµì•ˆ")
    print("ğŸ“– Part 4: Memory System - Message Trim")
    print("\n")

    # ì˜ˆì œ 1: Context Window ë¬¸ì œ
    example_1_context_overflow()
    input("\nâ ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")

    # ì˜ˆì œ 2: Trim Messages
    example_2_trim_messages()
    input("\nâ ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")

    # ì˜ˆì œ 3: Smart Trim
    example_3_keep_first_and_recent()
    input("\nâ ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")

    # ì˜ˆì œ 4: Delete Messages
    example_4_delete_messages()
    input("\nâ ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")

    # ì˜ˆì œ 5: Filtering
    example_5_message_filtering()
    input("\nâ ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")

    # ë³´ë„ˆìŠ¤: Token-based Trim
    print("\n" + "=" * 70)
    choice = input("ğŸ ë³´ë„ˆìŠ¤ ì˜ˆì œë¥¼ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
    if choice == 'y':
        bonus_token_based_trim()

    # ë§ˆë¬´ë¦¬
    print("\n" + "=" * 70)
    print("ğŸ‰ Part 4-3 ì˜ˆì œë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤!")
    print("=" * 70)
    print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print("  1. 04_summarization.py - Message Summarization")
    print("  2. 05_custom_state.py - Custom State")
    print("  3. 06_long_term_store.py - Long-term Memory")
    print("\nğŸ“š í•µì‹¬ ê°œë… ë³µìŠµ:")
    print("  â€¢ before_model: LLM í˜¸ì¶œ ì „ ë©”ì‹œì§€ ì²˜ë¦¬")
    print("  â€¢ after_model: LLM í˜¸ì¶œ í›„ ë©”ì‹œì§€ ì²˜ë¦¬")
    print("  â€¢ Trim: í˜„ì¬ í˜¸ì¶œì—ë§Œ ì ìš© (ë³µêµ¬ ê°€ëŠ¥)")
    print("  â€¢ Delete: ì˜êµ¬ ì‚­ì œ (ë³µêµ¬ ë¶ˆê°€)")
    print("  â€¢ ì „ëµ: ê°œìˆ˜, í† í°, í•„í„°ë§ ê¸°ë°˜")
    print("\n" + "=" * 70 + "\n")


if __name__ == "__main__":
    main()


# ============================================================================
# ğŸ“š ì¶”ê°€ í•™ìŠµ í¬ì¸íŠ¸
# ============================================================================
#
# 1. ì‹¤ì œ í† í° ê³„ì‚°:
#    import tiktoken
#    encoding = tiktoken.encoding_for_model("gpt-4o-mini")
#    tokens = encoding.encode(text)
#    token_count = len(tokens)
#
# 2. Trim ì „ëµ ì„ íƒ:
#    - ë‹¨ìˆœ ëŒ€í™”: ìµœê·¼ Nê°œ
#    - ë³µì¡í•œ ì‘ì—…: í† í° ê¸°ë°˜
#    - Tool ë§ìŒ: í•„í„°ë§ ê¸°ë°˜
#
# 3. Context Window í¬ê¸°:
#    - GPT-4o-mini: 128K tokens
#    - GPT-4o: 128K tokens
#    - Claude 3.5: 200K tokens
#
# 4. ì•ˆì „ ì—¬ìœ ë¶„:
#    MAX_TOKENS = CONTEXT_WINDOW * 0.8  # 20% ì—¬ìœ 
#
# ============================================================================
