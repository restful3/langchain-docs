"""
================================================================================
LangChain AI Agent ë§ˆìŠ¤í„° êµì•ˆ
Part 4: Memory - ì‹¤ìŠµ ê³¼ì œ 2 í•´ë‹µ
================================================================================

ê³¼ì œ: ìë™ ìš”ì•½ ì‹œìŠ¤í…œ
ë‚œì´ë„: â­â­â­â˜†â˜† (ì¤‘ê¸‰)

ìš”êµ¬ì‚¬í•­:
1. ëŒ€í™”ê°€ ê¸¸ì–´ì§€ë©´ ìë™ìœ¼ë¡œ ìš”ì•½
2. ìš”ì•½ë³¸ì„ ë©”ëª¨ë¦¬ì— ì €ì¥í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€
3. í† í° í•œë„ë¥¼ ê³ ë ¤í•œ ìŠ¤ë§ˆíŠ¸ ë©”ëª¨ë¦¬ ê´€ë¦¬

í•™ìŠµ ëª©í‘œ:
- ë©”ì‹œì§€ ìˆ˜ ê¸°ë°˜ ìš”ì•½ íŠ¸ë¦¬ê±°
- ìš”ì•½ì„ í™œìš©í•œ ë©”ëª¨ë¦¬ ìµœì í™”
- ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ê´€ë¦¬

================================================================================
"""

from dotenv import load_dotenv
from typing import Sequence, Literal
from langchain_core.messages import (
    BaseMessage,
    HumanMessage,
    AIMessage,
    SystemMessage,
    RemoveMessage
)
from langchain_openai import ChatOpenAI
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.graph.state import CompiledStateGraph

load_dotenv()

# ============================================================================
# State ì •ì˜
# ============================================================================

class ChatState(MessagesState):
    """ì±„íŒ… ìƒíƒœ with ìš”ì•½"""
    summary: str  # í˜„ì¬ê¹Œì§€ì˜ ëŒ€í™” ìš”ì•½


# ============================================================================
# ìë™ ìš”ì•½ ì±—ë´‡ êµ¬ì¶•
# ============================================================================

def create_summarizing_chatbot(
    model_name: str = "gpt-4o-mini",
    summary_threshold: int = 6  # ë©”ì‹œì§€ Nê°œë§ˆë‹¤ ìš”ì•½
) -> CompiledStateGraph:
    """ìë™ ìš”ì•½ ê¸°ëŠ¥ì´ ìˆëŠ” ì±—ë´‡ ìƒì„±"""

    # LLM ëª¨ë¸
    model = ChatOpenAI(model=model_name, temperature=0.7)

    # ëŒ€í™” ì‘ë‹µ ë…¸ë“œ
    def chatbot_node(state: ChatState) -> dict:
        """ì¼ë°˜ ëŒ€í™” ì‘ë‹µ"""
        # ìš”ì•½ì´ ìˆìœ¼ë©´ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ í¬í•¨
        messages = list(state["messages"])
        if state.get("summary"):
            summary_msg = SystemMessage(
                content=f"ì´ì „ ëŒ€í™” ìš”ì•½:\n{state['summary']}\n\n"
                        f"ìœ„ ìš”ì•½ì„ ì°¸ê³ í•˜ì—¬ ëŒ€í™”ë¥¼ ì´ì–´ê°€ì„¸ìš”."
            )
            messages = [summary_msg] + messages

        response = model.invoke(messages)
        return {"messages": [response]}

    # ìš”ì•½ í•„ìš” ì—¬ë¶€ íŒë‹¨
    def should_summarize(state: ChatState) -> Literal["summarize", "continue"]:
        """ìš”ì•½ì´ í•„ìš”í•œì§€ íŒë‹¨"""
        messages = state["messages"]

        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì œì™¸í•˜ê³  ì¹´ìš´íŠ¸
        user_ai_messages = [
            m for m in messages
            if isinstance(m, (HumanMessage, AIMessage))
        ]

        # threshold ì´ˆê³¼ ì‹œ ìš”ì•½
        if len(user_ai_messages) > summary_threshold:
            return "summarize"
        return "continue"

    # ìš”ì•½ ìƒì„± ë…¸ë“œ
    def summarize_node(state: ChatState) -> dict:
        """ëŒ€í™” ìš”ì•½ ìƒì„±"""
        messages = state["messages"]

        # ìš”ì•½ ëŒ€ìƒ: HumanMessageì™€ AIMessageë§Œ
        conversation = [
            m for m in messages
            if isinstance(m, (HumanMessage, AIMessage))
        ]

        # ê¸°ì¡´ ìš”ì•½ì´ ìˆìœ¼ë©´ í¬í•¨
        summary_prompt = ""
        if state.get("summary"):
            summary_prompt = f"ê¸°ì¡´ ìš”ì•½:\n{state['summary']}\n\n"

        summary_prompt += """ë‹¤ìŒ ëŒ€í™” ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.
í•µì‹¬ ì£¼ì œ, ì¤‘ìš”í•œ ì •ë³´, ì‚¬ìš©ì ì„ í˜¸ë„ ë“±ì„ í¬í•¨í•˜ì„¸ìš”.

ëŒ€í™” ë‚´ìš©:
"""
        for msg in conversation:
            role = "ì‚¬ìš©ì" if isinstance(msg, HumanMessage) else "AI"
            summary_prompt += f"{role}: {msg.content}\n"

        summary_prompt += "\nìš”ì•½ (3-5 ë¬¸ì¥):"

        # ìš”ì•½ ìƒì„±
        summary_response = model.invoke([HumanMessage(content=summary_prompt)])
        new_summary = summary_response.content

        print(f"\nğŸ“ ëŒ€í™” ìš”ì•½ ìƒì„± ì™„ë£Œ ({len(conversation)}ê°œ ë©”ì‹œì§€)")
        print(f"ìš”ì•½: {new_summary[:100]}...")

        # ì˜¤ë˜ëœ ë©”ì‹œì§€ ì‚­ì œ (ìµœê·¼ 2ê°œë§Œ ìœ ì§€)
        messages_to_remove = [
            RemoveMessage(id=m.id)
            for m in conversation[:-2]
        ]

        return {
            "summary": new_summary,
            "messages": messages_to_remove
        }

    # ê·¸ë˜í”„ êµ¬ì¶•
    graph_builder = StateGraph(ChatState)

    # ë…¸ë“œ ì¶”ê°€
    graph_builder.add_node("chatbot", chatbot_node)
    graph_builder.add_node("summarize", summarize_node)

    # ì—£ì§€ ì¶”ê°€
    graph_builder.add_edge(START, "chatbot")
    graph_builder.add_conditional_edges(
        "chatbot",
        should_summarize,
        {
            "summarize": "summarize",
            "continue": END
        }
    )
    graph_builder.add_edge("summarize", END)

    # ë©”ëª¨ë¦¬ ì¶”ê°€
    memory = InMemorySaver()
    graph = graph_builder.compile(checkpointer=memory)

    return graph


# ============================================================================
# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
# ============================================================================

def test_auto_summarization():
    """ìë™ ìš”ì•½ í…ŒìŠ¤íŠ¸"""
    print("=" * 70)
    print("ğŸ“š ìë™ ìš”ì•½ ì±—ë´‡ í…ŒìŠ¤íŠ¸")
    print("=" * 70)

    # ìš”ì•½ threshold = 4 (ë©”ì‹œì§€ 4ê°œë§ˆë‹¤ ìš”ì•½)
    chatbot = create_summarizing_chatbot(summary_threshold=4)
    config = {"configurable": {"thread_id": "test_session"}}

    # ê¸´ ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜
    conversation_turns = [
        "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” íŒŒì´ì¬ ê°œë°œìì…ë‹ˆë‹¤.",
        "ìš”ì¦˜ LangChainì„ ê³µë¶€í•˜ê³  ìˆì–´ìš”.",
        "íŠ¹íˆ Agent ì‹œìŠ¤í…œì´ í¥ë¯¸ë¡­ë„¤ìš”.",
        "ë©”ëª¨ë¦¬ ê´€ë¦¬ê°€ ì¤‘ìš”í•œ ê²ƒ ê°™ì•„ìš”.",
        "ëŒ€í™”ê°€ ê¸¸ì–´ì§€ë©´ ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ë‚˜ìš”?",  # ì—¬ê¸°ì„œ ìš”ì•½ ë°œìƒ
        "ì œê°€ ì²˜ìŒì— ë­ë¼ê³  í–ˆì£ ?",  # ìš”ì•½ë³¸ì—ì„œ ì •ë³´ ê°€ì ¸ì™€ì•¼ í•¨
        "LangChain ë§ê³  ë‹¤ë¥¸ ê²ƒë„ ê³µë¶€ ì¤‘ì´ì—ìš”.",
        "FastAPIë¡œ APIë¥¼ ë§Œë“¤ê³  ìˆì–´ìš”.",
        "Dockerë„ ë°°ìš°ê³  ìˆê³ ìš”.",  # ë‘ ë²ˆì§¸ ìš”ì•½ ë°œìƒ
        "ì œ ì§ì—…ì´ ë­ì˜€ì£ ?",  # ìš”ì•½ë³¸ì—ì„œ ì •ë³´ ê°€ì ¸ì™€ì•¼ í•¨
    ]

    print("\nğŸ’¬ ëŒ€í™” ì‹œì‘...\n")

    for i, user_msg in enumerate(conversation_turns, 1):
        print("=" * 70)
        print(f"ğŸ‘¤ Turn {i}: {user_msg}")

        # ìƒíƒœ ì „ í™•ì¸
        state_before = chatbot.get_state(config)
        msg_count_before = len([
            m for m in state_before.values.get("messages", [])
            if isinstance(m, (HumanMessage, AIMessage))
        ])

        # ë©”ì‹œì§€ ì „ì†¡
        result = chatbot.invoke(
            {"messages": [HumanMessage(content=user_msg)]},
            config=config
        )

        # ì‘ë‹µ ì¶œë ¥
        ai_response = result["messages"][-1].content
        print(f"ğŸ¤– {ai_response}")

        # ìƒíƒœ í›„ í™•ì¸
        state_after = chatbot.get_state(config)
        msg_count_after = len([
            m for m in state_after.values.get("messages", [])
            if isinstance(m, (HumanMessage, AIMessage))
        ])
        summary = state_after.values.get("summary", "")

        # ë©”ëª¨ë¦¬ ìƒíƒœ ì¶œë ¥
        if msg_count_after < msg_count_before:
            print(f"\nâš ï¸  ë©”ì‹œì§€ ì••ì¶•: {msg_count_before} â†’ {msg_count_after}")
            print(f"ğŸ“ í˜„ì¬ ìš”ì•½: {summary[:150]}...")
        else:
            print(f"\nğŸ“Š í˜„ì¬ ë©”ì‹œì§€ ìˆ˜: {msg_count_after}")
            if summary:
                print(f"ğŸ“ í˜„ì¬ ìš”ì•½ ì¡´ì¬: {len(summary)} ê¸€ì")

        print()

    print("=" * 70)
    print("âœ… ìë™ ìš”ì•½ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 70)

    # ìµœì¢… ìƒíƒœ í™•ì¸
    final_state = chatbot.get_state(config)
    print("\nğŸ“Š ìµœì¢… ë©”ëª¨ë¦¬ ìƒíƒœ:")
    print(f"  ë©”ì‹œì§€ ìˆ˜: {len(final_state.values['messages'])}")
    print(f"  ìš”ì•½ ê¸¸ì´: {len(final_state.values.get('summary', ''))} ê¸€ì")

    if final_state.values.get("summary"):
        print(f"\nğŸ“ ìµœì¢… ìš”ì•½:\n{final_state.values['summary']}")


def test_memory_efficiency():
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ë¹„êµ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 70)
    print("ğŸ”¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ë¹„êµ")
    print("=" * 70)

    # ì¼ë°˜ ì±—ë´‡ (ìš”ì•½ ì—†ìŒ)
    from langgraph.prebuilt import create_react_agent

    model = ChatOpenAI(model="gpt-4o-mini")
    normal_chatbot = create_react_agent(model, [], checkpointer=InMemorySaver())

    # ìš”ì•½ ì±—ë´‡
    summary_chatbot = create_summarizing_chatbot(summary_threshold=4)

    # í…ŒìŠ¤íŠ¸ ëŒ€í™”
    test_messages = [
        f"ë©”ì‹œì§€ {i}: ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ì…ë‹ˆë‹¤." for i in range(1, 11)
    ]

    # ì¼ë°˜ ì±—ë´‡ í…ŒìŠ¤íŠ¸
    config_normal = {"configurable": {"thread_id": "normal"}}
    for msg in test_messages[:8]:  # 8ê°œë§Œ
        normal_chatbot.invoke(
            {"messages": [HumanMessage(content=msg)]},
            config_normal
        )

    state_normal = normal_chatbot.get_state(config_normal)
    normal_msg_count = len(state_normal.values["messages"])

    # ìš”ì•½ ì±—ë´‡ í…ŒìŠ¤íŠ¸
    config_summary = {"configurable": {"thread_id": "summary"}}
    for msg in test_messages[:8]:  # 8ê°œ
        summary_chatbot.invoke(
            {"messages": [HumanMessage(content=msg)]},
            config_summary
        )

    state_summary = summary_chatbot.get_state(config_summary)
    summary_msg_count = len([
        m for m in state_summary.values["messages"]
        if isinstance(m, (HumanMessage, AIMessage))
    ])

    # ê²°ê³¼ ë¹„êµ
    print(f"\nğŸ“Š ê²°ê³¼ ë¹„êµ (8í„´ ëŒ€í™” í›„):")
    print(f"  ì¼ë°˜ ì±—ë´‡ ë©”ì‹œì§€ ìˆ˜: {normal_msg_count}")
    print(f"  ìš”ì•½ ì±—ë´‡ ë©”ì‹œì§€ ìˆ˜: {summary_msg_count}")
    print(f"  ì ˆê°ë¥ : {(1 - summary_msg_count / normal_msg_count) * 100:.1f}%")

    if state_summary.values.get("summary"):
        print(f"\n  ìš”ì•½ë³¸ ì¡´ì¬: âœ…")
        print(f"  ìš”ì•½ ê¸¸ì´: {len(state_summary.values['summary'])} ê¸€ì")

    print("\nğŸ’¡ ìš”ì•½ ì‹œìŠ¤í…œì˜ ì¥ì :")
    print("  - ë©”ì‹œì§€ ìˆ˜ ê°ì†Œë¡œ í† í° ë¹„ìš© ì ˆê°")
    print("  - ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° íš¨ìœ¨ì  ì‚¬ìš©")
    print("  - í•µì‹¬ ì •ë³´ëŠ” ìš”ì•½ë³¸ì— ë³´ì¡´")


def interactive_mode():
    """ëŒ€í™”í˜• ëª¨ë“œ"""
    print("\n" + "=" * 70)
    print("ğŸ® ìë™ ìš”ì•½ ì±—ë´‡ - ëŒ€í™”í˜• ëª¨ë“œ")
    print("=" * 70)
    print("ëª…ë ¹ì–´:")
    print("  /summary - í˜„ì¬ ìš”ì•½ ë³´ê¸°")
    print("  /messages - í˜„ì¬ ë©”ì‹œì§€ ìˆ˜")
    print("  /reset - ëŒ€í™” ì´ˆê¸°í™”")
    print("  /quit - ì¢…ë£Œ")
    print("=" * 70)

    chatbot = create_summarizing_chatbot(summary_threshold=4)
    config = {"configurable": {"thread_id": "interactive"}}

    turn = 0
    while True:
        try:
            turn += 1
            user_input = input(f"\nğŸ‘¤ Turn {turn}: ").strip()

            if not user_input:
                continue

            if user_input == "/quit":
                print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

            elif user_input == "/summary":
                state = chatbot.get_state(config)
                summary = state.values.get("summary", "")
                if summary:
                    print(f"\nğŸ“ í˜„ì¬ ìš”ì•½:\n{summary}")
                else:
                    print("ğŸ“ ì•„ì§ ìš”ì•½ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                turn -= 1
                continue

            elif user_input == "/messages":
                state = chatbot.get_state(config)
                messages = [
                    m for m in state.values.get("messages", [])
                    if isinstance(m, (HumanMessage, AIMessage))
                ]
                print(f"\nğŸ“Š í˜„ì¬ ë©”ì‹œì§€ ìˆ˜: {len(messages)}")
                print("ğŸ“œ ë©”ì‹œì§€ ëª©ë¡:")
                for i, msg in enumerate(messages, 1):
                    role = "ğŸ‘¤" if isinstance(msg, HumanMessage) else "ğŸ¤–"
                    print(f"  {i}. {role} {msg.content[:50]}...")
                turn -= 1
                continue

            elif user_input == "/reset":
                config = {"configurable": {"thread_id": f"interactive_{turn}"}}
                print("ğŸ”„ ëŒ€í™”ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                turn = 0
                continue

            # ì¼ë°˜ ë©”ì‹œì§€
            result = chatbot.invoke(
                {"messages": [HumanMessage(content=user_input)]},
                config=config
            )

            ai_response = result["messages"][-1].content
            print(f"ğŸ¤– {ai_response}")

        except KeyboardInterrupt:
            print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")


# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("\n" + "=" * 70)
    print("ğŸ“š Part 4: ìë™ ìš”ì•½ ì‹œìŠ¤í…œ - ì‹¤ìŠµ ê³¼ì œ 2 í•´ë‹µ")
    print("=" * 70)

    try:
        # í…ŒìŠ¤íŠ¸ 1: ìë™ ìš”ì•½
        test_auto_summarization()

        # í…ŒìŠ¤íŠ¸ 2: ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
        test_memory_efficiency()

        # ëŒ€í™”í˜• ëª¨ë“œ
        print("\nëŒ€í™”í˜• ëª¨ë“œë¥¼ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ", end="")
        choice = input().strip().lower()

        if choice in ['y', 'yes', 'ì˜ˆ']:
            interactive_mode()

    except Exception as e:
        print(f"\nâš ï¸  ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

    # í•™ìŠµ í¬ì¸íŠ¸
    print("\n" + "=" * 70)
    print("ğŸ’¡ í•™ìŠµ í¬ì¸íŠ¸:")
    print("  1. ë©”ì‹œì§€ ìˆ˜ ê¸°ë°˜ ìë™ ìš”ì•½ íŠ¸ë¦¬ê±°")
    print("  2. RemoveMessageë¡œ ì˜¤ë˜ëœ ë©”ì‹œì§€ ì •ë¦¬")
    print("  3. ìš”ì•½ë³¸ì„ SystemMessageë¡œ ì œê³µ")
    print("  4. ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ëŒ€í­ í–¥ìƒ")
    print("\nğŸ’¡ ì¶”ê°€ í•™ìŠµ:")
    print("  1. í† í° ìˆ˜ ê¸°ë°˜ ìš”ì•½ (tiktoken ì‚¬ìš©)")
    print("  2. ì ì§„ì  ìš”ì•½ (ìš”ì•½ì˜ ìš”ì•½)")
    print("  3. ì—”í‹°í‹° ì¶”ì¶œ ë° ë³„ë„ ì €ì¥")
    print("  4. ì‚¬ìš©ìë³„ ìš”ì•½ ì „ëµ ì»¤ìŠ¤í„°ë§ˆì´ì§•")
    print("=" * 70)


if __name__ == "__main__":
    main()
