"""
================================================================================
LangChain AI Agent ë§ˆìŠ¤í„° êµì•ˆ
Part 9: í”„ë¡œë•ì…˜ ì¤€ë¹„ - ë°±ì—”ë“œ ì„œë²„ (FastAPI)
================================================================================

íŒŒì¼ëª…: backend_server.py
ì„¤ëª…: React í”„ë¡ íŠ¸ì—”ë“œì™€ ì—°ë™ë˜ëŠ” ìŠ¤íŠ¸ë¦¬ë° Agent ì„œë²„

ì‹¤í–‰ ë°©ë²•:
    uvicorn backend_server:app --reload --port 8000

================================================================================
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import AsyncIterator
import asyncio
import json
import os
import ast
import operator
from dotenv import load_dotenv

from langchain.agents import create_agent
from langchain.tools import tool
from langchain_openai import ChatOpenAI

# í™˜ê²½ ì„¤ì •
load_dotenv()

# ============================================================================
# FastAPI ì•± ì„¤ì •
# ============================================================================

app = FastAPI(title="LangChain Agent API")

# CORS ì„¤ì • (í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://localhost:3000"],  # Vite, CRA
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================================================================
# ì•ˆì „í•œ ìˆ˜í•™ ê³„ì‚°ê¸°
# ============================================================================

def safe_eval_math(expression: str) -> float:
    """
    ì•ˆì „í•˜ê²Œ ìˆ˜í•™ í‘œí˜„ì‹ì„ í‰ê°€í•©ë‹ˆë‹¤.
    eval() ëŒ€ì‹  astë¥¼ ì‚¬ìš©í•˜ì—¬ í—ˆìš©ëœ ì—°ì‚°ë§Œ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    # í—ˆìš©ëœ ì—°ì‚°ì ë§¤í•‘
    allowed_operators = {
        ast.Add: operator.add,
        ast.Sub: operator.sub,
        ast.Mult: operator.mul,
        ast.Div: operator.truediv,
        ast.Pow: operator.pow,
        ast.Mod: operator.mod,
        ast.FloorDiv: operator.floordiv,
        ast.USub: operator.neg,  # ë‹¨í•­ ë§ˆì´ë„ˆìŠ¤
    }

    def eval_node(node):
        """AST ë…¸ë“œë¥¼ ì¬ê·€ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤."""
        if isinstance(node, ast.Constant):  # Python 3.8+
            return node.value
        elif isinstance(node, ast.Num):  # Python 3.7 í˜¸í™˜ì„±
            return node.n
        elif isinstance(node, ast.BinOp):
            left = eval_node(node.left)
            right = eval_node(node.right)
            op_type = type(node.op)
            if op_type not in allowed_operators:
                raise ValueError(f"í—ˆìš©ë˜ì§€ ì•Šì€ ì—°ì‚°ì: {op_type.__name__}")
            return allowed_operators[op_type](left, right)
        elif isinstance(node, ast.UnaryOp):
            operand = eval_node(node.operand)
            op_type = type(node.op)
            if op_type not in allowed_operators:
                raise ValueError(f"í—ˆìš©ë˜ì§€ ì•Šì€ ì—°ì‚°ì: {op_type.__name__}")
            return allowed_operators[op_type](operand)
        else:
            raise ValueError(f"í—ˆìš©ë˜ì§€ ì•Šì€ ë…¸ë“œ íƒ€ì…: {type(node).__name__}")

    try:
        # í‘œí˜„ì‹ì„ ASTë¡œ íŒŒì‹±
        tree = ast.parse(expression, mode='eval')
        # ASTë¥¼ í‰ê°€
        return eval_node(tree.body)
    except SyntaxError as e:
        raise ValueError(f"ì˜ëª»ëœ í‘œí˜„ì‹ êµ¬ë¬¸: {e}")


# ============================================================================
# ë„êµ¬ ì •ì˜
# ============================================================================

@tool
def get_weather(city: str) -> str:
    """ì£¼ì–´ì§„ ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
    # ì‹¤ì œë¡œëŠ” API í˜¸ì¶œ, ì—¬ê¸°ì„œëŠ” ëª¨ì˜ ë°ì´í„°
    weather_data = {
        "ì„œìš¸": "ë§‘ìŒ, 22Â°C",
        "ë¶€ì‚°": "íë¦¼, 19Â°C",
        "ë‰´ìš•": "ë¹„, 15Â°C",
        "ë„ì¿„": "ë§‘ìŒ, 20Â°C",
    }
    return weather_data.get(city, f"{city}ì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


@tool
def calculate(expression: str) -> str:
    """ìˆ˜í•™ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    try:
        # ì•ˆì „í•œ ìˆ˜í•™ í‘œí˜„ì‹ í‰ê°€ (ast ì‚¬ìš©)
        result = safe_eval_math(expression)
        return f"{expression} = {result}"
    except Exception as e:
        return f"ê³„ì‚° ì˜¤ë¥˜: {e}"


@tool
def search_web(query: str) -> str:
    """ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. (ëª¨ì˜)"""
    return f"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼: LangChainì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤."


# ============================================================================
# Agent ìƒì„±
# ============================================================================

def create_streaming_agent():
    """ìŠ¤íŠ¸ë¦¬ë° Agentë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    if not os.getenv("OPENAI_API_KEY"):
        raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    model = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.7,
        streaming=True,  # ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
    )

    agent = create_agent(
        model=model,
        tools=[get_weather, calculate, search_web],
        system_prompt="""
ë‹¹ì‹ ì€ ìœ ìš©í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
        """.strip(),
    )

    return agent


# ============================================================================
# API ëª¨ë¸
# ============================================================================

class ChatRequest(BaseModel):
    message: str
    stream: bool = True


class ChatResponse(BaseModel):
    response: str


# ============================================================================
# SSE ìŠ¤íŠ¸ë¦¬ë° ì—”ë“œí¬ì¸íŠ¸
# ============================================================================

async def event_stream(message: str) -> AsyncIterator[str]:
    """
    Server-Sent Events í˜•ì‹ìœ¼ë¡œ Agent ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.

    Yields:
        SSE í˜•ì‹ì˜ ì´ë²¤íŠ¸ ë¬¸ìì—´
    """
    try:
        agent = create_streaming_agent()

        # Agent ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë°)
        async for chunk in agent.astream(
            {"messages": [{"role": "user", "content": message}]}
        ):
            # ë©”ì‹œì§€ ì²­í¬ ì²˜ë¦¬
            if "messages" in chunk:
                for msg in chunk["messages"]:
                    if hasattr(msg, "content") and msg.content:
                        # í† í° ì „ì†¡
                        event = {
                            "type": "token",
                            "content": msg.content,
                        }
                        yield f"data: {json.dumps(event, ensure_ascii=False)}\n\n"
                        await asyncio.sleep(0.01)  # ì•½ê°„ì˜ ì§€ì—° (ì‹œê° íš¨ê³¼)

            # ë„êµ¬ í˜¸ì¶œ ê°ì§€
            if "tool_calls" in chunk:
                for tool_call in chunk["tool_calls"]:
                    event = {
                        "type": "tool_call",
                        "tool": tool_call.get("name", "unknown"),
                    }
                    yield f"data: {json.dumps(event, ensure_ascii=False)}\n\n"

        # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ
        yield "data: [DONE]\n\n"

    except Exception as e:
        # ì—ëŸ¬ ì „ì†¡
        error_event = {
            "type": "error",
            "error": str(e),
        }
        yield f"data: {json.dumps(error_event, ensure_ascii=False)}\n\n"


@app.post("/stream")
async def stream_chat(request: ChatRequest):
    """
    ì±„íŒ… ë©”ì‹œì§€ë¥¼ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.

    Args:
        request: ì±„íŒ… ìš”ì²­ (message, stream)

    Returns:
        StreamingResponse: SSE ìŠ¤íŠ¸ë¦¼
    """
    if not request.message.strip():
        raise HTTPException(status_code=400, detail="ë©”ì‹œì§€ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

    return StreamingResponse(
        event_stream(request.message),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
        },
    )


# ============================================================================
# ì¼ë°˜ (ë¹„ìŠ¤íŠ¸ë¦¬ë°) ì—”ë“œí¬ì¸íŠ¸
# ============================================================================

@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    ì±„íŒ… ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤ (ë¹„ìŠ¤íŠ¸ë¦¬ë°).

    Args:
        request: ì±„íŒ… ìš”ì²­

    Returns:
        ChatResponse: Agent ì‘ë‹µ
    """
    if not request.message.strip():
        raise HTTPException(status_code=400, detail="ë©”ì‹œì§€ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

    try:
        agent = create_streaming_agent()

        result = agent.invoke({
            "messages": [{"role": "user", "content": request.message}]
        })

        response_content = result["messages"][-1].content

        return ChatResponse(response=response_content)

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# í—¬ìŠ¤ ì²´í¬
# ============================================================================

@app.get("/health")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {
        "status": "healthy",
        "openai_configured": bool(os.getenv("OPENAI_API_KEY")),
    }


@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "LangChain Agent API",
        "version": "1.0.0",
        "endpoints": {
            "stream": "POST /stream - ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ…",
            "chat": "POST /chat - ì¼ë°˜ ì±„íŒ…",
            "health": "GET /health - í—¬ìŠ¤ ì²´í¬",
        },
    }


# ============================================================================
# ì‹¤í–‰
# ============================================================================

if __name__ == "__main__":
    import uvicorn

    print("=" * 70)
    print("ğŸš€ LangChain Agent ì„œë²„ ì‹œì‘")
    print("=" * 70)
    print()
    print("ğŸ“ ì„œë²„ ì£¼ì†Œ: http://localhost:8000")
    print("ğŸ“– API ë¬¸ì„œ: http://localhost:8000/docs")
    print("ğŸ”§ í—¬ìŠ¤ ì²´í¬: http://localhost:8000/health")
    print()
    print("âŒ¨ï¸  ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”")
    print("=" * 70)
    print()

    uvicorn.run(
        "backend_server:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
    )


# ============================================================================
# ğŸ“š í•™ìŠµ í¬ì¸íŠ¸
# ============================================================================
#
# 1. FastAPI:
#    - í˜„ëŒ€ì ì¸ Python ì›¹ í”„ë ˆì„ì›Œí¬
#    - ìë™ API ë¬¸ì„œ ìƒì„± (/docs)
#    - íƒ€ì… íŒíŠ¸ ê¸°ë°˜ ê²€ì¦
#
# 2. CORS:
#    - í”„ë¡ íŠ¸ì—”ë“œì™€ ë°±ì—”ë“œ ë„ë©”ì¸ì´ ë‹¤ë¥¼ ë•Œ í•„ìš”
#    - allow_originsì— í”„ë¡ íŠ¸ì—”ë“œ ì£¼ì†Œ ì¶”ê°€
#
# 3. Server-Sent Events:
#    - StreamingResponseë¡œ êµ¬í˜„
#    - data: í”„ë¦¬í”½ìŠ¤ í•„ìˆ˜
#    - ì´ë²¤íŠ¸ ëì— \n\n ì¶”ê°€
#
# 4. ë¹„ë™ê¸° ì²˜ë¦¬:
#    - async/awaitë¡œ ë¹„ë™ê¸° Agent ì‹¤í–‰
#    - astream()ìœ¼ë¡œ ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë°
#
# ============================================================================
# ğŸ“ í”„ë¡œë•ì…˜ ê³ ë ¤ì‚¬í•­
# ============================================================================
#
# - ì¸ì¦/ì¸ê°€ (JWT, OAuth)
# - Rate Limiting
# - ì—ëŸ¬ ë¡œê¹…
# - ëª¨ë‹ˆí„°ë§ (Prometheus, Grafana)
# - ë°°í¬ (Docker, Kubernetes)
#
# ============================================================================
