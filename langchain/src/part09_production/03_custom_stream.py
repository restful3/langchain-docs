"""
================================================================================
LangChain AI Agent ë§ˆìŠ¤í„° êµì•ˆ
Part 9: í”„ë¡œë•ì…˜ (Production)
================================================================================

íŒŒì¼ëª…: 03_custom_stream.py
ë‚œì´ë„: â­â­â­â­â­ (ì „ë¬¸ê°€)
ì˜ˆìƒ ì‹œê°„: 25ë¶„

ğŸ“š í•™ìŠµ ëª©í‘œ:
  - Custom Streaming êµ¬í˜„ ë°©ë²•
  - Streaming ë°ì´í„° ê°€ê³µ ë° í•„í„°ë§
  - ì‹¤ì‹œê°„ UI ì—…ë°ì´íŠ¸ íŒ¨í„´
  - ê³ ê¸‰ Streaming ê¸°ë²•

ğŸ“– ê³µì‹ ë¬¸ì„œ:
  â€¢ Streaming: /official/11-streaming-overview.md

ğŸ“„ êµì•ˆ ë¬¸ì„œ:
  â€¢ Part 9 ê°œìš”: /docs/part09_production.md

ğŸ”§ í•„ìš”í•œ íŒ¨í‚¤ì§€:
  pip install langchain langchain-openai langgraph

ğŸ”‘ í•„ìš”í•œ í™˜ê²½ë³€ìˆ˜:
  - OPENAI_API_KEY

ğŸš€ ì‹¤í–‰ ë°©ë²•:
  python 03_custom_stream.py

================================================================================
"""

# ============================================================================
# Imports
# ============================================================================

import os
import sys
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.agents import create_agent
from langchain.tools import tool
from langgraph.checkpoint.memory import MemorySaver
from typing import Generator, Dict, Any
import time

# ============================================================================
# í™˜ê²½ ì„¤ì •
# ============================================================================

load_dotenv()

if not os.getenv("OPENAI_API_KEY"):
    print("âŒ ì˜¤ë¥˜: OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    sys.exit(1)

# ============================================================================
# ì˜ˆì œ 1: Custom Streaming Wrapper
# ============================================================================

def example_1_custom_wrapper():
    """Custom Streaming Wrapper ë§Œë“¤ê¸°"""
    print("=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 1: Custom Streaming Wrapper")
    print("=" * 70)

    @tool
    def get_data(source: str) -> str:
        """ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        time.sleep(0.5)
        return f"{source}ì—ì„œ ë°ì´í„° 100ê±´ ë¡œë“œ ì™„ë£Œ"

    agent = create_agent(
        model="gpt-4o-mini",
        tools=[get_data],
        checkpointer=MemorySaver(),
    )

    def custom_stream_wrapper(
        agent_stream: Generator,
        add_timestamps: bool = True,
        filter_tool_messages: bool = False
    ) -> Generator[Dict[str, Any], None, None]:
        """
        Agent ìŠ¤íŠ¸ë¦¼ì„ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ëŠ” ë˜í¼

        Args:
            agent_stream: Agent.stream() ì œë„ˆë ˆì´í„°
            add_timestamps: íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€ ì—¬ë¶€
            filter_tool_messages: Tool ë©”ì‹œì§€ í•„í„°ë§ ì—¬ë¶€
        """
        for chunk in agent_stream:
            # ì»¤ìŠ¤í…€ ë°ì´í„° êµ¬ì¡° ìƒì„±
            custom_chunk = {
                "original": chunk,
                "metadata": {}
            }

            # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
            if add_timestamps:
                custom_chunk["metadata"]["timestamp"] = time.time()

            # Tool ë©”ì‹œì§€ í•„í„°ë§
            if filter_tool_messages and "messages" in chunk:
                messages = chunk["messages"]
                filtered = [
                    msg for msg in messages
                    if not hasattr(msg, "name") or not msg.name
                ]
                if filtered:
                    custom_chunk["filtered_messages"] = filtered
                else:
                    continue  # Tool ë©”ì‹œì§€ë§Œ ìˆìœ¼ë©´ ìŠ¤í‚µ

            yield custom_chunk

    print("\nğŸ¨ Custom Wrapper ì‚¬ìš©:")
    print("-" * 70)

    user_message = "databaseì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì£¼ì„¸ìš”."
    print(f"ğŸ‘¤ ì‚¬ìš©ì: {user_message}\n")

    config = {"configurable": {"thread_id": "custom_wrapper"}}

    # Custom wrapper ì ìš©
    base_stream = agent.stream(
        {"messages": [{"role": "user", "content": user_message}]},
        config=config,
        stream_mode="messages"
    )

    wrapped_stream = custom_stream_wrapper(
        base_stream,
        add_timestamps=True,
        filter_tool_messages=True
    )

    for i, custom_chunk in enumerate(wrapped_stream, 1):
        print(f"\n[Chunk {i}]")

        if "metadata" in custom_chunk and "timestamp" in custom_chunk["metadata"]:
            timestamp = custom_chunk["metadata"]["timestamp"]
            print(f"  ğŸ• íƒ€ì„ìŠ¤íƒ¬í”„: {timestamp:.3f}")

        message, metadata = custom_chunk["original"]
        if hasattr(message, "content") and message.content:
            print(f"  ğŸ’¬ {message.content[:60]}...")

    print("\n" + "-" * 70)
    print("âœ… Custom Wrapperë¡œ ìŠ¤íŠ¸ë¦¼ ë°ì´í„° ê°€ê³µ ì™„ë£Œ")


# ============================================================================
# ì˜ˆì œ 2: ì‹¤ì‹œê°„ ì§„í–‰ë¥  í‘œì‹œ
# ============================================================================

def example_2_progress_streaming():
    """ì‹¤ì‹œê°„ ì§„í–‰ë¥ ì„ í‘œì‹œí•˜ëŠ” Streaming"""
    print("\n" + "=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 2: ì‹¤ì‹œê°„ ì§„í–‰ë¥  í‘œì‹œ")
    print("=" * 70)

    @tool
    def step_1_collect() -> str:
        """Step 1: ë°ì´í„° ìˆ˜ì§‘"""
        time.sleep(1)
        return "ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: 1000ê±´"

    @tool
    def step_2_process() -> str:
        """Step 2: ë°ì´í„° ì²˜ë¦¬"""
        time.sleep(1.5)
        return "ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: ê²€ì¦ë¨"

    @tool
    def step_3_analyze() -> str:
        """Step 3: ë°ì´í„° ë¶„ì„"""
        time.sleep(1)
        return "ë¶„ì„ ì™„ë£Œ: í‰ê·  85ì "

    agent = create_agent(
        model="gpt-4o-mini",
        tools=[step_1_collect, step_2_process, step_3_analyze],
        checkpointer=MemorySaver(),
    )

    class ProgressTracker:
        """ì§„í–‰ ìƒí™©ì„ ì¶”ì í•˜ëŠ” í´ë˜ìŠ¤"""

        def __init__(self, total_steps: int = 3):
            self.total_steps = total_steps
            self.current_step = 0
            self.start_time = time.time()

        def update(self, step_name: str):
            """ì§„í–‰ ë‹¨ê³„ ì—…ë°ì´íŠ¸"""
            self.current_step += 1
            progress = (self.current_step / self.total_steps) * 100
            elapsed = time.time() - self.start_time

            # ì§„í–‰ë¥  ë°” ìƒì„±
            bar_length = 30
            filled = int(bar_length * self.current_step / self.total_steps)
            bar = "â–ˆ" * filled + "â–‘" * (bar_length - filled)

            print(f"\nğŸ“Š ì§„í–‰ë¥ : [{bar}] {progress:.0f}%")
            print(f"   ë‹¨ê³„: {step_name}")
            print(f"   ê²½ê³¼ ì‹œê°„: {elapsed:.1f}ì´ˆ")

    print("\nğŸ“Š ì§„í–‰ ìƒí™© ì¶”ì :")
    print("-" * 70)

    user_message = "ë°ì´í„°ë¥¼ ìˆ˜ì§‘, ì²˜ë¦¬, ë¶„ì„í•´ì£¼ì„¸ìš”."
    print(f"ğŸ‘¤ ì‚¬ìš©ì: {user_message}")

    config = {"configurable": {"thread_id": "progress_demo"}}
    tracker = ProgressTracker(total_steps=3)

    for message, metadata in agent.stream(
        {"messages": [{"role": "user", "content": user_message}]},
        config=config,
        stream_mode="messages"
    ):
        # Tool í˜¸ì¶œ ê°ì§€
        if hasattr(message, "tool_calls") and message.tool_calls:
            for tool_call in message.tool_calls:
                tool_name = tool_call["name"]
                tracker.update(tool_name)

        # ìµœì¢… ë‹µë³€
        elif hasattr(message, "content") and message.content and "ì™„ë£Œ" in message.content:
            print(f"\n\nğŸ‰ ìµœì¢… ê²°ê³¼:\n{message.content}")

    print("\n" + "-" * 70)
    print("âœ… ì§„í–‰ë¥  ì¶”ì  ì™„ë£Œ")


# ============================================================================
# ì˜ˆì œ 3: ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° í•„í„°ë§
# ============================================================================

def example_3_stream_filtering():
    """íŠ¹ì • ì¡°ê±´ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¼ í•„í„°ë§"""
    print("\n" + "=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 3: ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° í•„í„°ë§")
    print("=" * 70)

    @tool
    def check_item(item: str) -> str:
        """ì•„ì´í…œì„ í™•ì¸í•©ë‹ˆë‹¤."""
        return f"{item}: OK"

    agent = create_agent(
        model="gpt-4o-mini",
        tools=[check_item],
        checkpointer=MemorySaver(),
    )

    def filter_stream(
        stream: Generator,
        include_ai_messages: bool = True,
        include_tool_calls: bool = True,
        include_tool_responses: bool = False
    ) -> Generator:
        """
        ìŠ¤íŠ¸ë¦¼ì„ í•„í„°ë§

        Args:
            include_ai_messages: AI ì‘ë‹µ í¬í•¨ ì—¬ë¶€
            include_tool_calls: Tool í˜¸ì¶œ í¬í•¨ ì—¬ë¶€
            include_tool_responses: Tool ì‘ë‹µ í¬í•¨ ì—¬ë¶€
        """
        for message, metadata in stream:
            should_include = False
            message_type = "unknown"

            # AI ë©”ì‹œì§€
            if hasattr(message, "content") and message.content and not hasattr(message, "name"):
                should_include = include_ai_messages
                message_type = "ai_message"

            # Tool í˜¸ì¶œ
            elif hasattr(message, "tool_calls") and message.tool_calls:
                should_include = include_tool_calls
                message_type = "tool_call"

            # Tool ì‘ë‹µ
            elif hasattr(message, "name") and message.name:
                should_include = include_tool_responses
                message_type = "tool_response"

            if should_include:
                yield {
                    "type": message_type,
                    "message": message,
                    "metadata": metadata
                }

    print("\nğŸ” í•„í„°ë§ ì˜ˆì‹œ:")
    print("-" * 70)

    user_message = "item1, item2, item3ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
    print(f"ğŸ‘¤ ì‚¬ìš©ì: {user_message}\n")

    config = {"configurable": {"thread_id": "filter_demo"}}

    # AI ë©”ì‹œì§€ë§Œ í•„í„°ë§
    print("ğŸ”¹ AI ë©”ì‹œì§€ë§Œ í‘œì‹œ:")
    base_stream = agent.stream(
        {"messages": [{"role": "user", "content": user_message}]},
        config=config,
        stream_mode="messages"
    )

    filtered = filter_stream(
        base_stream,
        include_ai_messages=True,
        include_tool_calls=False,
        include_tool_responses=False
    )

    for item in filtered:
        if item["type"] == "ai_message":
            content = item["message"].content
            print(f"  ğŸ¤– {content[:70]}...")

    print("\n" + "-" * 70)
    print("âœ… í•„í„°ë§ëœ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì™„ë£Œ")


# ============================================================================
# ì˜ˆì œ 4: ë²„í¼ë§ ë° ë°°ì¹˜ ì²˜ë¦¬
# ============================================================================

def example_4_buffered_streaming():
    """ë²„í¼ë§ ë° ë°°ì¹˜ ì²˜ë¦¬"""
    print("\n" + "=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 4: ë²„í¼ë§ ë° ë°°ì¹˜ ì²˜ë¦¬")
    print("=" * 70)

    @tool
    def generate_item(index: int) -> str:
        """ì•„ì´í…œì„ ìƒì„±í•©ë‹ˆë‹¤."""
        return f"Item-{index}"

    agent = create_agent(
        model="gpt-4o-mini",
        tools=[generate_item],
        checkpointer=MemorySaver(),
    )

    def buffered_stream(stream: Generator, buffer_size: int = 3):
        """
        ìŠ¤íŠ¸ë¦¼ì„ ë²„í¼ë§í•˜ì—¬ ë°°ì¹˜ë¡œ ë°˜í™˜

        Args:
            buffer_size: ë²„í¼ í¬ê¸°
        """
        buffer = []

        for chunk in stream:
            buffer.append(chunk)

            # ë²„í¼ê°€ ê°€ë“ ì°¨ë©´ ë°˜í™˜
            if len(buffer) >= buffer_size:
                yield {
                    "batch": buffer.copy(),
                    "size": len(buffer)
                }
                buffer.clear()

        # ë‚¨ì€ í•­ëª© ë°˜í™˜
        if buffer:
            yield {
                "batch": buffer.copy(),
                "size": len(buffer)
            }

    print("\nğŸ“¦ ë²„í¼ë§ ìŠ¤íŠ¸ë¦¼:")
    print("-" * 70)

    user_message = "5ê°œì˜ ì•„ì´í…œì„ ìƒì„±í•´ì£¼ì„¸ìš”."
    print(f"ğŸ‘¤ ì‚¬ìš©ì: {user_message}\n")

    config = {"configurable": {"thread_id": "buffer_demo"}}

    base_stream = agent.stream(
        {"messages": [{"role": "user", "content": user_message}]},
        config=config,
        stream_mode="messages"
    )

    buffered = buffered_stream(base_stream, buffer_size=2)

    batch_num = 0
    for batch_data in buffered:
        batch_num += 1
        print(f"\në°°ì¹˜ {batch_num}: {batch_data['size']}ê°œ í•­ëª©")

        for message, metadata in batch_data["batch"]:
            if hasattr(message, "content") and message.content:
                print(f"  â€¢ {message.content[:50]}...")

    print("\n" + "-" * 70)
    print(f"âœ… {batch_num}ê°œ ë°°ì¹˜ë¡œ ì²˜ë¦¬ ì™„ë£Œ")
    print("ğŸ’¡ ë²„í¼ë§ì€ ë„¤íŠ¸ì›Œí¬ ì˜¤ë²„í—¤ë“œë¥¼ ì¤„ì´ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤.")


# ============================================================================
# ì˜ˆì œ 5: ì‹¤ì‹œê°„ UI ì—…ë°ì´íŠ¸ ì‹œë®¬ë ˆì´ì…˜
# ============================================================================

def example_5_realtime_ui_simulation():
    """ì‹¤ì‹œê°„ UI ì—…ë°ì´íŠ¸ ì‹œë®¬ë ˆì´ì…˜"""
    print("\n" + "=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 5: ì‹¤ì‹œê°„ UI ì—…ë°ì´íŠ¸ ì‹œë®¬ë ˆì´ì…˜")
    print("=" * 70)

    @tool
    def fetch_news(category: str) -> str:
        """ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        time.sleep(0.8)
        return f"{category} ë‰´ìŠ¤: ìµœì‹  ê¸°ì‚¬ 10ê±´"

    @tool
    def summarize_news(news: str) -> str:
        """ë‰´ìŠ¤ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""
        time.sleep(1)
        return f"ìš”ì•½: {news[:30]}..."

    agent = create_agent(
        model="gpt-4o-mini",
        tools=[fetch_news, summarize_news],
        checkpointer=MemorySaver(),
    )

    class UISimulator:
        """UI ì—…ë°ì´íŠ¸ ì‹œë®¬ë ˆì´í„°"""

        def __init__(self):
            self.status = "ëŒ€ê¸° ì¤‘"
            self.current_task = ""
            self.messages = []

        def update_status(self, status: str, task: str = ""):
            """ìƒíƒœ ì—…ë°ì´íŠ¸"""
            self.status = status
            self.current_task = task
            self._render()

        def add_message(self, message: str):
            """ë©”ì‹œì§€ ì¶”ê°€"""
            self.messages.append(message)
            self._render()

        def _render(self):
            """UI ë Œë”ë§ (ì½˜ì†” ì‹œë®¬ë ˆì´ì…˜)"""
            print("\r" + " " * 80, end="")  # ì´ì „ ì¤„ ì§€ìš°ê¸°
            print(f"\rìƒíƒœ: {self.status} | ì‘ì—…: {self.current_task}", end="", flush=True)

    print("\nğŸ–¥ï¸  UI ì—…ë°ì´íŠ¸ ì‹œë®¬ë ˆì´ì…˜:")
    print("-" * 70)

    user_message = "ê¸°ìˆ  ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì™€ì„œ ìš”ì•½í•´ì£¼ì„¸ìš”."
    print(f"ğŸ‘¤ ì‚¬ìš©ì: {user_message}\n")

    config = {"configurable": {"thread_id": "ui_demo"}}
    ui = UISimulator()

    ui.update_status("ì‹œì‘", "Agent ì‹¤í–‰ ì¤‘")

    for message, metadata in agent.stream(
        {"messages": [{"role": "user", "content": user_message}]},
        config=config,
        stream_mode="messages"
    ):
        # Tool í˜¸ì¶œ
        if hasattr(message, "tool_calls") and message.tool_calls:
            for tool_call in message.tool_calls:
                tool_name = tool_call["name"]
                ui.update_status("ì‹¤í–‰ ì¤‘", f"{tool_name} í˜¸ì¶œ")
                time.sleep(0.3)

        # Tool ì‘ë‹µ
        elif hasattr(message, "name"):
            ui.update_status("ì²˜ë¦¬ ì¤‘", f"{message.name} ì™„ë£Œ")

        # AI ë‹µë³€
        elif hasattr(message, "content") and message.content:
            ui.update_status("ì™„ë£Œ", "ë‹µë³€ ìƒì„±")
            print(f"\n\nğŸ’¬ ìµœì¢… ë‹µë³€:\n{message.content}")

    print("\n" + "-" * 70)
    print("âœ… ì‹¤ì‹œê°„ UI ì—…ë°ì´íŠ¸ ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ")


# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("\n" + "=" * 70)
    print("ğŸ“ LangChain AI Agent ë§ˆìŠ¤í„° êµì•ˆ")
    print("ğŸ“– Part 9: í”„ë¡œë•ì…˜ - Custom Streaming")
    print("=" * 70 + "\n")

    # ì˜ˆì œ ì‹¤í–‰
    example_1_custom_wrapper()
    input("\nâ ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")

    example_2_progress_streaming()
    input("\nâ ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")

    example_3_stream_filtering()
    input("\nâ ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")

    example_4_buffered_streaming()
    input("\nâ ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")

    example_5_realtime_ui_simulation()

    # ë§ˆë¬´ë¦¬
    print("\n" + "=" * 70)
    print("ğŸ‰ Part 9-03: Custom Streamingì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤!")
    print("=" * 70)
    print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print("  1. 04_hitl_basic.py - Human-in-the-Loop ê¸°ì´ˆ")
    print("  2. 05_hitl_decisions.py - HITL ì˜ì‚¬ê²°ì •")
    print("  3. 06_structured_output.py - Structured Output")
    print("\nğŸ“š í•µì‹¬ ìš”ì•½:")
    print("  â€¢ Custom Wrapperë¡œ ìŠ¤íŠ¸ë¦¼ ë°ì´í„° ê°€ê³µ")
    print("  â€¢ ì§„í–‰ë¥  í‘œì‹œë¡œ UX ê°œì„ ")
    print("  â€¢ í•„í„°ë§ìœ¼ë¡œ í•„ìš”í•œ ë°ì´í„°ë§Œ ì²˜ë¦¬")
    print("  â€¢ ë²„í¼ë§ìœ¼ë¡œ ë„¤íŠ¸ì›Œí¬ íš¨ìœ¨ í–¥ìƒ")
    print("  â€¢ ì‹¤ì‹œê°„ UI ì—…ë°ì´íŠ¸ íŒ¨í„´")
    print("\n" + "=" * 70 + "\n")


# ============================================================================
# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
# ============================================================================

if __name__ == "__main__":
    main()


# ============================================================================
# ğŸ“š ì¶”ê°€ í•™ìŠµ í¬ì¸íŠ¸
# ============================================================================
#
# 1. Custom Streaming í™œìš© ì‚¬ë¡€:
#    - ì‹¤ì‹œê°„ ì±„íŒ… UI
#    - ì§„í–‰ë¥  í‘œì‹œ
#    - ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§
#    - ë°ì´í„° ë³€í™˜ ë° ê°€ê³µ
#
# 2. ì„±ëŠ¥ ìµœì í™”:
#    - ë²„í¼ í¬ê¸° ì¡°ì ˆ
#    - í•„í„°ë§ìœ¼ë¡œ ë¶ˆí•„ìš”í•œ ë°ì´í„° ì œê±°
#    - ë¹„ë™ê¸° ì²˜ë¦¬
#
# 3. ì‹¤ì „ íŒ¨í„´:
#    - Generator ì²´ì´ë‹
#    - ìƒíƒœ ì¶”ì 
#    - ì˜¤ë¥˜ ì²˜ë¦¬
#
# ============================================================================
