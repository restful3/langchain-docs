"""
================================================================================
LangChain AI Agent ë§ˆìŠ¤í„° êµì•ˆ
Part 5: ë¯¸ë“¤ì›¨ì–´ (Middleware)
================================================================================

íŒŒì¼ëª…: 03_wrap_model_call.py
ë‚œì´ë„: â­â­â­â­â˜† (ê³ ê¸‰)
ì˜ˆìƒ ì‹œê°„: 40ë¶„

ğŸ“š í•™ìŠµ ëª©í‘œ:
  - wrap_model_call í›… ì´í•´
  - ëª¨ë¸ í˜¸ì¶œ ì¬ì‹œë„ êµ¬í˜„
  - ìºì‹± ë° ë³€í™˜ íŒ¨í„´ í•™ìŠµ

ğŸ“– ê³µì‹ ë¬¸ì„œ:
  â€¢ Custom Middleware: /official/16-custom-middleware.md#wrap-style-hooks

ğŸ“„ êµì•ˆ ë¬¸ì„œ:
  â€¢ Part 5.3.2: /docs/part05_middleware.md#32-wrap_model_call-í›…

ğŸš€ ì‹¤í–‰ ë°©ë²•:
  python 03_wrap_model_call.py

================================================================================
"""

import os
import time
import hashlib
import json
from dotenv import load_dotenv
from langchain.agents import create_agent
from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse
from langchain.tools import tool
from langchain_openai import ChatOpenAI
from typing import Callable

load_dotenv()

# ============================================================================
# ì˜ˆì œ 1: ëª¨ë¸ í˜¸ì¶œ ì¬ì‹œë„
# ============================================================================

def example_1_retry_model():
    """ëª¨ë¸ í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„"""
    print("=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 1: ëª¨ë¸ í˜¸ì¶œ ì¬ì‹œë„")
    print("=" * 70)

    attempt_count = {"count": 0}

    @wrap_model_call
    def retry_on_failure(
        request: ModelRequest,
        handler: Callable[[ModelRequest], ModelResponse],
    ) -> ModelResponse:
        max_retries = 3

        for attempt in range(max_retries):
            try:
                attempt_count["count"] += 1
                print(f"\nğŸ”„ ì‹œë„ #{attempt + 1}")

                response = handler(request)
                print(f"âœ… ì„±ê³µ!")
                return response

            except Exception as e:
                print(f"âŒ ì‹¤íŒ¨: {str(e)[:50]}...")

                if attempt == max_retries - 1:
                    print(f"â›” ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
                    raise

                # ì§€ìˆ˜ ë°±ì˜¤í”„
                wait_time = 2 ** attempt
                print(f"â³ {wait_time}ì´ˆ ëŒ€ê¸°...")
                time.sleep(wait_time)

    @tool
    def simple_tool(text: str) -> str:
        """ê°„ë‹¨í•œ ë„êµ¬"""
        return f"ì²˜ë¦¬ë¨: {text}"

    agent = create_agent(
        model="gpt-4o-mini",
        tools=[simple_tool],
        middleware=[retry_on_failure],
    )

    response = agent.invoke({
        "messages": [{"role": "user", "content": "ì•ˆë…•"}]
    })

    print(f"\nğŸ“Š ì´ ì‹œë„ íšŸìˆ˜: {attempt_count['count']}")
    print(f"âœ… ì‘ë‹µ: {response['messages'][-1].content}")


# ============================================================================
# ì˜ˆì œ 2: ëª¨ë¸ í˜¸ì¶œ ë¡œê¹…
# ============================================================================

def example_2_log_model_calls():
    """ëª¨ë¸ í˜¸ì¶œ ì „í›„ ë¡œê¹…"""
    print("\n" + "=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 2: ëª¨ë¸ í˜¸ì¶œ ë¡œê¹…")
    print("=" * 70)

    @wrap_model_call
    def log_call(
        request: ModelRequest,
        handler: Callable[[ModelRequest], ModelResponse],
    ) -> ModelResponse:
        start_time = time.time()

        print(f"\nğŸ“¥ ëª¨ë¸ í˜¸ì¶œ ì‹œì‘")
        print(f"   ë©”ì‹œì§€ ìˆ˜: {len(request.messages)}")

        response = handler(request)

        duration = time.time() - start_time
        print(f"ğŸ“¤ ëª¨ë¸ ì‘ë‹µ ë°›ìŒ ({duration:.2f}ì´ˆ)")

        return response

    @tool
    def calculator(expression: str) -> str:
        """ê³„ì‚°í•©ë‹ˆë‹¤."""
        try:
            return str(eval(expression))
        except:
            return "ì˜¤ë¥˜"

    agent = create_agent(
        model="gpt-4o-mini",
        tools=[calculator],
        middleware=[log_call],
    )

    response = agent.invoke({
        "messages": [{"role": "user", "content": "100 * 50ì€?"}]
    })

    print(f"\nâœ… ì‘ë‹µ: {response['messages'][-1].content}")


# ============================================================================
# ì˜ˆì œ 3: ê°„ë‹¨í•œ ìºì‹±
# ============================================================================

def example_3_caching():
    """ëª¨ë¸ ì‘ë‹µ ìºì‹±"""
    print("\n" + "=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 3: ëª¨ë¸ ì‘ë‹µ ìºì‹±")
    print("=" * 70)

    cache = {}

    def hash_request(request: ModelRequest) -> str:
        """ìš”ì²­ í•´ì‹±"""
        content = str([m.content for m in request.messages])
        return hashlib.md5(content.encode()).hexdigest()

    @wrap_model_call
    def cache_responses(
        request: ModelRequest,
        handler: Callable[[ModelRequest], ModelResponse],
    ) -> ModelResponse:
        cache_key = hash_request(request)

        if cache_key in cache:
            print(f"\nğŸ’¾ ìºì‹œ íˆíŠ¸! (í‚¤: {cache_key[:8]}...)")
            return cache[cache_key]

        print(f"\nğŸ” ìºì‹œ ë¯¸ìŠ¤ - ëª¨ë¸ í˜¸ì¶œ (í‚¤: {cache_key[:8]}...)")
        response = handler(request)

        cache[cache_key] = response
        return response

    @tool
    def get_data(query: str) -> str:
        """ë°ì´í„° ì¡°íšŒ"""
        return f"{query}ì— ëŒ€í•œ ë°ì´í„°"

    agent = create_agent(
        model="gpt-4o-mini",
        tools=[get_data],
        middleware=[cache_responses],
    )

    # ì²« ë²ˆì§¸ í˜¸ì¶œ
    print("\nğŸ”¹ ì²« ë²ˆì§¸ ìš”ì²­:")
    response1 = agent.invoke({
        "messages": [{"role": "user", "content": "íŒŒì´ì¬ì´ ë­ì•¼?"}]
    })

    # ë™ì¼í•œ í˜¸ì¶œ (ìºì‹œë¨)
    print("\nğŸ”¹ ë‘ ë²ˆì§¸ ìš”ì²­ (ë™ì¼):")
    response2 = agent.invoke({
        "messages": [{"role": "user", "content": "íŒŒì´ì¬ì´ ë­ì•¼?"}]
    })

    print(f"\nğŸ“Š ìºì‹œ í¬ê¸°: {len(cache)}")


# ============================================================================
# ì˜ˆì œ 4: ìš”ì²­ ë³€í™˜
# ============================================================================

def example_4_transform_request():
    """ëª¨ë¸ ìš”ì²­ì„ ë³€í™˜"""
    print("\n" + "=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 4: ìš”ì²­ ë³€í™˜")
    print("=" * 70)

    @wrap_model_call
    def add_context(
        request: ModelRequest,
        handler: Callable[[ModelRequest], ModelResponse],
    ) -> ModelResponse:
        # ëª¨ë“  ì‚¬ìš©ì ë©”ì‹œì§€ì— ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        modified_messages = []

        for msg in request.messages:
            if hasattr(msg, 'content') and isinstance(msg.content, str):
                if msg.type == "human":
                    modified_content = f"[ì¤‘ìš”] {msg.content}"
                    print(f"\nâœï¸ ë©”ì‹œì§€ ë³€í™˜: {msg.content} â†’ {modified_content}")

                    # ìƒˆ ë©”ì‹œì§€ ê°ì²´ ìƒì„±
                    from langchain_core.messages import HumanMessage
                    modified_messages.append(HumanMessage(content=modified_content))
                else:
                    modified_messages.append(msg)
            else:
                modified_messages.append(msg)

        # ë³€í™˜ëœ ìš”ì²­ìœ¼ë¡œ ëª¨ë¸ í˜¸ì¶œ
        modified_request = ModelRequest(messages=modified_messages)
        return handler(modified_request)

    @tool
    def process(text: str) -> str:
        """ì²˜ë¦¬"""
        return f"ì²˜ë¦¬ë¨: {text}"

    agent = create_agent(
        model="gpt-4o-mini",
        tools=[process],
        middleware=[add_context],
    )

    response = agent.invoke({
        "messages": [{"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”"}]
    })

    print(f"\nâœ… ì‘ë‹µ: {response['messages'][-1].content}")


# ============================================================================
# ì˜ˆì œ 5: ì¡°ê±´ë¶€ ëª¨ë¸ í˜¸ì¶œ (ë‹¨ë½)
# ============================================================================

def example_5_short_circuit():
    """íŠ¹ì • ì¡°ê±´ì—ì„œ ëª¨ë¸ í˜¸ì¶œ ê±´ë„ˆë›°ê¸°"""
    print("\n" + "=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 5: ì¡°ê±´ë¶€ ëª¨ë¸ í˜¸ì¶œ")
    print("=" * 70)

    @wrap_model_call
    def skip_simple_questions(
        request: ModelRequest,
        handler: Callable[[ModelRequest], ModelResponse],
    ) -> ModelResponse:
        # ë§ˆì§€ë§‰ ë©”ì‹œì§€ í™•ì¸
        last_msg = request.messages[-1] if request.messages else None

        if last_msg and hasattr(last_msg, 'content'):
            content = last_msg.content.lower()

            # ê°„ë‹¨í•œ ì¸ì‚¬ëŠ” ëª¨ë¸ í˜¸ì¶œ ì—†ì´ ì‘ë‹µ
            if content in ["ì•ˆë…•", "hi", "hello"]:
                print(f"\nâš¡ ê°„ë‹¨í•œ ì¸ì‚¬ ê°ì§€ - ëª¨ë¸ í˜¸ì¶œ ê±´ë„ˆë›°ê¸°")

                from langchain_core.messages import AIMessage
                return ModelResponse(message=AIMessage(content="ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"))

        print(f"\nğŸ” ì¼ë°˜ ì§ˆë¬¸ - ëª¨ë¸ í˜¸ì¶œ")
        return handler(request)

    @tool
    def help_tool() -> str:
        """ë„ì›€ë§"""
        return "ë„ì›€ë§ ë‚´ìš©"

    agent = create_agent(
        model="gpt-4o-mini",
        tools=[help_tool],
        middleware=[skip_simple_questions],
    )

    # ê°„ë‹¨í•œ ì¸ì‚¬
    print("\nğŸ”¹ ê°„ë‹¨í•œ ì¸ì‚¬:")
    response1 = agent.invoke({
        "messages": [{"role": "user", "content": "ì•ˆë…•"}]
    })
    print(f"âœ… ì‘ë‹µ: {response1['messages'][-1].content}")

    # ë³µì¡í•œ ì§ˆë¬¸
    print("\nğŸ”¹ ë³µì¡í•œ ì§ˆë¬¸:")
    response2 = agent.invoke({
        "messages": [{"role": "user", "content": "íŒŒì´ì¬ ì„¤ëª…í•´ì¤˜"}]
    })
    print(f"âœ… ì‘ë‹µ: {response2['messages'][-1].content[:60]}...")


# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("\n")
    print("ğŸ“ LangChain AI Agent ë§ˆìŠ¤í„° êµì•ˆ")
    print("ğŸ“– Part 5: ë¯¸ë“¤ì›¨ì–´ - wrap_model_call")
    print("\n")

    example_1_retry_model()
    input("\nâ ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")

    example_2_log_model_calls()
    input("\nâ ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")

    example_3_caching()
    input("\nâ ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")

    example_4_transform_request()
    input("\nâ ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")

    example_5_short_circuit()

    print("\n" + "=" * 70)
    print("ğŸ‰ Part 5-3 ì™„ë£Œ!")
    print("=" * 70 + "\n")


if __name__ == "__main__":
    main()


# ============================================================================
# ğŸ“š ì¶”ê°€ í•™ìŠµ í¬ì¸íŠ¸
# ============================================================================
#
# 1. wrap_model_callì˜ ê°•ë ¥í•¨:
#    - ì¬ì‹œë„ ë¡œì§ êµ¬í˜„
#    - ìºì‹±ìœ¼ë¡œ ë¹„ìš© ì ˆê°
#    - ìš”ì²­/ì‘ë‹µ ë³€í™˜
#    - ì¡°ê±´ë¶€ ëª¨ë¸ í˜¸ì¶œ (ë‹¨ë½)
#
# 2. handler í•¨ìˆ˜:
#    - ì‹¤ì œ ëª¨ë¸ í˜¸ì¶œì„ ìˆ˜í–‰
#    - ì—¬ëŸ¬ ë²ˆ í˜¸ì¶œ ê°€ëŠ¥ (ì¬ì‹œë„)
#    - í˜¸ì¶œí•˜ì§€ ì•Šì„ ìˆ˜ë„ ìˆìŒ (ë‹¨ë½)
#
# 3. ì‹¤ë¬´ í™œìš©:
#    - API ì¥ì•  ëŒ€ì‘ (ì¬ì‹œë„)
#    - ë¹„ìš© ìµœì í™” (ìºì‹±)
#    - A/B í…ŒìŠ¤íŒ…
#
# ============================================================================
