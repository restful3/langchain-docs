"""
================================================================================
LangChain AI Agent ë§ˆìŠ¤í„° êµì•ˆ
Part 5: Middleware - ì‹¤ìŠµ ê³¼ì œ 1 í•´ë‹µ
================================================================================

ê³¼ì œ: ë¹„ìš© ì¶”ì  Middleware
ë‚œì´ë„: â­â­â˜†â˜†â˜† (ì´ˆê¸‰)

ìš”êµ¬ì‚¬í•­:
1. í† í° ì‚¬ìš©ëŸ‰ ì¶”ì  (ì…ë ¥/ì¶œë ¥)
2. ëª¨ë¸ë³„ ë¹„ìš© ê³„ì‚°
3. ëˆ„ì  í†µê³„ ë° ë¦¬í¬íŠ¸

í•™ìŠµ ëª©í‘œ:
- Middleware êµ¬ì¡° ì´í•´
- í† í° ì‚¬ìš©ëŸ‰ ì¸¡ì •
- ë¹„ìš© ê³„ì‚° ë¡œì§ êµ¬í˜„

================================================================================
"""

from typing import Sequence, Literal
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_core.runnables import RunnableConfig
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.checkpoint.memory import MemorySaver
from datetime import datetime
import tiktoken

# ============================================================================
# ë¹„ìš© ê³„ì‚°ê¸°
# ============================================================================

class CostCalculator:
    """ëª¨ë¸ë³„ ë¹„ìš© ê³„ì‚°"""

    # ëª¨ë¸ë³„ ë¹„ìš© (1K í† í°ë‹¹ USD)
    PRICING = {
        "gpt-4o": {"input": 0.005, "output": 0.015},
        "gpt-4o-mini": {"input": 0.00015, "output": 0.0006},
        "gpt-4-turbo": {"input": 0.01, "output": 0.03},
        "gpt-3.5-turbo": {"input": 0.0005, "output": 0.0015},
    }

    @classmethod
    def calculate_cost(cls, model: str, input_tokens: int, output_tokens: int) -> float:
        """ë¹„ìš© ê³„ì‚°"""
        if model not in cls.PRICING:
            # ê¸°ë³¸ê°’ ì‚¬ìš©
            model = "gpt-4o-mini"

        pricing = cls.PRICING[model]
        input_cost = (input_tokens / 1000) * pricing["input"]
        output_cost = (output_tokens / 1000) * pricing["output"]

        return input_cost + output_cost

    @classmethod
    def get_pricing_info(cls, model: str) -> dict:
        """ëª¨ë¸ ê°€ê²© ì •ë³´"""
        return cls.PRICING.get(model, cls.PRICING["gpt-4o-mini"])


# ============================================================================
# í† í° ì¹´ìš´í„°
# ============================================================================

class TokenCounter:
    """í† í° ìˆ˜ ê³„ì‚°"""

    def __init__(self, model: str = "gpt-4o"):
        try:
            self.encoding = tiktoken.encoding_for_model(model)
        except KeyError:
            # ê¸°ë³¸ ì¸ì½”ë”© ì‚¬ìš©
            self.encoding = tiktoken.get_encoding("cl100k_base")

    def count_tokens(self, text: str) -> int:
        """í…ìŠ¤íŠ¸ì˜ í† í° ìˆ˜ ê³„ì‚°"""
        return len(self.encoding.encode(text))

    def count_messages_tokens(self, messages: Sequence[BaseMessage]) -> int:
        """ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ì˜ í† í° ìˆ˜ ê³„ì‚°"""
        total = 0
        for message in messages:
            # ë©”ì‹œì§€ êµ¬ì¡° ì˜¤ë²„í—¤ë“œ (ì•½ 4 í† í°)
            total += 4
            total += self.count_tokens(str(message.content))
        # ì‘ë‹µ í”„ë¼ì´ë°
        total += 2
        return total


# ============================================================================
# ë¹„ìš© ì¶”ì  Middleware
# ============================================================================

class CostTrackingMiddleware:
    """ë¹„ìš© ì¶”ì  ë¯¸ë“¤ì›¨ì–´"""

    def __init__(self):
        self.stats = {
            "total_requests": 0,
            "total_input_tokens": 0,
            "total_output_tokens": 0,
            "total_cost": 0.0,
            "requests": []
        }
        self.current_request = None

    def before_call(self, state: MessagesState, config: RunnableConfig):
        """LLM í˜¸ì¶œ ì „"""
        model = config.get("metadata", {}).get("model", "gpt-4o-mini")

        # í† í° ì¹´ìš´í„° ì´ˆê¸°í™”
        counter = TokenCounter(model)

        # ì…ë ¥ í† í° ê³„ì‚°
        input_tokens = counter.count_messages_tokens(state["messages"])

        # í˜„ì¬ ìš”ì²­ ì •ë³´ ì €ì¥
        self.current_request = {
            "timestamp": datetime.now().isoformat(),
            "model": model,
            "input_tokens": input_tokens,
            "output_tokens": 0,
            "cost": 0.0,
            "user_message": state["messages"][-1].content if state["messages"] else "",
        }

        print(f"ğŸ“Š [Cost Tracker] ì…ë ¥ í† í°: {input_tokens}")

    def after_call(self, result: dict, config: RunnableConfig):
        """LLM í˜¸ì¶œ í›„"""
        if not self.current_request:
            return

        model = self.current_request["model"]
        counter = TokenCounter(model)

        # ì¶œë ¥ ë©”ì‹œì§€ì˜ í† í° ìˆ˜ ê³„ì‚°
        output_messages = [
            msg for msg in result["messages"]
            if isinstance(msg, AIMessage)
        ]

        if output_messages:
            last_output = output_messages[-1]
            output_tokens = counter.count_tokens(last_output.content)
            self.current_request["output_tokens"] = output_tokens
            self.current_request["ai_response"] = last_output.content[:100] + "..."

        # ë¹„ìš© ê³„ì‚°
        cost = CostCalculator.calculate_cost(
            model,
            self.current_request["input_tokens"],
            self.current_request["output_tokens"]
        )
        self.current_request["cost"] = cost

        # í†µê³„ ì—…ë°ì´íŠ¸
        self.stats["total_requests"] += 1
        self.stats["total_input_tokens"] += self.current_request["input_tokens"]
        self.stats["total_output_tokens"] += self.current_request["output_tokens"]
        self.stats["total_cost"] += cost
        self.stats["requests"].append(self.current_request.copy())

        print(f"ğŸ“Š [Cost Tracker] ì¶œë ¥ í† í°: {output_tokens}")
        print(f"ğŸ’° [Cost Tracker] ë¹„ìš©: ${cost:.6f}")
        print(f"ğŸ“ˆ [Cost Tracker] ëˆ„ì  ë¹„ìš©: ${self.stats['total_cost']:.6f}")

        self.current_request = None

    def get_stats(self) -> dict:
        """í†µê³„ ì¡°íšŒ"""
        return self.stats.copy()

    def reset_stats(self):
        """í†µê³„ ì´ˆê¸°í™”"""
        self.stats = {
            "total_requests": 0,
            "total_input_tokens": 0,
            "total_output_tokens": 0,
            "total_cost": 0.0,
            "requests": []
        }

    def print_report(self):
        """ìƒì„¸ ë¦¬í¬íŠ¸ ì¶œë ¥"""
        print("\n" + "=" * 70)
        print("ğŸ’° ë¹„ìš© ì¶”ì  ë¦¬í¬íŠ¸")
        print("=" * 70)

        print(f"\nğŸ“Š ì „ì²´ í†µê³„:")
        print(f"  ì´ ìš”ì²­ ìˆ˜: {self.stats['total_requests']}")
        print(f"  ì´ ì…ë ¥ í† í°: {self.stats['total_input_tokens']:,}")
        print(f"  ì´ ì¶œë ¥ í† í°: {self.stats['total_output_tokens']:,}")
        print(f"  ì´ í† í°: {self.stats['total_input_tokens'] + self.stats['total_output_tokens']:,}")
        print(f"  ì´ ë¹„ìš©: ${self.stats['total_cost']:.6f}")

        if self.stats['total_requests'] > 0:
            avg_input = self.stats['total_input_tokens'] / self.stats['total_requests']
            avg_output = self.stats['total_output_tokens'] / self.stats['total_requests']
            avg_cost = self.stats['total_cost'] / self.stats['total_requests']

            print(f"\nğŸ“ˆ í‰ê· :")
            print(f"  ìš”ì²­ë‹¹ ì…ë ¥ í† í°: {avg_input:.1f}")
            print(f"  ìš”ì²­ë‹¹ ì¶œë ¥ í† í°: {avg_output:.1f}")
            print(f"  ìš”ì²­ë‹¹ ë¹„ìš©: ${avg_cost:.6f}")

        # ìµœê·¼ 5ê°œ ìš”ì²­
        if self.stats['requests']:
            print(f"\nğŸ“œ ìµœê·¼ ìš”ì²­ (ìµœëŒ€ 5ê°œ):")
            for i, req in enumerate(self.stats['requests'][-5:], 1):
                print(f"\n  {i}. {req['timestamp']}")
                print(f"     ëª¨ë¸: {req['model']}")
                print(f"     í† í°: {req['input_tokens']} â†’ {req['output_tokens']}")
                print(f"     ë¹„ìš©: ${req['cost']:.6f}")
                print(f"     ì§ˆë¬¸: {req['user_message'][:50]}...")

        print("\n" + "=" * 70)


# ============================================================================
# ë¹„ìš© ì¶”ì  ì±—ë´‡ êµ¬ì¶•
# ============================================================================

def create_cost_tracking_chatbot(model_name: str = "gpt-4o-mini"):
    """ë¹„ìš© ì¶”ì  ì±—ë´‡ ìƒì„±"""

    model = ChatOpenAI(model=model_name, temperature=0.7)
    middleware = CostTrackingMiddleware()

    # ì±—ë´‡ ë…¸ë“œ (ë¯¸ë“¤ì›¨ì–´ í†µí•©)
    def chatbot_node(state: MessagesState, config: RunnableConfig) -> dict:
        """ëŒ€í™” ì‘ë‹µ with ë¹„ìš© ì¶”ì """
        # Before call
        middleware.before_call(state, config)

        # LLM í˜¸ì¶œ
        response = model.invoke(state["messages"])
        result = {"messages": [response]}

        # After call
        middleware.after_call(result, config)

        return result

    # ê·¸ë˜í”„ êµ¬ì¶•
    graph_builder = StateGraph(MessagesState)
    graph_builder.add_node("chatbot", chatbot_node)
    graph_builder.add_edge(START, "chatbot")
    graph_builder.add_edge("chatbot", END)

    memory = MemorySaver()
    graph = graph_builder.compile(checkpointer=memory)

    return graph, middleware


# ============================================================================
# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
# ============================================================================

def test_cost_tracking():
    """ë¹„ìš© ì¶”ì  í…ŒìŠ¤íŠ¸"""
    print("=" * 70)
    print("ğŸ’° ë¹„ìš© ì¶”ì  Middleware í…ŒìŠ¤íŠ¸")
    print("=" * 70)

    # ì—¬ëŸ¬ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸
    models = ["gpt-4o-mini", "gpt-4o"]

    for model_name in models:
        print(f"\n{'=' * 70}")
        print(f"ğŸ” ëª¨ë¸: {model_name}")
        print("=" * 70)

        chatbot, middleware = create_cost_tracking_chatbot(model_name)
        config = {
            "configurable": {"thread_id": f"test_{model_name}"},
            "metadata": {"model": model_name}
        }

        # ê°€ê²© ì •ë³´
        pricing = CostCalculator.get_pricing_info(model_name)
        print(f"\nğŸ’µ ê°€ê²© ì •ë³´ (1K í† í°):")
        print(f"  ì…ë ¥: ${pricing['input']}")
        print(f"  ì¶œë ¥: ${pricing['output']}")

        # í…ŒìŠ¤íŠ¸ ëŒ€í™”
        test_messages = [
            "ì•ˆë…•í•˜ì„¸ìš”!",
            "Pythonì—ì„œ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "ë”•ì…”ë„ˆë¦¬ëŠ” ì–´ë–»ê²Œ ì‚¬ìš©í•˜ë‚˜ìš”?",
        ]

        for msg in test_messages:
            print(f"\n{'=' * 70}")
            print(f"ğŸ‘¤ ì‚¬ìš©ì: {msg}")
            print("=" * 70)

            result = chatbot.invoke(
                {"messages": [HumanMessage(content=msg)]},
                config
            )

            ai_response = result["messages"][-1].content
            print(f"\nğŸ¤– AI: {ai_response[:200]}...")

        # ë¦¬í¬íŠ¸ ì¶œë ¥
        middleware.print_report()


def test_cost_comparison():
    """ëª¨ë¸ë³„ ë¹„ìš© ë¹„êµ"""
    print("\n" + "=" * 70)
    print("ğŸ“Š ëª¨ë¸ë³„ ë¹„ìš© ë¹„êµ")
    print("=" * 70)

    test_message = "ì¸ê³µì§€ëŠ¥ì˜ ì—­ì‚¬ì™€ ë°œì „ ê³¼ì •ì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”."
    models = ["gpt-4o-mini", "gpt-4o", "gpt-4-turbo"]

    results = []

    for model_name in models:
        chatbot, middleware = create_cost_tracking_chatbot(model_name)
        config = {
            "configurable": {"thread_id": f"compare_{model_name}"},
            "metadata": {"model": model_name}
        }

        print(f"\nğŸ” {model_name} í…ŒìŠ¤íŠ¸ ì¤‘...")

        result = chatbot.invoke(
            {"messages": [HumanMessage(content=test_message)]},
            config
        )

        stats = middleware.get_stats()
        results.append({
            "model": model_name,
            "stats": stats
        })

    # ë¹„êµ í‘œ ì¶œë ¥
    print("\n" + "=" * 70)
    print("ğŸ“Š ë¹„êµ ê²°ê³¼")
    print("=" * 70)
    print(f"{'ëª¨ë¸':<20} {'ì…ë ¥ í† í°':>12} {'ì¶œë ¥ í† í°':>12} {'ë¹„ìš©':>12}")
    print("-" * 70)

    for r in results:
        print(
            f"{r['model']:<20} "
            f"{r['stats']['total_input_tokens']:>12} "
            f"{r['stats']['total_output_tokens']:>12} "
            f"${r['stats']['total_cost']:>11.6f}"
        )

    print("=" * 70)

    # ê°€ì¥ ì €ë ´í•œ ëª¨ë¸
    cheapest = min(results, key=lambda x: x['stats']['total_cost'])
    print(f"\nğŸ’¡ ê°€ì¥ ì €ë ´í•œ ëª¨ë¸: {cheapest['model']}")
    print(f"   ë¹„ìš©: ${cheapest['stats']['total_cost']:.6f}")


def interactive_mode():
    """ëŒ€í™”í˜• ëª¨ë“œ"""
    print("\n" + "=" * 70)
    print("ğŸ® ë¹„ìš© ì¶”ì  ì±—ë´‡ - ëŒ€í™”í˜• ëª¨ë“œ")
    print("=" * 70)
    print("ëª…ë ¹ì–´:")
    print("  /stats - í˜„ì¬ í†µê³„")
    print("  /report - ìƒì„¸ ë¦¬í¬íŠ¸")
    print("  /reset - í†µê³„ ì´ˆê¸°í™”")
    print("  /model <name> - ëª¨ë¸ ë³€ê²½")
    print("  /quit - ì¢…ë£Œ")
    print("=" * 70)

    current_model = "gpt-4o-mini"
    chatbot, middleware = create_cost_tracking_chatbot(current_model)
    config = {
        "configurable": {"thread_id": "interactive"},
        "metadata": {"model": current_model}
    }

    print(f"\ní˜„ì¬ ëª¨ë¸: {current_model}")
    pricing = CostCalculator.get_pricing_info(current_model)
    print(f"ê°€ê²© (1K í† í°): ì…ë ¥ ${pricing['input']}, ì¶œë ¥ ${pricing['output']}")

    while True:
        try:
            user_input = input(f"\n[{current_model}] ğŸ‘¤ : ").strip()

            if not user_input:
                continue

            if user_input == "/quit":
                middleware.print_report()
                print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

            elif user_input == "/stats":
                stats = middleware.get_stats()
                print(f"\nğŸ“Š í˜„ì¬ í†µê³„:")
                print(f"  ìš”ì²­ ìˆ˜: {stats['total_requests']}")
                print(f"  ì´ í† í°: {stats['total_input_tokens'] + stats['total_output_tokens']:,}")
                print(f"  ëˆ„ì  ë¹„ìš©: ${stats['total_cost']:.6f}")
                continue

            elif user_input == "/report":
                middleware.print_report()
                continue

            elif user_input == "/reset":
                middleware.reset_stats()
                print("âœ… í†µê³„ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                continue

            elif user_input.startswith("/model"):
                parts = user_input.split()
                if len(parts) < 2:
                    print("âŒ ì‚¬ìš©ë²•: /model <model_name>")
                    continue

                new_model = parts[1]
                current_model = new_model
                chatbot, middleware = create_cost_tracking_chatbot(current_model)
                config["metadata"]["model"] = current_model

                pricing = CostCalculator.get_pricing_info(current_model)
                print(f"âœ… ëª¨ë¸ ë³€ê²½: {current_model}")
                print(f"   ê°€ê²©: ì…ë ¥ ${pricing['input']}, ì¶œë ¥ ${pricing['output']}")
                continue

            # ì¼ë°˜ ë©”ì‹œì§€
            result = chatbot.invoke(
                {"messages": [HumanMessage(content=user_input)]},
                config
            )

            ai_response = result["messages"][-1].content
            print(f"\nğŸ¤– {ai_response}")

        except KeyboardInterrupt:
            middleware.print_report()
            print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")


# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("\n" + "=" * 70)
    print("ğŸ’° Part 5: ë¹„ìš© ì¶”ì  Middleware - ì‹¤ìŠµ ê³¼ì œ 1 í•´ë‹µ")
    print("=" * 70)

    try:
        # í…ŒìŠ¤íŠ¸ 1: ê¸°ë³¸ ë¹„ìš© ì¶”ì 
        test_cost_tracking()

        # í…ŒìŠ¤íŠ¸ 2: ëª¨ë¸ë³„ ë¹„êµ
        test_cost_comparison()

        # ëŒ€í™”í˜• ëª¨ë“œ
        print("\nëŒ€í™”í˜• ëª¨ë“œë¥¼ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ", end="")
        choice = input().strip().lower()

        if choice in ['y', 'yes', 'ì˜ˆ']:
            interactive_mode()

    except Exception as e:
        print(f"\nâš ï¸  ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

    # í•™ìŠµ í¬ì¸íŠ¸
    print("\n" + "=" * 70)
    print("ğŸ’¡ í•™ìŠµ í¬ì¸íŠ¸:")
    print("  1. before_call/after_call íŒ¨í„´")
    print("  2. tiktokenìœ¼ë¡œ í† í° ìˆ˜ ê³„ì‚°")
    print("  3. ëª¨ë¸ë³„ ê°€ê²© ì •ë³´ ê´€ë¦¬")
    print("  4. ëˆ„ì  í†µê³„ ë° ë¦¬í¬íŠ¸")
    print("\nğŸ’¡ ì¶”ê°€ í•™ìŠµ:")
    print("  1. ì˜ˆì‚° í•œë„ ì„¤ì • ë° ì•Œë¦¼")
    print("  2. ë¹„ìš© ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥")
    print("  3. ì‚¬ìš©ìë³„ ë¹„ìš© ì¶”ì ")
    print("  4. ëŒ€ì‹œë³´ë“œ ì‹œê°í™”")
    print("=" * 70)


if __name__ == "__main__":
    main()
