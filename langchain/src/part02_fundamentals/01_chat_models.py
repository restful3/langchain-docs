"""
================================================================================
LangChain AI Agent ë§ˆìŠ¤í„° êµì•ˆ
Part 2: LangChain ê¸°ì´ˆ
================================================================================

íŒŒì¼ëª…: 01_chat_models.py
ë‚œì´ë„: â­â­â˜†â˜†â˜† (ì´ˆê¸‰)
ì˜ˆìƒ ì‹œê°„: 20ë¶„

ğŸ“š í•™ìŠµ ëª©í‘œ:
  - Chat Modelsì˜ ê°œë… ì´í•´
  - ë‹¤ì–‘í•œ LLM í”„ë¡œë°”ì´ë” ì‚¬ìš©ë²•
  - init_chat_model() í†µí•© API ì´í•´

ğŸ“– ê³µì‹ ë¬¸ì„œ:
  â€¢ Models: /official/07-models.md

ğŸ”§ í•„ìš”í•œ íŒ¨í‚¤ì§€:
  pip install langchain-openai langchain-anthropic

ğŸš€ ì‹¤í–‰ ë°©ë²•:
  python 01_chat_models.py

================================================================================
"""

import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.chat_models import init_chat_model

load_dotenv()

# ============================================================================
# ì˜ˆì œ 1: ChatOpenAI ê¸°ë³¸ ì‚¬ìš©
# ============================================================================

def example_1_basic_chat():
    """ê°€ì¥ ê¸°ë³¸ì ì¸ Chat Model ì‚¬ìš©"""
    print("=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 1: ChatOpenAI ê¸°ë³¸ ì‚¬ìš©")
    print("=" * 70)

    # Chat Model ì´ˆê¸°í™”
    model = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.7,
        max_tokens=1000,
    )

    # ê°„ë‹¨í•œ í˜¸ì¶œ
    response = model.invoke("LangChainì´ ë¬´ì—‡ì¸ê°€ìš”? í•œ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.")

    print(f"\nğŸ¤– ì‘ë‹µ: {response.content}\n")


# ============================================================================
# ì˜ˆì œ 2: init_chat_model() - í†µí•© API
# ============================================================================

def example_2_init_chat_model():
    """í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ìë™ ëª¨ë¸ ì„ íƒ"""
    print("=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 2: init_chat_model() í†µí•© API")
    print("=" * 70)

    # í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ëœ API í‚¤ ê¸°ë°˜ìœ¼ë¡œ ìë™ ì„ íƒ
    model = init_chat_model()

    response = model.invoke("ì•ˆë…•í•˜ì„¸ìš”!")

    print(f"\nğŸ¤– ëª¨ë¸: {model.model_name}")
    print(f"ğŸ¤– ì‘ë‹µ: {response.content}\n")


# ============================================================================
# ì˜ˆì œ 3: Temperature ì¡°ì ˆ
# ============================================================================

def example_3_temperature():
    """Temperatureë¡œ ì°½ì˜ì„± ì¡°ì ˆ"""
    print("=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 3: Temperatureë¡œ ì°½ì˜ì„± ì¡°ì ˆ")
    print("=" * 70)

    prompt = "AIì— ëŒ€í•œ ì¬ë¯¸ìˆëŠ” ë†ë‹´ í•˜ë‚˜ í•´ì£¼ì„¸ìš”."

    # Temperature 0.0 (ê²°ì •ì )
    model_deterministic = ChatOpenAI(model="gpt-4o-mini", temperature=0.0)
    response1 = model_deterministic.invoke(prompt)

    # Temperature 1.0 (ì°½ì˜ì )
    model_creative = ChatOpenAI(model="gpt-4o-mini", temperature=1.0)
    response2 = model_creative.invoke(prompt)

    print(f"\nğŸŒ¡ï¸ Temperature 0.0 (ê²°ì •ì ):")
    print(f"   {response1.content}")

    print(f"\nğŸŒ¡ï¸ Temperature 1.0 (ì°½ì˜ì ):")
    print(f"   {response2.content}\n")


# ============================================================================
# ì˜ˆì œ 4: ìŠ¤íŠ¸ë¦¬ë°
# ============================================================================

def example_4_streaming():
    """ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ"""
    print("=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 4: ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ")
    print("=" * 70)

    model = ChatOpenAI(model="gpt-4o-mini", temperature=0.7, streaming=True)

    print("\nğŸ¤– ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ:")
    print("   ", end="", flush=True)

    for chunk in model.stream("íŒŒì´ì¬ì˜ ì¥ì  3ê°€ì§€ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”."):
        print(chunk.content, end="", flush=True)

    print("\n")


# ============================================================================
# ì˜ˆì œ 5: ë‹¤ì–‘í•œ í”„ë¡œë°”ì´ë”
# ============================================================================

def example_5_multiple_providers():
    """ì—¬ëŸ¬ LLM í”„ë¡œë°”ì´ë” ì‚¬ìš©"""
    print("=" * 70)
    print("ğŸ“Œ ì˜ˆì œ 5: ë‹¤ì–‘í•œ LLM í”„ë¡œë°”ì´ë”")
    print("=" * 70)

    prompt = "ì•ˆë…•í•˜ì„¸ìš”!"

    # OpenAI
    if os.getenv("OPENAI_API_KEY"):
        from langchain_openai import ChatOpenAI
        openai_model = ChatOpenAI(model="gpt-4o-mini")
        response = openai_model.invoke(prompt)
        print(f"\nâœ… OpenAI (gpt-4o-mini): {response.content}")

    # Anthropic
    if os.getenv("ANTHROPIC_API_KEY"):
        from langchain_anthropic import ChatAnthropic
        anthropic_model = ChatAnthropic(model="claude-haiku-4-5-20251001")
        response = anthropic_model.invoke(prompt)
        print(f"\nâœ… Anthropic (claude-haiku-4-5): {response.content}")

    # Google
    if os.getenv("GOOGLE_API_KEY"):
        from langchain_google_genai import ChatGoogleGenerativeAI
        google_model = ChatGoogleGenerativeAI(model="gemini-2.5-flash-lite")
        response = google_model.invoke(prompt)
        print(f"\nâœ… Google (gemini-2.5-flash-lite): {response.content}")

    print()


# ============================================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================================

def main():
    print("\nğŸ“ Part 2: LangChain ê¸°ì´ˆ - Chat Models\n")

    example_1_basic_chat()
    input("â ê³„ì†í•˜ë ¤ë©´ Enter...")

    example_2_init_chat_model()
    input("â ê³„ì†í•˜ë ¤ë©´ Enter...")

    example_3_temperature()
    input("â ê³„ì†í•˜ë ¤ë©´ Enter...")

    example_4_streaming()
    input("â ê³„ì†í•˜ë ¤ë©´ Enter...")

    example_5_multiple_providers()

    print("=" * 70)
    print("ğŸ‰ Chat Models í•™ìŠµ ì™„ë£Œ!")
    print("ğŸ“– ë‹¤ìŒ: 02_messages.py - ë©”ì‹œì§€ íƒ€ì…")
    print("=" * 70 + "\n")


if __name__ == "__main__":
    main()
