# Part 2: LangChain í•µì‹¬ êµ¬ì„± ìš”ì†Œ

> ğŸ“š **í•™ìŠµ ì‹œê°„**: ì•½ 3-4ì‹œê°„
>
> ğŸ¯ **ë‚œì´ë„**: â­â­â˜†â˜†â˜† (ì´ˆê¸‰)
>
> ğŸ› ï¸ **í™˜ê²½ ì„¤ì •**: [SETUP_GUIDE.md](../SETUP_GUIDE.md) â€” API í‚¤ ì„¤ì •, íŒ¨í‚¤ì§€ ì„¤ì¹˜, ì‹¤í–‰ í™˜ê²½ êµ¬ì„±
>
> ğŸ“– **ê³µì‹ ë¬¸ì„œ**: [07-models.md](../official/07-models_ko.md), [08-messages.md](../official/08-messages_ko.md), [09-tools.md](../official/09-tools_ko.md)
>
> ğŸ’» **ì˜ˆì œ ì½”ë“œ**: [part02_fundamentals ë””ë ‰í† ë¦¬](../src/part02_fundamentals/)

---

## ğŸ“‹ í•™ìŠµ ëª©í‘œ

ì´ íŒŒíŠ¸ë¥¼ ì™„ë£Œí•˜ë©´ ë‹¤ìŒì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- [ ] `init_chat_model()`ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ LLM í”„ë¡œë°”ì´ë”ì˜ ëª¨ë¸ì„ ì´ˆê¸°í™”í•  ìˆ˜ ìˆë‹¤
- [ ] SystemMessage, HumanMessage, AIMessageì˜ ì—­í• ê³¼ ì‚¬ìš©ë²•ì„ ì´í•´í•œë‹¤
- [ ] `@tool` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ë³¸ ë„êµ¬ë¥¼ ë§Œë“¤ ìˆ˜ ìˆë‹¤
- [ ] Pydantic ìŠ¤í‚¤ë§ˆë¥¼ í™œìš©í•˜ì—¬ ë³µì¡í•œ ì…ë ¥ì„ ë°›ëŠ” ë„êµ¬ë¥¼ ì •ì˜í•  ìˆ˜ ìˆë‹¤
- [ ] ToolRuntimeì„ í†µí•´ Agent ìƒíƒœì™€ ì»¨í…ìŠ¤íŠ¸ì— ì ‘ê·¼í•˜ëŠ” ë°©ë²•ì„ ì´í•´í•œë‹¤
- [ ] Tool Callingì˜ ë™ì‘ ì›ë¦¬ì™€ ëª¨ë¸ì´ ë„êµ¬ë¥¼ ì„ íƒí•˜ëŠ” ê³¼ì •ì„ ì´í•´í•œë‹¤

---

## ğŸ“š ê°œìš”

ì´ íŒŒíŠ¸ì—ì„œëŠ” **LangChain Agentë¥¼ êµ¬ì„±í•˜ëŠ” í•µì‹¬ ìš”ì†Œ**ì¸ Chat Models, Messages, Toolsë¥¼ í•™ìŠµí•©ë‹ˆë‹¤. ì´ ì„¸ ê°€ì§€ êµ¬ì„± ìš”ì†ŒëŠ” ëª¨ë“  LangChain ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ê¸°ì´ˆê°€ ë©ë‹ˆë‹¤.

### ì™œ ì¤‘ìš”í•œê°€?

- **ëª¨ë¸ì˜ í‘œì¤€í™”**: ë‹¤ì–‘í•œ LLM í”„ë¡œë°”ì´ë”(OpenAI, Anthropic, Google ë“±)ë¥¼ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- **ëŒ€í™”ì˜ êµ¬ì¡°í™”**: Messagesë¥¼ í†µí•´ ëŒ€í™” íë¦„ì„ ëª…í™•í•˜ê²Œ ê´€ë¦¬í•˜ê³  ì¶”ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- **ëŠ¥ë ¥ì˜ í™•ì¥**: Toolsë¥¼ í†µí•´ LLMì´ ì™¸ë¶€ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³  ì‹¤ì œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- **í”„ë¡œë•ì…˜ ì¤€ë¹„**: ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” íŒ¨í„´ê³¼ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ë¥¼ ìµí™ë‹ˆë‹¤

### ì‹¤ë¬´ í™œìš© ì‚¬ë¡€

- **ë©€í‹° ëª¨ë¸ ì „ëµ**: ë¹„ìš© ì ˆê°ì„ ìœ„í•´ ê°„ë‹¨í•œ ì‘ì—…ì€ GPT-4o-mini, ë³µì¡í•œ ì‘ì—…ì€ Claude ì‚¬ìš©
- **ëŒ€í™”í˜• AI ì„œë¹„ìŠ¤**: ê³ ê° ì§ˆë¬¸ì„ ì´í•´í•˜ê³  ë§¥ë½ì„ ìœ ì§€í•˜ë©° ë‹µë³€í•˜ëŠ” ì±—ë´‡
- **ë°ì´í„° ì¡°íšŒ Agent**: ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ê³  ê²°ê³¼ë¥¼ ìì—°ì–´ë¡œ ì„¤ëª…
- **ìë™í™” ì›Œí¬í”Œë¡œìš°**: API í˜¸ì¶œ, íŒŒì¼ ì²˜ë¦¬, ì´ë©”ì¼ ë°œì†¡ ë“±ì˜ ì‘ì—…ì„ ìë™ìœ¼ë¡œ ìˆ˜í–‰

---

## 1. Chat Models ì´í•´í•˜ê¸°

### 1.1 Chat Modelsë€?

**Chat Models**ì€ LLM(Large Language Model)ì„ LangChainì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í‘œì¤€í™”ëœ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ë˜í¼ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë‹¤ì–‘í•œ í”„ë¡œë°”ì´ë”ì˜ ëª¨ë¸ì„ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```mermaid
graph LR
    A[LangChain Application] --> B[Chat Model Interface]
    B --> C[OpenAI<br/>GPT-4, GPT-4o]
    B --> D[Anthropic<br/>Claude 4.5]
    B --> E[Google<br/>Gemini]
    B --> F[Azure<br/>Azure OpenAI]

    style B fill:#e1f5ff,stroke:#01579b
    style C fill:#fff3e0,stroke:#e65100
    style D fill:#f3e5f5,stroke:#4a148c
    style E fill:#e8f5e9,stroke:#1b5e20
    style F fill:#e3f2fd,stroke:#0d47a1
```

> ğŸ“– **ê³µì‹ ë¬¸ì„œ**: [07-models.md](../official/07-models_ko.md#ê¸°ë³¸-ì‚¬ìš©ë²•)

#### í•µì‹¬ íŠ¹ì§•

1. **í‘œì¤€í™”ëœ ì¸í„°í˜ì´ìŠ¤**
   - ëª¨ë“  í”„ë¡œë°”ì´ë”ê°€ ë™ì¼í•œ ë©”ì„œë“œ ì œê³µ: `invoke()`, `stream()`, `batch()`
   - ë²¤ë” ì¢…ì†ì„±(lock-in) ë°©ì§€

2. **ë‹¤ì–‘í•œ í”„ë¡œë°”ì´ë” ì§€ì›**
   - OpenAI, Anthropic, Google, Azure, AWS Bedrock, HuggingFace ë“±
   - ë¡œì»¬ ëª¨ë¸(Ollama)ë„ ì§€ì›

3. **í’ë¶€í•œ ê¸°ëŠ¥**
   - Tool calling (í•¨ìˆ˜ í˜¸ì¶œ)
   - Structured output (êµ¬ì¡°í™”ëœ ì¶œë ¥)
   - Multimodal (ì´ë¯¸ì§€, ì˜¤ë””ì˜¤, ë¹„ë””ì˜¤)
   - Reasoning (ì¶”ë¡  ê³¼ì • ë…¸ì¶œ)

### 1.2 init_chat_model() ì‚¬ìš©ë²•

`init_chat_model()`ì€ Chat Modelì„ ì´ˆê¸°í™”í•˜ëŠ” ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ì…ë‹ˆë‹¤. ëª¨ë¸ ì´ë¦„ë§Œ ì „ë‹¬í•˜ë©´ LangChainì´ ìë™ìœ¼ë¡œ ì ì ˆí•œ í”„ë¡œë°”ì´ë”ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.

#### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from langchain.chat_models import init_chat_model

# ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•
model = init_chat_model("gpt-4o-mini")

# ëª¨ë¸ í˜¸ì¶œ
response = model.invoke("ì•ˆë…•í•˜ì„¸ìš”! LangChainì´ ë¬´ì—‡ì¸ê°€ìš”?")
print(response.content)
```

**ğŸ’¡ ì‹¤í–‰ ê²°ê³¼**:
```
LangChainì€ LLM(Large Language Model) ê¸°ë°˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‰½ê²Œ ê°œë°œí•  ìˆ˜ ìˆë„ë¡
ë•ëŠ” ì˜¤í”ˆì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤...
```

> ğŸ’» **ì˜ˆì œ ì½”ë“œ**: [01_chat_models.py](../src/part02_fundamentals/01_chat_models.py) ë¼ì¸ 39-55

#### í”„ë¡œë°”ì´ë” ëª…ì‹œì  ì§€ì •

```python
# í”„ë¡œë°”ì´ë”ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •
model = init_chat_model(
    model="gpt-4o-mini",
    model_provider="openai"
)

# ë˜ëŠ” "í”„ë¡œë°”ì´ë”:ëª¨ë¸" í˜•ì‹ ì‚¬ìš©
model = init_chat_model("openai:gpt-4o-mini")
```

### 1.3 í”„ë¡œë°”ì´ë”ë³„ ì„¤ì •

ê° í”„ë¡œë°”ì´ë”ë§ˆë‹¤ ê³ ìœ í•œ ì„¤ì • ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¡œ API í‚¤ë¥¼ ì„¤ì •í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤.

#### OpenAI ì„¤ì •

```python
import os
from langchain.chat_models import init_chat_model

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ["OPENAI_API_KEY"] = "sk-..."

# ëª¨ë¸ ì´ˆê¸°í™”
model = init_chat_model("gpt-4o-mini")

# ë˜ëŠ” ì§ì ‘ í´ë˜ìŠ¤ ì‚¬ìš©
from langchain_openai import ChatOpenAI
model = ChatOpenAI(model="gpt-4o-mini")
```

**ì£¼ìš” ëª¨ë¸**:
- `gpt-4o`: ìµœì‹  í”Œë˜ê·¸ì‹­ ëª¨ë¸ (2024-11)
- `gpt-4o-mini`: ë¹„ìš© íš¨ìœ¨ì ì¸ ì†Œí˜• ëª¨ë¸
- `gpt-4-turbo`: ì´ì „ ì„¸ëŒ€ ê³ ì„±ëŠ¥ ëª¨ë¸

#### Anthropic (Claude) ì„¤ì •

```python
import os
from langchain.chat_models import init_chat_model

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ["ANTHROPIC_API_KEY"] = "sk-ant-..."

# ëª¨ë¸ ì´ˆê¸°í™”
model = init_chat_model("claude-sonnet-4-5-20250929")

# ë˜ëŠ” ì§ì ‘ í´ë˜ìŠ¤ ì‚¬ìš©
from langchain_anthropic import ChatAnthropic
model = ChatAnthropic(model="claude-sonnet-4-5-20250929")
```

**ì£¼ìš” ëª¨ë¸**:
- `claude-opus-4-5-20251101`: ìµœê³  ì„±ëŠ¥ ëª¨ë¸
- `claude-sonnet-4-5-20250929`: ê· í˜•ì¡íŒ ì„±ëŠ¥
- `claude-haiku-4-5-20251001`: ë¹ ë¥´ê³  ì €ë ´í•œ ëª¨ë¸

> ğŸ“– **ê³µì‹ ë¬¸ì„œ**: [07-models.md](../official/07-models_ko.md#anthropic)

#### Google Gemini ì„¤ì •

```python
import os
from langchain.chat_models import init_chat_model

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ["GOOGLE_API_KEY"] = "..."

# ëª¨ë¸ ì´ˆê¸°í™”
model = init_chat_model("google_genai:gemini-2.5-flash-lite")

# ë˜ëŠ” ì§ì ‘ í´ë˜ìŠ¤ ì‚¬ìš©
from langchain_google_genai import ChatGoogleGenerativeAI
model = ChatGoogleGenerativeAI(model="gemini-2.5-flash-lite")
```

#### Azure OpenAI ì„¤ì •

```python
import os
from langchain.chat_models import init_chat_model

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ["AZURE_OPENAI_API_KEY"] = "..."
os.environ["AZURE_OPENAI_ENDPOINT"] = "https://your-resource.openai.azure.com"
os.environ["OPENAI_API_VERSION"] = "2025-03-01-preview"

# ëª¨ë¸ ì´ˆê¸°í™”
model = init_chat_model(
    "azure_openai:gpt-4.1",
    azure_deployment="your-deployment-name"
)
```

> ğŸ’» **ì˜ˆì œ ì½”ë“œ**: [01_chat_models.py](../src/part02_fundamentals/01_chat_models.py) ë¼ì¸ 129-158

### 1.4 Temperatureì™€ ì£¼ìš” íŒŒë¼ë¯¸í„°

Chat Modelì˜ ë™ì‘ì„ ì œì–´í•˜ëŠ” ì£¼ìš” íŒŒë¼ë¯¸í„°ë“¤ì„ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

#### Temperature (ì˜¨ë„)

**Temperature**ëŠ” ëª¨ë¸ ì¶œë ¥ì˜ ë¬´ì‘ìœ„ì„±ì„ ì œì–´í•©ë‹ˆë‹¤. 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê²°ì •ë¡ ì ì´ê³ , 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì°½ì˜ì ì…ë‹ˆë‹¤.

```python
# ë‚®ì€ temperature (0~0.3): ì¼ê´€ë˜ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì¶œë ¥
deterministic_model = init_chat_model(
    "gpt-4o-mini",
    temperature=0.0
)

# ì¤‘ê°„ temperature (0.5~0.7): ê· í˜•ì¡íŒ ì¶œë ¥ (ê¸°ë³¸ê°’)
balanced_model = init_chat_model(
    "gpt-4o-mini",
    temperature=0.7
)

# ë†’ì€ temperature (0.8~1.0): ì°½ì˜ì ì´ê³  ë‹¤ì–‘í•œ ì¶œë ¥
creative_model = init_chat_model(
    "gpt-4o-mini",
    temperature=1.0
)
```

**ì‚¬ìš© ê°€ì´ë“œ**:
- **Temperature 0.0**: ë°ì´í„° ì¶”ì¶œ, ë¶„ë¥˜, ë²ˆì—­ ë“± ì •í™•ì„±ì´ ì¤‘ìš”í•œ ì‘ì—…
- **Temperature 0.7**: ì¼ë°˜ì ì¸ ëŒ€í™”, ì§ˆì˜ì‘ë‹µ (ëŒ€ë¶€ë¶„ì˜ ê²½ìš°)
- **Temperature 1.0**: ì°½ì˜ì  ê¸€ì“°ê¸°, ë¸Œë ˆì¸ìŠ¤í† ë°, ì•„ì´ë””ì–´ ìƒì„±

#### ê¸°íƒ€ ì£¼ìš” íŒŒë¼ë¯¸í„°

```python
model = init_chat_model(
    "gpt-4o-mini",
    # ì¶œë ¥ ê¸¸ì´ ì œí•œ
    max_tokens=1000,

    # ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
    timeout=30,

    # ì¬ì‹œë„ íšŸìˆ˜
    max_retries=3,

    # Temperature (ë¬´ì‘ìœ„ì„±)
    temperature=0.7,
)
```

**íŒŒë¼ë¯¸í„° ì„¤ëª…**:

| íŒŒë¼ë¯¸í„° | íƒ€ì… | ì„¤ëª… | ê¸°ë³¸ê°’ |
|---------|------|------|-------|
| `model` | `str` | ëª¨ë¸ ì´ë¦„ (í•„ìˆ˜) | - |
| `temperature` | `float` | ì¶œë ¥ì˜ ë¬´ì‘ìœ„ì„± (0.0~1.0) | 0.7 |
| `max_tokens` | `int` | ìµœëŒ€ ì¶œë ¥ í† í° ìˆ˜ | ì œí•œ ì—†ìŒ |
| `timeout` | `int` | ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ì´ˆ) | 60 |
| `max_retries` | `int` | ì¬ì‹œë„ íšŸìˆ˜ | 2 |

> ğŸ’» **ì˜ˆì œ ì½”ë“œ**: [01_chat_models.py](../src/part02_fundamentals/01_chat_models.py) ë¼ì¸ 81-101

### 1.5 Model Profiles & Capabilities Detection

**Model Profiles**ëŠ” ëª¨ë¸ì˜ ì§€ì› ê¸°ëŠ¥ê³¼ ì œì•½ì‚¬í•­ì„ í™•ì¸í•  ìˆ˜ ìˆëŠ” ë©”íƒ€ë°ì´í„°ì…ë‹ˆë‹¤.

#### Model Profileì´ë€?

ê° Chat Modelì€ `.profile` ì†ì„±ì„ í†µí•´ ìì‹ ì˜ capabilitiesë¥¼ ë…¸ì¶œí•©ë‹ˆë‹¤:

```python
from langchain.chat_models import init_chat_model

model = init_chat_model("gpt-4o")

# Model profile í™•ì¸
print(model.profile)
# {
#   "max_input_tokens": 128000,
#   "image_inputs": True,
#   "audio_inputs": False,
#   "video_inputs": False,
#   "tool_calling": True,
#   "structured_output": True,
# }
```

#### ì£¼ìš” Profile í•„ë“œ

| í•„ë“œ | íƒ€ì… | ì„¤ëª… |
|------|------|------|
| `max_input_tokens` | `int` | ìµœëŒ€ ì…ë ¥ í† í° ìˆ˜ (context window) |
| `max_output_tokens` | `int` | ìµœëŒ€ ì¶œë ¥ í† í° ìˆ˜ |
| `image_inputs` | `bool` | ì´ë¯¸ì§€ ì…ë ¥ ì§€ì› ì—¬ë¶€ |
| `audio_inputs` | `bool` | ì˜¤ë””ì˜¤ ì…ë ¥ ì§€ì› ì—¬ë¶€ |
| `video_inputs` | `bool` | ë¹„ë””ì˜¤ ì…ë ¥ ì§€ì› ì—¬ë¶€ |
| `tool_calling` | `bool` | Tool calling ì§€ì› ì—¬ë¶€ |
| `structured_output` | `bool` | Structured output ì§€ì› ì—¬ë¶€ |

#### ì‹¤ì „ í™œìš© ì‚¬ë¡€

**1. Context Window ê¸°ë°˜ ë™ì  ì²˜ë¦¬**

```python
def process_with_context_awareness(model, messages):
    """ëª¨ë¸ì˜ context windowì— ë§ê²Œ ë©”ì‹œì§€ ì²˜ë¦¬"""
    max_tokens = model.profile.get("max_input_tokens", 4096)

    # í† í° ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ ì¶”ì •)
    total_tokens = sum(len(m.content.split()) * 1.3 for m in messages)

    if total_tokens > max_tokens * 0.8:  # 80% ì´ìƒ ì‚¬ìš© ì‹œ
        print(f"âš ï¸ Context window ê·¼ì ‘: {total_tokens}/{max_tokens}")
        # ìš”ì•½ ë˜ëŠ” ë©”ì‹œì§€ trimming í•„ìš”
        return trigger_summarization(messages)

    return model.invoke(messages)
```

**2. Multimodal Capability ì²´í¬**

```python
def send_image_if_supported(model, image_url, prompt):
    """ëª¨ë¸ì´ ì´ë¯¸ì§€ë¥¼ ì§€ì›í•˜ëŠ” ê²½ìš°ë§Œ ì „ì†¡"""
    if model.profile.get("image_inputs", False):
        # ì´ë¯¸ì§€ í¬í•¨ ë©”ì‹œì§€ ì „ì†¡
        return model.invoke([
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": image_url}}
                ]
            }
        ])
    else:
        # í…ìŠ¤íŠ¸ë§Œ ì „ì†¡
        print("âš ï¸ ì´ ëª¨ë¸ì€ ì´ë¯¸ì§€ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return model.invoke(prompt)
```

**3. Tool Calling ì§€ì› í™•ì¸**

```python
from langchain.tools import tool

@tool
def get_weather(city: str) -> str:
    """ë„ì‹œì˜ ë‚ ì”¨ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
    return f"{city}: ë§‘ìŒ, 22ë„"

def create_agent_with_fallback(model_name):
    """Tool calling ì§€ì› ì—¬ë¶€ì— ë”°ë¼ Agent ìƒì„±"""
    model = init_chat_model(model_name)

    if model.profile.get("tool_calling", False):
        # Tool calling ì§€ì› â†’ Agent ìƒì„±
        from langgraph.prebuilt import create_react_agent
        return create_react_agent(model=model, tools=[get_weather])
    else:
        # Tool calling ë¯¸ì§€ì› â†’ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ fallback
        print(f"âš ï¸ {model_name}ì€ tool callingì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return create_prompt_based_agent(model)
```

#### Profile Data ì¶œì²˜

Model profile ë°ì´í„°ëŠ” [models.dev](https://models.dev/) í”„ë¡œì íŠ¸ì—ì„œ ì œê³µë©ë‹ˆë‹¤:
- ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ capability ë°ì´í„°ë² ì´ìŠ¤
- LangChain integration packagesì—ì„œ augmentation ì¶”ê°€
- ì»¤ë®¤ë‹ˆí‹° ê¸°ì—¬ë¡œ ì§€ì† ì—…ë°ì´íŠ¸

#### Custom Profile ì„¤ì •

Model profileì´ ì˜ëª»ë˜ì—ˆê±°ë‚˜ ëˆ„ë½ëœ ê²½ìš° ì§ì ‘ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
# Option 1: ì´ˆê¸°í™” ì‹œ ì§€ì •
custom_profile = {
    "max_input_tokens": 100_000,
    "tool_calling": True,
    "structured_output": True,
    "image_inputs": False,
}

model = init_chat_model(
    "custom-model",
    profile=custom_profile
)

# Option 2: ê¸°ì¡´ profile ì—…ë°ì´íŠ¸
from copy import copy

new_profile = model.profile | {"max_output_tokens": 4096}
model = model.model_copy(update={"profile": new_profile})
```

#### ì£¼ì˜ì‚¬í•­

**1. Profileì€ Beta ê¸°ëŠ¥**:
- Profile í˜•ì‹ì€ ë³€ê²½ë  ìˆ˜ ìˆìŒ
- í•­ìƒ ìµœì‹  LangChain ë²„ì „ ì‚¬ìš© ê¶Œì¥ (`langchain>=1.1`)

**2. ëª¨ë“  ëª¨ë¸ì´ ì™„ì „í•œ Profileì„ ì œê³µí•˜ì§€ëŠ” ì•ŠìŒ**:
```python
# Profile ë°ì´í„° ì—†ì„ ë•Œ ëŒ€ë¹„
max_tokens = model.profile.get("max_input_tokens")
if max_tokens is None:
    print("âš ï¸ Profile ë°ì´í„° ì—†ìŒ - ê¸°ë³¸ê°’ ì‚¬ìš©")
    max_tokens = 4096  # Fallback
```

**3. Profile vs ì‹¤ì œ ë™ì‘**:
- Profileì€ **ì„ ì–¸ì  ë©”íƒ€ë°ì´í„°**ì¼ ë¿
- ì‹¤ì œ API ì‘ë‹µì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ (ë²„ì „, ì„¤ì •ì— ë”°ë¼)
- ì¤‘ìš”í•œ ê¸°ëŠ¥ì€ í•­ìƒ ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê¶Œì¥

> ğŸ’¡ **í•µì‹¬ í¬ì¸íŠ¸**:
> - Model profileë¡œ ëª¨ë¸ì˜ capabilitiesë¥¼ í”„ë¡œê·¸ë˜ë° ë°©ì‹ìœ¼ë¡œ í™•ì¸
> - Context window, multimodal ì§€ì›, tool calling ë“± ì²´í¬
> - ë™ì  ì²˜ë¦¬ ë¡œì§ êµ¬í˜„ ê°€ëŠ¥ (summarization, input gating)
> - models.dev ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì§€ì† ì—…ë°ì´íŠ¸

---

## 2. Messages ë‹¤ë£¨ê¸°

### 2.1 Messages ê°œìš”

**Messages**ëŠ” LangChainì—ì„œ ëŒ€í™”ì˜ ê¸°ë³¸ ë‹¨ìœ„ì…ë‹ˆë‹¤. ê° ë©”ì‹œì§€ëŠ” ì—­í• (role)ê³¼ ë‚´ìš©(content)ì„ ê°€ì§€ë©°, ëŒ€í™”ì˜ ë§¥ë½ì„ êµ¬ì„±í•©ë‹ˆë‹¤.

```mermaid
graph LR
    A[Messages] --> B[SystemMessage<br/>ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­]
    A --> C[HumanMessage<br/>ì‚¬ìš©ì ì…ë ¥]
    A --> D[AIMessage<br/>AI ì‘ë‹µ]
    A --> E[ToolMessage<br/>ë„êµ¬ ì‹¤í–‰ ê²°ê³¼]

    style A fill:#e1f5ff,stroke:#01579b,stroke-width:3px
    style B fill:#fff3e0,stroke:#e65100
    style C fill:#e8f5e9,stroke:#1b5e20
    style D fill:#f3e5f5,stroke:#4a148c
    style E fill:#fce4ec,stroke:#880e4f
```

**Messageì˜ êµ¬ì„± ìš”ì†Œ**:
- **Role (ì—­í• )**: ë©”ì‹œì§€ ë°œì‹ ì (system, user, assistant, tool)
- **Content (ë‚´ìš©)**: ì‹¤ì œ ë©”ì‹œì§€ ë‚´ìš© (í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ì˜¤ë””ì˜¤ ë“±)
- **Metadata (ë©”íƒ€ë°ì´í„°)**: ID, í† í° ì‚¬ìš©ëŸ‰, ì‘ë‹µ ì •ë³´ ë“±

> ğŸ“– **ê³µì‹ ë¬¸ì„œ**: [08-messages.md](../official/08-messages_ko.md#ë©”ì‹œì§€-ìœ í˜•)
> ğŸ’» **ì˜ˆì œ ì½”ë“œ**: [02_messages.py](../src/part02_fundamentals/02_messages.py)

### 2.2 SystemMessage - ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­

`SystemMessage`ëŠ” ëª¨ë¸ì˜ í–‰ë™ ë°©ì‹ê³¼ ì—­í• ì„ ì •ì˜í•˜ëŠ” ì´ˆê¸° ì§€ì‹œì‚¬í•­ì…ë‹ˆë‹¤. ëŒ€í™”ì˜ ë§¨ ì•ì— ìœ„ì¹˜í•˜ë©° ëª¨ë¸ì˜ "ì„±ê²©"ì„ ê²°ì •í•©ë‹ˆë‹¤.

#### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from langchain.messages import SystemMessage, HumanMessage

# ê°„ë‹¨í•œ ì‹œìŠ¤í…œ ë©”ì‹œì§€
system_msg = SystemMessage("ë‹¹ì‹ ì€ ì¹œì ˆí•œ Python ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.")

messages = [
    system_msg,
    HumanMessage("FastAPIë¡œ REST APIë¥¼ ë§Œë“œëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”")
]

response = model.invoke(messages)
print(response.content)
```

#### ìƒì„¸í•œ í˜ë¥´ì†Œë‚˜ ì •ì˜

```python
system_msg = SystemMessage("""
ë‹¹ì‹ ì€ 10ë…„ ê²½ë ¥ì˜ ì‹œë‹ˆì–´ Python ê°œë°œìì…ë‹ˆë‹¤.

**ì—­í• **:
- ì›¹ í”„ë ˆì„ì›Œí¬(Django, FastAPI) ì „ë¬¸ê°€
- í•­ìƒ ì½”ë“œ ì˜ˆì œì™€ í•¨ê»˜ ì„¤ëª…ì„ ì œê³µí•©ë‹ˆë‹¤
- ê°„ê²°í•˜ì§€ë§Œ ì¶©ë¶„íˆ ìì„¸í•œ ì„¤ëª…ì„ ì œê³µí•©ë‹ˆë‹¤

**ì‘ë‹µ ìŠ¤íƒ€ì¼**:
- í•µì‹¬ ê°œë…ì„ ë¨¼ì € ì„¤ëª…
- ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ ì˜ˆì œ ì œê³µ
- ì£¼ì˜ì‚¬í•­ê³¼ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ í¬í•¨
""")

messages = [
    system_msg,
    HumanMessage("FastAPIì—ì„œ ì˜ì¡´ì„± ì£¼ì…ì„ êµ¬í˜„í•˜ëŠ” ë°©ë²•ì€?")
]

response = model.invoke(messages)
```

**ğŸ’¡ ì‹¤ìŠµ í¬ì¸íŠ¸**:
1. ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ë³€ê²½í•˜ë©´ì„œ ì‘ë‹µì´ ì–´ë–»ê²Œ ë‹¬ë¼ì§€ëŠ”ì§€ ê´€ì°°í•˜ì„¸ìš”
2. ë„ˆë¬´ ê¸´ ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” í† í°ì„ ë‚­ë¹„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
3. ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ ì§€ì‹œê°€ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ë§Œë“­ë‹ˆë‹¤

> ğŸ“– **ê³µì‹ ë¬¸ì„œ**: [08-messages.md](../official/08-messages_ko.md#system-ë©”ì‹œì§€)

### 2.3 HumanMessage - ì‚¬ìš©ì ì…ë ¥

`HumanMessage`ëŠ” ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. í…ìŠ¤íŠ¸ë¿ë§Œ ì•„ë‹ˆë¼ ì´ë¯¸ì§€, ì˜¤ë””ì˜¤, íŒŒì¼ ë“± ë‹¤ì–‘í•œ í˜•íƒœì˜ ì½˜í…ì¸ ë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### í…ìŠ¤íŠ¸ ë©”ì‹œì§€

```python
from langchain.messages import HumanMessage

# Message ê°ì²´ ì‚¬ìš©
human_msg = HumanMessage("ë¨¸ì‹ ëŸ¬ë‹ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?")
response = model.invoke([human_msg])

# ë¬¸ìì—´ ì¶•ì•½í˜• (ë‹¨ì¼ ë©”ì‹œì§€ì¸ ê²½ìš°)
response = model.invoke("ë¨¸ì‹ ëŸ¬ë‹ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?")
```

#### ë©”íƒ€ë°ì´í„° ì¶”ê°€

```python
human_msg = HumanMessage(
    content="ì•ˆë…•í•˜ì„¸ìš”!",
    name="alice",  # ì‚¬ìš©ì ì‹ë³„ (ì„ íƒ)
    id="msg_123",  # ê³ ìœ  ID (ì„ íƒ, ì¶”ì ìš©)
)
```

> âš ï¸ **ì£¼ì˜**: `name` í•„ë“œì˜ ë™ì‘ì€ í”„ë¡œë°”ì´ë”ë§ˆë‹¤ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¼ë¶€ëŠ” ì‚¬ìš©ì ì‹ë³„ì— ì‚¬ìš©í•˜ê³ , ì¼ë¶€ëŠ” ë¬´ì‹œí•©ë‹ˆë‹¤.

#### ë©€í‹°ëª¨ë‹¬ ì…ë ¥

```python
# ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ í•¨ê»˜ ì „ì†¡
human_msg = HumanMessage(content=[
    {"type": "text", "text": "ì´ ì´ë¯¸ì§€ì— ë¬´ì—‡ì´ ìˆë‚˜ìš”?"},
    {"type": "image", "url": "https://example.com/image.jpg"}
])

response = model.invoke([human_msg])
```

> ğŸ“– **ê³µì‹ ë¬¸ì„œ**: [08-messages.md](../official/08-messages_ko.md#human-ë©”ì‹œì§€)

### 2.4 AIMessage - AI ì‘ë‹µ

`AIMessage`ëŠ” ëª¨ë¸ì´ ìƒì„±í•œ ì‘ë‹µì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. `invoke()` ë©”ì„œë“œëŠ” í•­ìƒ `AIMessage` ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

#### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
# ëª¨ë¸ í˜¸ì¶œ
response = model.invoke("AIì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”")

# AIMessage ê°ì²´ í™•ì¸
print(type(response))  # <class 'langchain.messages.AIMessage'>
print(response.content)  # ì‘ë‹µ í…ìŠ¤íŠ¸
```

#### AIMessageì˜ ì£¼ìš” ì†ì„±

```python
from langchain.messages import HumanMessage

response = model.invoke([HumanMessage("ì•ˆë…•í•˜ì„¸ìš”!")])

# í…ìŠ¤íŠ¸ ë‚´ìš©
print(response.text)
print(response.content)  # ë™ì¼

# ê³ ìœ  ID
print(response.id)  # "msg_abc123"

# í† í° ì‚¬ìš©ëŸ‰
print(response.usage_metadata)
# {
#     'input_tokens': 8,
#     'output_tokens': 304,
#     'total_tokens': 312,
#     'input_token_details': {'audio': 0, 'cache_read': 0},
#     'output_token_details': {'audio': 0, 'reasoning': 256}
# }

# ì‘ë‹µ ë©”íƒ€ë°ì´í„°
print(response.response_metadata)
# ëª¨ë¸ ì´ë¦„, ì™„ë£Œ ì´ìœ  ë“±
```

#### ìˆ˜ë™ìœ¼ë¡œ AIMessage ìƒì„±

ëŒ€í™” ê¸°ë¡ì„ ì¬êµ¬ì„±í•˜ê±°ë‚˜ í…ŒìŠ¤íŠ¸í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤:

```python
from langchain.messages import AIMessage, SystemMessage, HumanMessage

# ëŒ€í™” ê¸°ë¡ ì¬êµ¬ì„±
messages = [
    SystemMessage("ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤"),
    HumanMessage("ë„ì™€ì¤„ ìˆ˜ ìˆë‚˜ìš”?"),
    AIMessage("ë¬¼ë¡ ì…ë‹ˆë‹¤! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"),  # ìˆ˜ë™ ìƒì„±
    HumanMessage("2+2ëŠ”?")
]

response = model.invoke(messages)
print(response.content)  # "2+2ëŠ” 4ì…ë‹ˆë‹¤."
```

> ğŸ“– **ê³µì‹ ë¬¸ì„œ**: [08-messages.md](../official/08-messages_ko.md#ai-ë©”ì‹œì§€)

### 2.5 ToolMessage - ë„êµ¬ ì‹¤í–‰ ê²°ê³¼

`ToolMessage`ëŠ” Tool Callingì—ì„œ ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ëª¨ë¸ì— ì „ë‹¬í•  ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤. (Tool Callingì€ ì„¹ì…˜ 6ì—ì„œ ìì„¸íˆ ë‹¤ë£¹ë‹ˆë‹¤)

#### ê¸°ë³¸ êµ¬ì¡°

```python
from langchain.messages import AIMessage, ToolMessage

# 1. ëª¨ë¸ì´ ë„êµ¬ í˜¸ì¶œì„ ìš”ì²­ (AIMessage)
ai_message = AIMessage(
    content="",
    tool_calls=[{
        "name": "get_weather",
        "args": {"location": "San Francisco"},
        "id": "call_123"
    }]
)

# 2. ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ (ToolMessage)
tool_message = ToolMessage(
    content="Sunny, 72Â°F",
    tool_call_id="call_123",  # ë°˜ë“œì‹œ ì¼ì¹˜í•´ì•¼ í•¨
    name="get_weather"
)

# 3. ëª¨ë¸ì— ê²°ê³¼ ì „ë‹¬
messages = [
    HumanMessage("ìƒŒí”„ë€ì‹œìŠ¤ì½” ë‚ ì”¨ëŠ”?"),
    ai_message,
    tool_message
]

response = model.invoke(messages)
print(response.content)
# "ìƒŒí”„ë€ì‹œìŠ¤ì½”ëŠ” í˜„ì¬ í™”ì°½í•˜ê³  72ë„ì…ë‹ˆë‹¤."
```

**ToolMessageì˜ í•„ìˆ˜ ì†ì„±**:
- `content`: ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ (ë¬¸ìì—´)
- `tool_call_id`: AIMessageì˜ tool_call IDì™€ ì¼ì¹˜í•´ì•¼ í•¨
- `name`: í˜¸ì¶œëœ ë„êµ¬ ì´ë¦„

> ğŸ“– **ê³µì‹ ë¬¸ì„œ**: [08-messages.md](../official/08-messages_ko.md#tool-ë©”ì‹œì§€)

### 2.6 Dictionary í¬ë§· ì‚¬ìš©í•˜ê¸°

LangChainì€ OpenAIì˜ ì±„íŒ… ì™„ë£Œ í˜•ì‹(dictionary)ë„ ì§€ì›í•©ë‹ˆë‹¤. ê°„ë‹¨í•œ ê²½ìš°ì—ëŠ” ì´ í˜•ì‹ì´ ë” í¸ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### Dictionary í˜•ì‹

```python
# Dictionary í˜•ì‹ì˜ ë©”ì‹œì§€
messages = [
    {"role": "system", "content": "ë‹¹ì‹ ì€ ë²ˆì—­ ì „ë¬¸ê°€ì…ë‹ˆë‹¤"},
    {"role": "user", "content": "I love programmingì„ í”„ë‘ìŠ¤ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”"},
    {"role": "assistant", "content": "J'adore la programmation."},
    {"role": "user", "content": "I love building applicationsë„ ë²ˆì—­í•˜ì„¸ìš”"}
]

response = model.invoke(messages)
print(response.content)
# "J'adore crÃ©er des applications."
```

#### Message ê°ì²´ vs Dictionary

```python
# Message ê°ì²´ (ê¶Œì¥)
from langchain.messages import SystemMessage, HumanMessage

messages = [
    SystemMessage("ë‹¹ì‹ ì€ ë²ˆì—­ ì „ë¬¸ê°€ì…ë‹ˆë‹¤"),
    HumanMessage("Helloë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”")
]

# Dictionary í˜•ì‹ (ê°„ë‹¨í•œ ê²½ìš°)
messages = [
    {"role": "system", "content": "ë‹¹ì‹ ì€ ë²ˆì—­ ì „ë¬¸ê°€ì…ë‹ˆë‹¤"},
    {"role": "user", "content": "Helloë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”"}
]
```

**ì–¸ì œ ì–´ë–¤ í˜•ì‹ì„ ì‚¬ìš©í• ê¹Œ?**
- **Message ê°ì²´**: íƒ€ì… ì•ˆì •ì„±, IDE ìë™ì™„ì„±, ë©€í‹°ëª¨ë‹¬, ë©”íƒ€ë°ì´í„° í•„ìš” ì‹œ
- **Dictionary**: ê°„ë‹¨í•œ í”„ë¡œí† íƒ€ì…, ì™¸ë¶€ API ì—°ë™, JSON ì§ë ¬í™” í•„ìš” ì‹œ

> ğŸ“– **ê³µì‹ ë¬¸ì„œ**: [08-messages.md](../official/08-messages_ko.md#ë”•ì…”ë„ˆë¦¬-í˜•ì‹)

### 2.7 Multimodal Content Handling

**Multimodal**ì€ í…ìŠ¤íŠ¸ ì™¸ì— ì´ë¯¸ì§€, ì˜¤ë””ì˜¤, ë¹„ë””ì˜¤, íŒŒì¼ ë“± ë‹¤ì–‘í•œ í˜•íƒœì˜ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ëŠ¥ë ¥ì…ë‹ˆë‹¤.

#### Multimodal ì§€ì› ëª¨ë¸

ë¨¼ì € ëª¨ë¸ì´ multimodalì„ ì§€ì›í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:

```python
from langchain.chat_models import init_chat_model

model = init_chat_model("gpt-4o")

# Multimodal ì§€ì› ì—¬ë¶€ í™•ì¸
if model.profile.get("image_inputs"):
    print("âœ… ì´ë¯¸ì§€ ì…ë ¥ ì§€ì›")
if model.profile.get("audio_inputs"):
    print("âœ… ì˜¤ë””ì˜¤ ì…ë ¥ ì§€ì›")
if model.profile.get("video_inputs"):
    print("âœ… ë¹„ë””ì˜¤ ì…ë ¥ ì§€ì›")
```

**ì£¼ìš” multimodal ëª¨ë¸**:
- GPT-4o, GPT-4o-mini (OpenAI) - ì´ë¯¸ì§€, ì˜¤ë””ì˜¤
- Claude 4.5 Sonnet (Anthropic) - ì´ë¯¸ì§€, PDF
- Gemini 2.5 Pro/Flash (Google) - ì´ë¯¸ì§€, ì˜¤ë””ì˜¤, ë¹„ë””ì˜¤

#### 1. ì´ë¯¸ì§€ ì…ë ¥ (Image Input)

ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ì— ì „ë‹¬í•˜ëŠ” 3ê°€ì§€ ë°©ë²•:

**ë°©ë²• 1: URL**

```python
message = {
    "role": "user",
    "content": [
        {"type": "text", "text": "ì´ ì´ë¯¸ì§€ì— ë¬´ì—‡ì´ ìˆë‚˜ìš”?"},
        {"type": "image", "url": "https://example.com/cat.jpg"}
    ]
}

response = model.invoke([message])
```

**ë°©ë²• 2: Base64 ì¸ì½”ë”©**

```python
import base64

# ì´ë¯¸ì§€ íŒŒì¼ì„ base64ë¡œ ì¸ì½”ë”©
with open("local_image.jpg", "rb") as image_file:
    base64_image = base64.b64encode(image_file.read()).decode("utf-8")

message = {
    "role": "user",
    "content": [
        {"type": "text", "text": "ì´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”."},
        {
            "type": "image",
            "base64": base64_image,
            "mime_type": "image/jpeg"
        }
    ]
}

response = model.invoke([message])
```

**ë°©ë²• 3: File ID (Provider-managed)**

ì¼ë¶€ providerëŠ” íŒŒì¼ì„ ë¯¸ë¦¬ ì—…ë¡œë“œí•˜ê³  IDë¡œ ì°¸ì¡°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
# ì˜ˆ: OpenAI File API
# 1. íŒŒì¼ ì—…ë¡œë“œ
# uploaded_file = openai.files.create(...)
# file_id = uploaded_file.id

message = {
    "role": "user",
    "content": [
        {"type": "text", "text": "ì´ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”."},
        {"type": "image", "file_id": "file-abc123"}
    ]
}

response = model.invoke([message])
```

#### ì£¼ì˜ì‚¬í•­

- **íŒŒì¼ í¬ê¸°**: ì´ë¯¸ì§€ëŠ” ì¼ë°˜ì ìœ¼ë¡œ 10MB ì´í•˜ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤. í° ì´ë¯¸ì§€ëŠ” ë¦¬ì‚¬ì´ì¦ˆ í›„ ì „ì†¡í•˜ì„¸ìš”.
- **ì§€ì› í¬ë§·**: PNG, JPEG, GIF, WebPê°€ ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ì—ì„œ ì§€ì›ë©ë‹ˆë‹¤.
- **Base64 vs URL**: ë¡œì»¬ íŒŒì¼ì€ Base64, ì´ë¯¸ í˜¸ìŠ¤íŒ…ëœ íŒŒì¼ì€ URLì´ íš¨ìœ¨ì ì…ë‹ˆë‹¤.
- **ë¹„ìš©**: ì´ë¯¸ì§€ ì…ë ¥ì€ í…ìŠ¤íŠ¸ë³´ë‹¤ í† í° ì†Œë¹„ê°€ í½ë‹ˆë‹¤. í•´ìƒë„ë¥¼ ë‚®ì¶”ë©´ ë¹„ìš©ì„ ì ˆê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> ğŸ’¡ **í•µì‹¬ í¬ì¸íŠ¸**:
> - ì—¬ê¸°ì„œëŠ” ì´ë¯¸ì§€ ì…ë ¥(URL, Base64)ë§Œ ë‹¤ë£¹ë‹ˆë‹¤
> - PDF, ì˜¤ë””ì˜¤, ë¹„ë””ì˜¤ ë“± ì¶”ê°€ ë©€í‹°ëª¨ë‹¬ ì…ë ¥ì€ [ê³µì‹ ë¬¸ì„œ](../official/08-messages_ko.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”

---

## 3. Tools ê¸°ì´ˆ

### 3.1 Tools ê°œìš”

**Tools**ëŠ” Agentê°€ ì™¸ë¶€ ì„¸ê³„ì™€ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. LLMì€ í…ìŠ¤íŠ¸ ìƒì„±ì— ë›°ì–´ë‚˜ì§€ë§Œ, ì‹¤ì œ ë°ì´í„° ì¡°íšŒë‚˜ ì‘ì—… ìˆ˜í–‰ì€ Toolsë¥¼ í†µí•´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.

```mermaid
sequenceDiagram
    participant U as User
    participant A as Agent
    participant M as Model
    participant T as Tools

    U->>A: "ì„œìš¸ ë‚ ì”¨ëŠ”?"
    A->>M: Messages + Available Tools
    M->>A: Tool Call: get_weather("ì„œìš¸")
    A->>T: Execute get_weather("ì„œìš¸")
    T->>A: "ì„œìš¸: ë§‘ìŒ, 15Â°C"
    A->>M: Tool Result
    M->>A: "ì„œìš¸ì€ í˜„ì¬ ë§‘ê³  15ë„ì…ë‹ˆë‹¤"
    A->>U: Final Answer
```

**Toolsì˜ êµ¬ì„± ìš”ì†Œ**:
1. **ìŠ¤í‚¤ë§ˆ (Schema)**: ë„êµ¬ ì´ë¦„, ì„¤ëª…, íŒŒë¼ë¯¸í„° ì •ì˜
2. **í•¨ìˆ˜ (Function)**: ì‹¤ì œ ì‹¤í–‰í•  Python í•¨ìˆ˜ ë˜ëŠ” ì½”ë£¨í‹´

> ğŸ“– **ê³µì‹ ë¬¸ì„œ**: [09-tools.md](../official/09-tools_ko.md#tool-ìƒì„±)

### 3.2 @tool ë°ì½”ë ˆì´í„°ë¡œ ë„êµ¬ ë§Œë“¤ê¸°

`@tool` ë°ì½”ë ˆì´í„°ëŠ” ì¼ë°˜ Python í•¨ìˆ˜ë¥¼ LangChain Toolë¡œ ë³€í™˜í•˜ëŠ” ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ì…ë‹ˆë‹¤.

#### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from langchain.tools import tool

@tool
def search_database(query: str, limit: int = 10) -> str:
    """ê³ ê° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¿¼ë¦¬ì™€ ì¼ì¹˜í•˜ëŠ” ë ˆì½”ë“œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    Args:
        query: ê²€ìƒ‰í•  ìš©ì–´
        limit: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
    """
    # ì‹¤ì œ êµ¬í˜„
    return f"'{query}'ì— ëŒ€í•œ {limit}ê°œì˜ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤"

# Tool ì†ì„± í™•ì¸
print(search_database.name)  # "search_database"
print(search_database.description)  # ë„êµ¬ ì„¤ëª… (docstring)
print(search_database.args)  # íŒŒë¼ë¯¸í„° ìŠ¤í‚¤ë§ˆ
```

**ğŸ’¡ í•µì‹¬ ìš”êµ¬ì‚¬í•­**:
1. **Type hints í•„ìˆ˜**: ëª¨ë“  íŒŒë¼ë¯¸í„°ì™€ ë°˜í™˜ íƒ€ì…ì— íƒ€ì… íŒíŠ¸ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤
2. **Docstring ê¶Œì¥**: ëª¨ë¸ì´ ë„êµ¬ë¥¼ ì–¸ì œ ì‚¬ìš©í• ì§€ ì´í•´í•˜ëŠ”ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤
3. **ë°˜í™˜ íƒ€ì…**: ì¼ë°˜ì ìœ¼ë¡œ `str`ì„ ë°˜í™˜í•˜ì§€ë§Œ, ë‹¤ë¥¸ íƒ€ì…ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤

> ğŸ’» **ì˜ˆì œ ì½”ë“œ**: [03_tools_basic.py](../src/part02_fundamentals/03_tools_basic.py) ë¼ì¸ 32-51

#### ì‹¤ìš©ì ì¸ ì˜ˆì œ

```python
@tool
def get_current_time(timezone: str = "UTC") -> str:
    """í˜„ì¬ ì‹œê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        timezone: ì‹œê°„ëŒ€ (ì˜ˆ: "UTC", "Asia/Seoul", "America/New_York")
    """
    from datetime import datetime
    import pytz

    tz = pytz.timezone(timezone)
    current_time = datetime.now(tz)
    return current_time.strftime("%Y-%m-%d %H:%M:%S %Z")

# ë„êµ¬ ì§ì ‘ í˜¸ì¶œ (í…ŒìŠ¤íŠ¸)
result = get_current_time.invoke({"timezone": "Asia/Seoul"})
print(result)  # "2025-02-05 10:30:45 KST"
```

### 3.3 Tool ì„¤ëª…(Docstring)ì˜ ì¤‘ìš”ì„±

Docstringì€ ëª¨ë¸ì´ **ì–¸ì œ** ì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ì§€ íŒë‹¨í•˜ëŠ” í•µì‹¬ ì •ë³´ì…ë‹ˆë‹¤. ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ ì„¤ëª…ì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤.

#### ì¢‹ì€ ì˜ˆ vs ë‚˜ìœ ì˜ˆ

```python
# âŒ ë‚˜ìœ ì˜ˆ: ì„¤ëª…ì´ ë¶€ì¡±í•¨
@tool
def get_data(id: str) -> str:
    """ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    return f"Data for {id}"

# âœ… ì¢‹ì€ ì˜ˆ: ëª…í™•í•˜ê³  êµ¬ì²´ì 
@tool
def get_customer_data(customer_id: str) -> str:
    """ê³ ê° IDë¡œ ê³ ê° ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

    ì´ ë„êµ¬ëŠ” ë‹¤ìŒ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤:
    - ê³ ê° ì´ë¦„, ì´ë©”ì¼, ì „í™”ë²ˆí˜¸
    - ê°€ì…ì¼, ìµœê·¼ êµ¬ë§¤ ì´ë ¥

    Args:
        customer_id: ì¡°íšŒí•  ê³ ê°ì˜ ê³ ìœ  ID (ì˜ˆ: "CUST-12345")

    Returns:
        ê³ ê° ì •ë³´ë¥¼ JSON í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ë°˜í™˜
    """
    return f"Customer data for {customer_id}"
```

**íš¨ê³¼ì ì¸ Docstring ì‘ì„± íŒ**:
1. **ëª©ì  ëª…í™•íˆ**: ë„êµ¬ê°€ ë¬´ì—‡ì„ í•˜ëŠ”ì§€ ì²« ë¬¸ì¥ì— ëª…í™•íˆ ì„¤ëª…
2. **ì‚¬ìš© ì‹œê¸°**: ì–´ë–¤ ìƒí™©ì—ì„œ ì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ì§€ ëª…ì‹œ
3. **íŒŒë¼ë¯¸í„° ì„¤ëª…**: ê° íŒŒë¼ë¯¸í„°ì˜ ì˜ë¯¸ì™€ ì˜ˆì‹œ ì œê³µ
4. **ë°˜í™˜ê°’ ì„¤ëª…**: ì–´ë–¤ í˜•ì‹ìœ¼ë¡œ ë¬´ì—‡ì„ ë°˜í™˜í•˜ëŠ”ì§€ ëª…ì‹œ

> ğŸ“– **ê³µì‹ ë¬¸ì„œ**: [09-tools.md](../official/09-tools_ko.md#ê¸°ë³¸-tool-ì •ì˜)

### 3.4 Type Hintsì˜ ì—­í• 

Type hintsëŠ” ë‹¨ìˆœí•œ ì£¼ì„ì´ ì•„ë‹™ë‹ˆë‹¤. LangChainì´ ë„êµ¬ì˜ ì…ë ¥ ìŠ¤í‚¤ë§ˆë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•˜ëŠ”ë° ì‚¬ìš©ë©ë‹ˆë‹¤.

#### ê¸°ë³¸ íƒ€ì…

```python
from typing import Optional, List

@tool
def process_order(
    order_id: str,          # í•„ìˆ˜ íŒŒë¼ë¯¸í„°
    quantity: int,          # ì •ìˆ˜
    price: float,           # ì‹¤ìˆ˜
    urgent: bool = False,   # ë¶ˆë¦° (ê¸°ë³¸ê°’)
    notes: Optional[str] = None  # ì„ íƒì  íŒŒë¼ë¯¸í„°
) -> str:
    """ì£¼ë¬¸ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    return f"Order {order_id} processed"
```

#### ë³µì¡í•œ íƒ€ì…

```python
from typing import List, Dict, Literal

@tool
def search_products(
    categories: List[str],                    # ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸
    price_range: Dict[str, float],           # ë”•ì…”ë„ˆë¦¬
    sort_by: Literal["price", "rating", "name"] = "rating"  # ì œí•œëœ ì„ íƒì§€
) -> str:
    """ìƒí’ˆì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    Args:
        categories: ê²€ìƒ‰í•  ì¹´í…Œê³ ë¦¬ ëª©ë¡ (ì˜ˆ: ["electronics", "books"])
        price_range: ê°€ê²© ë²”ìœ„ (ì˜ˆ: {"min": 10.0, "max": 100.0})
        sort_by: ì •ë ¬ ê¸°ì¤€ ("price", "rating", "name" ì¤‘ í•˜ë‚˜)
    """
    return f"Found products in {categories}"
```

**ì§€ì›ë˜ëŠ” íƒ€ì…**:
- ê¸°ë³¸: `str`, `int`, `float`, `bool`
- ì»¨í…Œì´ë„ˆ: `List[T]`, `Dict[K, V]`, `Tuple[T, ...]`
- ì„ íƒì : `Optional[T]`, `Union[T1, T2]`
- ì œí•œ: `Literal["a", "b", "c"]`

> ğŸ’» **ì˜ˆì œ ì½”ë“œ**: [03_tools_basic.py](../src/part02_fundamentals/03_tools_basic.py) ë¼ì¸ 58-84

---

## 4. ToolRuntime - ê³ ê¸‰ Tool ê¸°ëŠ¥

### 4.1 ToolRuntimeì´ë€?

**ToolRuntime**ì€ Tool ì‹¤í–‰ ì‹œ Agentì˜ ìƒíƒœ, ì»¨í…ìŠ¤íŠ¸, ë©”ëª¨ë¦¬ì— ì ‘ê·¼í•˜ëŠ” ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤.

ì¼ë°˜ì ì¸ Toolì€ ë…ë¦½ì ìœ¼ë¡œ ë™ì‘í•˜ì§€ë§Œ, ë•Œë¡œëŠ” **Agentì˜ í˜„ì¬ ìƒíƒœë‚˜ ì‚¬ìš©ì ì •ë³´**ì— ì ‘ê·¼í•´ì•¼ í•˜ëŠ” ê²½ìš°ê°€ ìˆìŠµë‹ˆë‹¤. ToolRuntimeì´ ì´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

**ê¸°ë³¸ ì‚¬ìš©ë²•**:

```python
from langchain.tools import tool, ToolRuntime

@tool
def get_user_preference(
    category: str,
    runtime: ToolRuntime
) -> str:
    """ì‚¬ìš©ì ì„¤ì •ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    # Runtimeì„ í†µí•´ ë‹¤ì–‘í•œ ì •ë³´ ì ‘ê·¼
    user_id = runtime.context["user_id"]
    messages = runtime.state["messages"]

    return f"User {user_id}ì˜ {category} ì„¤ì •: ..."
```

### 4.2 Runtime ì†ì„± ìš”ì•½

ToolRuntimeì€ 5ê°€ì§€ ì£¼ìš” ì†ì„±ì„ ì œê³µí•©ë‹ˆë‹¤:

| ì†ì„± | ìš©ë„ | ì„¤ëª… |
|------|------|------|
| `runtime.state` | Agent ìƒíƒœ ì ‘ê·¼ | ë©”ì‹œì§€ ê¸°ë¡ ë“± í˜„ì¬ ìƒíƒœ ì¡°íšŒ |
| `runtime.context` | ìš”ì²­ ì»¨í…ìŠ¤íŠ¸ | ì‚¬ìš©ì ID, ì–¸ì–´ ë“± ìš”ì²­ë³„ ì •ë³´ |
| `runtime.store` | ì¥ê¸° ë©”ëª¨ë¦¬ | ì‚¬ìš©ì ì„ í˜¸ë„ ë“± ì˜ì† ë°ì´í„° ì ‘ê·¼ |
| `runtime.stream_writer` | ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ | ì§„í–‰ë¥  ë“± ì¤‘ê°„ ê²°ê³¼ ìŠ¤íŠ¸ë¦¬ë° |
| `runtime.tool_call_id` | Tool Call ID | í˜„ì¬ í˜¸ì¶œì˜ ê³ ìœ  ì‹ë³„ì |

> ğŸ’¡ ToolRuntimeì˜ ìƒì„¸ í™œìš©ë²•ì€ Agent/MCPë¥¼ ë‹¤ë£¨ëŠ” í›„ì† íŒŒíŠ¸ì—ì„œ ì‹¤ìŠµí•©ë‹ˆë‹¤.

---

## 5. Tools ê³ ê¸‰ â€” Pydantic ìŠ¤í‚¤ë§ˆ

> ğŸ’» **ì˜ˆì œ ì½”ë“œ**: [04_tool_advanced.py](../src/part02_fundamentals/04_tool_advanced.py)

### 5.1 Pydantic ìŠ¤í‚¤ë§ˆë¡œ ë³µì¡í•œ ì…ë ¥ ì •ì˜

ë³µì¡í•œ ì…ë ¥ êµ¬ì¡°ê°€ í•„ìš”í•œ ê²½ìš° Pydantic ëª¨ë¸ì„ ì‚¬ìš©í•˜ë©´ ë” ëª…í™•í•˜ê³  ì•ˆì „í•©ë‹ˆë‹¤.

#### ê¸°ë³¸ Pydantic ìŠ¤í‚¤ë§ˆ

```python
from pydantic import BaseModel, Field
from langchain.tools import tool

class WeatherInput(BaseModel):
    """ë‚ ì”¨ ì¡°íšŒë¥¼ ìœ„í•œ ì…ë ¥ ìŠ¤í‚¤ë§ˆ"""
    location: str = Field(description="ë„ì‹œ ì´ë¦„ ë˜ëŠ” ì¢Œí‘œ")
    units: str = Field(
        default="celsius",
        description="ì˜¨ë„ ë‹¨ìœ„ ('celsius' ë˜ëŠ” 'fahrenheit')"
    )
    include_forecast: bool = Field(
        default=False,
        description="5ì¼ ì˜ˆë³´ í¬í•¨ ì—¬ë¶€"
    )

@tool(args_schema=WeatherInput)
def get_weather(location: str, units: str = "celsius", include_forecast: bool = False) -> str:
    """í˜„ì¬ ë‚ ì”¨ì™€ ì„ íƒì ìœ¼ë¡œ ì˜ˆë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    temp = 22 if units == "celsius" else 72
    result = f"í˜„ì¬ {location}ì˜ ë‚ ì”¨: {temp}ë„ {units}"
    if include_forecast:
        result += "\ní–¥í›„ 5ì¼: ë§‘ìŒ"
    return result
```

> ğŸ’» **ì˜ˆì œ ì½”ë“œ**: [04_tool_advanced.py](../src/part02_fundamentals/04_tool_advanced.py) ë¼ì¸ 44-61

ê° í•„ë“œì— `Field(description=...)`ë¥¼ ì‚¬ìš©í•˜ë©´ LLMì´ ê° íŒŒë¼ë¯¸í„°ì˜ ìš©ë„ë¥¼ ë” ì •í™•íˆ ì´í•´í•©ë‹ˆë‹¤. ìœ„ `WeatherInput` ì˜ˆì œì²˜ëŸ¼ `description`, `default`, `ge`/`le` ë“±ì˜ ì˜µì…˜ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> ğŸ’¡ ë…ìŠ¤íŠ¸ë§ê³¼ íƒ€ì…íŒíŠ¸ë§Œìœ¼ë¡œë„ ëŒ€ë¶€ë¶„ì˜ Toolì€ ì˜ ë™ì‘í•©ë‹ˆë‹¤. Pydantic ìŠ¤í‚¤ë§ˆëŠ” ë³µì¡í•œ ì…ë ¥ ê²€ì¦ì´ í•„ìš”í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.

---

## 6. Tool Calling ì´í•´í•˜ê¸°

> ğŸ’» **ì˜ˆì œ ì½”ë“œ**: [04_tool_advanced.py](../src/part02_fundamentals/04_tool_advanced.py)

### 6.1 Tool Callingì´ë€?

**Tool Calling**ì€ LLMì´ ëŒ€í™” ì¤‘ í•„ìš”í•œ ì •ë³´ë¥¼ ì–»ê¸° ìœ„í•´ ì™¸ë¶€ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤. ëª¨ë¸ì€ ë„êµ¬ì˜ ìŠ¤í‚¤ë§ˆë¥¼ ë³´ê³  ì–¸ì œ, ì–´ë–¤ ë„êµ¬ë¥¼, ì–´ë–¤ ì¸ìë¡œ í˜¸ì¶œí• ì§€ ììœ¨ì ìœ¼ë¡œ ê²°ì •í•©ë‹ˆë‹¤.

```mermaid
sequenceDiagram
    participant User as ì‚¬ìš©ì
    participant Agent as Agent
    participant Model as LLM
    participant Tools as Tools

    User->>Agent: "ì„œìš¸ê³¼ ë¶€ì‚°ì˜ ë‚ ì”¨ëŠ”?"
    Agent->>Model: Messages + Tool Schemas

    Note over Model: ë‚ ì”¨ ì •ë³´ê°€ í•„ìš”í•¨<br/>get_weather ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì•¼ê² ë‹¤

    Model->>Agent: Tool Calls:<br/>1. get_weather("ì„œìš¸")<br/>2. get_weather("ë¶€ì‚°")

    par ë³‘ë ¬ ì‹¤í–‰
        Agent->>Tools: get_weather("ì„œìš¸")
        Agent->>Tools: get_weather("ë¶€ì‚°")
    end

    par ê²°ê³¼ ìˆ˜ì‹ 
        Tools-->>Agent: "ì„œìš¸: ë§‘ìŒ, 15Â°C"
        Tools-->>Agent: "ë¶€ì‚°: íë¦¼, 18Â°C"
    end

    Agent->>Model: Tool Results

    Note over Model: ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ<br/>ì‚¬ìš©ì ì¹œí™”ì ì¸ ë‹µë³€ ìƒì„±

    Model->>Agent: "ì„œìš¸ì€ ë§‘ê³  15ë„,<br/>ë¶€ì‚°ì€ íë¦¬ê³  18ë„ì…ë‹ˆë‹¤"
    Agent->>User: ìµœì¢… ë‹µë³€
```

> ğŸ“– **ê³µì‹ ë¬¸ì„œ**: [07-models.md](../official/07-models_ko.md#tool-í˜¸ì¶œ)

### 6.2 ëª¨ë¸ì´ ë„êµ¬ë¥¼ ì„ íƒí•˜ëŠ” ê³¼ì •

ëª¨ë¸ì€ ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ì™€ ë°©ë²•ì„ ê²°ì •í•©ë‹ˆë‹¤:

1. **ì‚¬ìš©ì ì§ˆë¬¸ ë¶„ì„**: "ì„œìš¸ ë‚ ì”¨ëŠ”?" â†’ ë‚ ì”¨ ì •ë³´ê°€ í•„ìš”
2. **ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ í™•ì¸**: `get_weather`, `search_database`, `calculate` ë“±
3. **ì ì ˆí•œ ë„êµ¬ ì„ íƒ**: `get_weather`ê°€ ê°€ì¥ ì í•©
4. **íŒŒë¼ë¯¸í„° ì¶”ì¶œ**: ì§ˆë¬¸ì—ì„œ "ì„œìš¸"ì„ location íŒŒë¼ë¯¸í„°ë¡œ ì¶”ì¶œ
5. **Tool Call ìƒì„±**: `{"name": "get_weather", "args": {"location": "ì„œìš¸"}}`

#### ì‹¤ì œ ì˜ˆì œ

```python
from langchain.tools import tool
from langchain.chat_models import init_chat_model

@tool
def get_weather(location: str) -> str:
    """íŠ¹ì • ì§€ì—­ì˜ ë‚ ì”¨ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

    Args:
        location: ë„ì‹œ ì´ë¦„ (ì˜ˆ: "ì„œìš¸", "ë¶€ì‚°")
    """
    # ì‹¤ì œë¡œëŠ” API í˜¸ì¶œ
    return f"{location}ì€ í•­ìƒ í™”ì°½í•©ë‹ˆë‹¤!"

# ëª¨ë¸ì— ë„êµ¬ ë°”ì¸ë”©
model = init_chat_model("gpt-4o-mini")
model_with_tools = model.bind_tools([get_weather])

# ë„êµ¬ í˜¸ì¶œì´ í•„ìš”í•œ ì§ˆë¬¸
response = model_with_tools.invoke("ë³´ìŠ¤í„´ ë‚ ì”¨ëŠ” ì–´ë•Œ?")

# Tool calls í™•ì¸
for tool_call in response.tool_calls:
    print(f"Tool: {tool_call['name']}")
    print(f"Args: {tool_call['args']}")
    print(f"ID: {tool_call['id']}")
```

**ì¶œë ¥**:
```
Tool: get_weather
Args: {'location': 'ë³´ìŠ¤í„´'}
ID: call_abc123
```

### 6.3 Tool Call íŒŒì‹±ê³¼ ì‹¤í–‰ ë£¨í”„

Tool callingì˜ ì „ì²´ íë¦„ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

```python
from langchain.tools import tool
from langchain.messages import HumanMessage, ToolMessage

@tool
def get_weather(location: str) -> str:
    """ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    return f"{location}: ë§‘ìŒ, 20Â°C"

# 1ë‹¨ê³„: ëª¨ë¸ì— ë„êµ¬ ë°”ì¸ë”©
model_with_tools = model.bind_tools([get_weather])

# 2ë‹¨ê³„: ì´ˆê¸° ë©”ì‹œì§€ë¡œ ëª¨ë¸ í˜¸ì¶œ
messages = [HumanMessage("ë³´ìŠ¤í„´ ë‚ ì”¨ëŠ”?")]
ai_msg = model_with_tools.invoke(messages)
messages.append(ai_msg)

print("Model response:", ai_msg.tool_calls)
# [{'name': 'get_weather', 'args': {'location': 'ë³´ìŠ¤í„´'}, 'id': 'call_123'}]

# 3ë‹¨ê³„: ë„êµ¬ ì‹¤í–‰
for tool_call in ai_msg.tool_calls:
    # ë„êµ¬ ì‹¤í–‰
    result = get_weather.invoke(tool_call)

    # ToolMessage ìƒì„±
    tool_message = ToolMessage(
        content=result,
        tool_call_id=tool_call['id'],
        name=tool_call['name']
    )
    messages.append(tool_message)

print("Tool result:", messages[-1].content)
# "ë³´ìŠ¤í„´: ë§‘ìŒ, 20Â°C"

# 4ë‹¨ê³„: ë„êµ¬ ê²°ê³¼ë¥¼ í¬í•¨í•˜ì—¬ ëª¨ë¸ ì¬í˜¸ì¶œ
final_response = model_with_tools.invoke(messages)
print("Final answer:", final_response.content)
# "ë³´ìŠ¤í„´ì˜ í˜„ì¬ ë‚ ì”¨ëŠ” ë§‘ê³  20ë„ì…ë‹ˆë‹¤."
```

**ì‹¤í–‰ íë¦„ ìš”ì•½**:
1. **ë„êµ¬ ë°”ì¸ë”©**: `bind_tools()`ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë¥¼ ëª¨ë¸ì— ì•Œë¦¼
2. **Tool Call ìƒì„±**: ëª¨ë¸ì´ í•„ìš”í•œ ë„êµ¬ì™€ ì¸ìë¥¼ ê²°ì •
3. **ë„êµ¬ ì‹¤í–‰**: Agentê°€ ì‹¤ì œ ë„êµ¬ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ íšë“
4. **ê²°ê³¼ ì „ë‹¬**: ToolMessageë¡œ ê²°ê³¼ë¥¼ ëª¨ë¸ì— ë‹¤ì‹œ ì „ë‹¬
5. **ìµœì¢… ë‹µë³€**: ëª¨ë¸ì´ ë„êµ¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì¹œí™”ì ì¸ ë‹µë³€ ìƒì„±

> âš ï¸ **ì¤‘ìš”**: LangGraphì˜ Agent (ì˜ˆ: `create_react_agent()`)ë¥¼ ì‚¬ìš©í•˜ë©´ ì´ ì „ì²´ ë£¨í”„ê°€ ìë™ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ êµ¬í˜„í•˜ëŠ” ê²ƒì€ ì´í•´ë¥¼ ë•ê¸° ìœ„í•œ ê²ƒì…ë‹ˆë‹¤.

#### ë³‘ë ¬ Tool Calls

ë§ì€ ëª¨ë¸ì´ ì—¬ëŸ¬ ë„êµ¬ë¥¼ ë™ì‹œì— í˜¸ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
# ì—¬ëŸ¬ ë„ì‹œì˜ ë‚ ì”¨ë¥¼ ë™ì‹œì— ì¡°íšŒ
response = model_with_tools.invoke("ì„œìš¸ê³¼ ë¶€ì‚°ì˜ ë‚ ì”¨ëŠ”?")

print(response.tool_calls)
# [
#   {'name': 'get_weather', 'args': {'location': 'ì„œìš¸'}, 'id': 'call_1'},
#   {'name': 'get_weather', 'args': {'location': 'ë¶€ì‚°'}, 'id': 'call_2'}
# ]

# ë³‘ë ¬ ì‹¤í–‰ (ë¹„ë™ê¸°ë¡œ ë” íš¨ìœ¨ì )
results = []
for tool_call in response.tool_calls:
    result = get_weather.invoke(tool_call)
    results.append(result)
```

> ğŸ“– **ê³µì‹ ë¬¸ì„œ**: [07-models.md](../official/07-models_ko.md#tool-í˜¸ì¶œ)

---

## ğŸ“ ì‹¤ìŠµ ê³¼ì œ

### ê³¼ì œ 1: ë‹¤ì¤‘ í”„ë¡œë°”ì´ë” Chat Model (â­â­â˜†)

**ëª©í‘œ**: ë™ì¼í•œ ì§ˆë¬¸ì„ ì—¬ëŸ¬ í”„ë¡œë°”ì´ë”ì˜ ëª¨ë¸ë¡œ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë¹„êµí•´ë³´ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­**:
1. OpenAI GPT-4o-miniì™€ Anthropic Claude ëª¨ë¸ ì´ˆê¸°í™”
2. "AI Agentê°€ ë¬´ì—‡ì´ë©° ì–´ë–»ê²Œ í™œìš©ë˜ëŠ”ì§€ 3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”" ì§ˆë¬¸ ì‹¤í–‰
3. ë‘ ëª¨ë¸ì˜ ì‘ë‹µì„ ì¶œë ¥í•˜ê³  ì°¨ì´ì  ë¶„ì„

**íŒíŠ¸**:
```python
from langchain.chat_models import init_chat_model

gpt_model = init_chat_model("gpt-4o-mini")
claude_model = init_chat_model("claude-sonnet-4-5-20250929")

question = "AI Agentê°€ ë¬´ì—‡ì´ë©° ì–´ë–»ê²Œ í™œìš©ë˜ëŠ”ì§€ 3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”"

# TODO: ê° ëª¨ë¸ë¡œ ì§ˆë¬¸ ì‹¤í–‰í•˜ê³  ê²°ê³¼ ë¹„êµ
```

**í‰ê°€ ê¸°ì¤€**:
- [ ] ë‘ ëª¨ë¸ì´ ëª¨ë‘ ì •ìƒì ìœ¼ë¡œ ì‘ë‹µí•˜ëŠ”ê°€?
- [ ] ì‘ë‹µ ìŠ¤íƒ€ì¼ì˜ ì°¨ì´ë¥¼ ê´€ì°°í–ˆëŠ”ê°€?
- [ ] Temperatureë¥¼ ë³€ê²½í•˜ë©´ ê²°ê³¼ê°€ ì–´ë–»ê²Œ ë‹¬ë¼ì§€ëŠ”ê°€?

**í•´ë‹µ**: [ì—¬ê¸°](../src/part02_fundamentals/solutions/exercise_01.py)

---

### ê³¼ì œ 2: ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ (â­â­â˜†)

**ëª©í‘œ**: SystemMessage, HumanMessage, AIMessageë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì¤‘ í„´ ëŒ€í™”ë¥¼ êµ¬í˜„í•˜ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­**:
1. ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ "ë‹¹ì‹ ì€ Python íŠœí„°ì…ë‹ˆë‹¤" ì„¤ì •
2. 3í„´ì˜ ëŒ€í™” êµ¬í˜„:
   - í„´1: "ë³€ìˆ˜ë€ ë¬´ì—‡ì¸ê°€ìš”?"
   - í„´2: "ì˜ˆì œë¥¼ ë³´ì—¬ì£¼ì„¸ìš”"
   - í„´3: "ê·¸ëŸ¼ ìƒìˆ˜ëŠ”ìš”?"
3. ê° í„´ë§ˆë‹¤ ëŒ€í™” ê¸°ë¡ì„ ëˆ„ì í•˜ì—¬ ì „ë‹¬

**íŒíŠ¸**:
```python
from langchain.messages import SystemMessage, HumanMessage, AIMessage

messages = [
    SystemMessage("ë‹¹ì‹ ì€ ì¹œì ˆí•œ Python íŠœí„°ì…ë‹ˆë‹¤")
]

# í„´ 1
messages.append(HumanMessage("ë³€ìˆ˜ë€ ë¬´ì—‡ì¸ê°€ìš”?"))
response = model.invoke(messages)
messages.append(response)

# TODO: í„´ 2, 3 êµ¬í˜„
```

**í‰ê°€ ê¸°ì¤€**:
- [ ] ëŒ€í™” ë§¥ë½ì´ ìœ ì§€ë˜ëŠ”ê°€?
- [ ] ëª¨ë¸ì´ ì´ì „ ëŒ€í™”ë¥¼ ì°¸ì¡°í•˜ëŠ”ê°€?
- [ ] SystemMessageê°€ ëª¨ë“  ì‘ë‹µì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ê°€?

**í•´ë‹µ**: [ì—¬ê¸°](../src/part02_fundamentals/solutions/exercise_02.py)

---

### ê³¼ì œ 3: ì‹¤ìš©ì ì¸ Tool ë§Œë“¤ê¸° (â­â­â­)

**ëª©í‘œ**: Pydantic ìŠ¤í‚¤ë§ˆë¥¼ ì‚¬ìš©í•˜ì—¬ ë³µì¡í•œ ì…ë ¥ì„ ë°›ëŠ” ë„êµ¬ë¥¼ ë§Œë“¤ì–´ë³´ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­**:
1. ì‹ë‹¹ ì˜ˆì•½ì„ ìœ„í•œ `ReservationInput` Pydantic ìŠ¤í‚¤ë§ˆ ì •ì˜:
   - `restaurant_name`: ì‹ë‹¹ ì´ë¦„
   - `date`: ì˜ˆì•½ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹)
   - `time`: ì˜ˆì•½ ì‹œê°„ (HH:MM í˜•ì‹)
   - `party_size`: ì¸ì› ìˆ˜ (1-20ëª…)
   - `special_requests`: íŠ¹ë³„ ìš”ì²­ì‚¬í•­ (ì„ íƒ)
2. `@tool` ë°ì½”ë ˆì´í„°ë¡œ `make_reservation` ë„êµ¬ êµ¬í˜„
3. ë„êµ¬ë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ í…ŒìŠ¤íŠ¸

**íŒíŠ¸**:
```python
from pydantic import BaseModel, Field
from langchain.tools import tool
from typing import Optional

class ReservationInput(BaseModel):
    """ì‹ë‹¹ ì˜ˆì•½ì„ ìœ„í•œ ì…ë ¥ ìŠ¤í‚¤ë§ˆ"""
    restaurant_name: str = Field(description="ì˜ˆì•½í•  ì‹ë‹¹ ì´ë¦„")
    # TODO: ë‚˜ë¨¸ì§€ í•„ë“œ ì •ì˜

@tool(args_schema=ReservationInput)
def make_reservation(restaurant_name: str, date: str, time: str,
                    party_size: int, special_requests: Optional[str] = None) -> str:
    """ì‹ë‹¹ ì˜ˆì•½ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    # TODO: êµ¬í˜„
    pass
```

**í‰ê°€ ê¸°ì¤€**:
- [ ] Pydantic ìŠ¤í‚¤ë§ˆê°€ ì˜¬ë°”ë¥´ê²Œ ì •ì˜ë˜ì—ˆëŠ”ê°€?
- [ ] Field descriptionsê°€ ëª…í™•í•œê°€?
- [ ] ë„êµ¬ê°€ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ”ê°€?
- [ ] ê²€ì¦ (party_size ë²”ìœ„ ë“±)ì´ ì‘ë™í•˜ëŠ”ê°€?

**í•´ë‹µ**: [ì—¬ê¸°](../src/part02_fundamentals/solutions/exercise_03.py)

---

## ğŸ’¡ ì‹¤ì „ íŒ

### Tip 1: í”„ë¡œë°”ì´ë” ì„ íƒ ê°€ì´ë“œ

**ìƒí™©ë³„ ì¶”ì²œ ëª¨ë¸**:

| ìš©ë„ | ì¶”ì²œ ëª¨ë¸ | ì´ìœ  |
|-----|---------|------|
| í”„ë¡œí† íƒ€ì…/ê°œë°œ | `gpt-4o-mini` | ì €ë ´í•˜ê³  ë¹ ë¦„ |
| í”„ë¡œë•ì…˜ (ê³ í’ˆì§ˆ) | `claude-sonnet-4-5` | ì •í™•í•˜ê³  ì•ˆì •ì  |
| í”„ë¡œë•ì…˜ (ì €ë¹„ìš©) | `gpt-4o-mini` | ë¹„ìš© íš¨ìœ¨ì  |
| ë³µì¡í•œ ì¶”ë¡  | `claude-opus-4-5` | ìµœê³  ì„±ëŠ¥ |
| ë¡œì»¬ í…ŒìŠ¤íŠ¸ | Ollama (llama3.1) | ë¬´ë£Œ, ì˜¤í”„ë¼ì¸ |

### Tip 2: Temperature ì„¤ì • ì „ëµ

```python
# ì •í™•ì„±ì´ ì¤‘ìš”í•œ ì‘ì—…: temperature=0
extraction_model = init_chat_model("gpt-4o-mini", temperature=0.0)
result = extraction_model.invoke("ë‹¤ìŒ JSONì—ì„œ ì´ë¦„ì„ ì¶”ì¶œí•˜ì„¸ìš”: {...}")

# ì¼ë°˜ ëŒ€í™”: temperature=0.7 (ê¸°ë³¸ê°’)
chat_model = init_chat_model("gpt-4o-mini", temperature=0.7)

# ì°½ì˜ì  ì‘ì—…: temperature=0.9~1.0
creative_model = init_chat_model("gpt-4o-mini", temperature=1.0)
story = creative_model.invoke("SF ë‹¨í¸ ì†Œì„¤ì„ ì¨ì£¼ì„¸ìš”")
```

### Tip 3: íš¨ê³¼ì ì¸ System Message ì‘ì„±

```python
# âœ… ì¢‹ì€ ì˜ˆ: êµ¬ì²´ì ì´ê³  ëª…í™•
system_msg = SystemMessage("""
ë‹¹ì‹ ì€ Python ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

**ì—­í• **:
- ì´ˆë³´ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤
- í•­ìƒ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ ì˜ˆì œë¥¼ ì œê³µí•©ë‹ˆë‹¤
- ì—ëŸ¬ê°€ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë¶€ë¶„ì€ ë¯¸ë¦¬ ê²½ê³ í•©ë‹ˆë‹¤

**ì‘ë‹µ í˜•ì‹**:
1. ê°œë… ì„¤ëª… (2-3ë¬¸ì¥)
2. ì½”ë“œ ì˜ˆì œ
3. ì£¼ì˜ì‚¬í•­ ë˜ëŠ” ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤
""")

# âŒ ë‚˜ìœ ì˜ˆ: ë„ˆë¬´ ëª¨í˜¸í•¨
system_msg = SystemMessage("ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.")
```

### Tip 4: Tool ë””ë²„ê¹…

```python
from langchain.tools import tool

@tool
def my_tool(param: str) -> str:
    """ë„êµ¬ ì„¤ëª…"""
    print(f"Tool called with: {param}")  # ë””ë²„ê¹… ì¶œë ¥
    result = f"Result for {param}"
    print(f"Tool returning: {result}")   # ë””ë²„ê¹… ì¶œë ¥
    return result

# ë„êµ¬ë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ í…ŒìŠ¤íŠ¸
result = my_tool.invoke({"param": "test"})
print(result)

# ìŠ¤í‚¤ë§ˆ í™•ì¸
print(my_tool.name)
print(my_tool.description)
print(my_tool.args)
```

### Tip 5: ë¹„ìš© ìµœì í™”

```python
# ì „ëµ 1: ê°„ë‹¨í•œ ì‘ì—…ì€ ì‘ì€ ëª¨ë¸ ì‚¬ìš©
simple_model = init_chat_model("gpt-4o-mini")  # ì €ë ´
complex_model = init_chat_model("gpt-4o")      # ë¹„ìŒˆ

# ì „ëµ 2: max_tokensë¡œ ì¶œë ¥ ê¸¸ì´ ì œí•œ
model = init_chat_model("gpt-4o-mini", max_tokens=500)

# ì „ëµ 3: ìºì‹± í™œìš© (ë™ì¼í•œ ì…ë ¥ ë°˜ë³µ ì‹œ)
# OpenAIì™€ GeminiëŠ” ìë™ ìºì‹±
# Anthropicì€ ëª…ì‹œì  ìºì‹± í•„ìš”

# ì „ëµ 4: Batch API ì‚¬ìš© (ëŒ€ëŸ‰ ì²˜ë¦¬ ì‹œ 50% í• ì¸)
responses = model.batch([
    "ì§ˆë¬¸ 1",
    "ì§ˆë¬¸ 2",
    "ì§ˆë¬¸ 3"
])
```

---

## â“ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸

<details>
<summary>Q1: init_chat_model()ê³¼ ChatOpenAI() ì¤‘ ë¬´ì—‡ì„ ì‚¬ìš©í•´ì•¼ í•˜ë‚˜ìš”?</summary>

**A**: ì¼ë°˜ì ìœ¼ë¡œ `init_chat_model()`ì„ ê¶Œì¥í•©ë‹ˆë‹¤.

**init_chat_model() ì¥ì **:
- í”„ë¡œë°”ì´ë”ë¥¼ ì‰½ê²Œ êµì²´ ê°€ëŠ¥
- ëŸ°íƒ€ì„ì— ëª¨ë¸ ë³€ê²½ ê°€ëŠ¥ (configurable model)
- ë” ê°„ê²°í•œ ì½”ë“œ

**ì§ì ‘ í´ë˜ìŠ¤ ì‚¬ìš©ì´ ë‚˜ì€ ê²½ìš°**:
- í”„ë¡œë°”ì´ë”ë³„ ê³ ìœ  ê¸°ëŠ¥ ì‚¬ìš© ì‹œ (ì˜ˆ: OpenAIì˜ `use_responses_api`)
- íƒ€ì… ì²´í‚¹ì´ ì¤‘ìš”í•œ ëŒ€ê·œëª¨ í”„ë¡œì íŠ¸
- IDE ìë™ì™„ì„± ì§€ì›ì´ í•„ìš”í•œ ê²½ìš°

```python
# ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ì´ê²ƒìœ¼ë¡œ ì¶©ë¶„
model = init_chat_model("gpt-4o-mini")

# ê³ ê¸‰ ê¸°ëŠ¥ì´ í•„ìš”í•œ ê²½ìš°
from langchain_openai import ChatOpenAI
model = ChatOpenAI(model="gpt-4o-mini", use_responses_api=True)
```

ğŸ“– [07-models.md](../official/07-models_ko.md#ëª¨ë¸-ì´ˆê¸°í™”)
</details>

<details>
<summary>Q2: Toolì˜ docstringì„ ê¼­ ì‘ì„±í•´ì•¼ í•˜ë‚˜ìš”?</summary>

**A**: ë„¤, ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. Docstringì€ ëª¨ë¸ì´ ë„êµ¬ë¥¼ ì–¸ì œ ì‚¬ìš©í• ì§€ ê²°ì •í•˜ëŠ” í•µì‹¬ ì •ë³´ì…ë‹ˆë‹¤.

**ì¢‹ì€ docstringì˜ ìš”ì†Œ**:
1. **ëª…í™•í•œ ëª©ì **: ì²« ë¬¸ì¥ì— ë„êµ¬ê°€ ë¬´ì—‡ì„ í•˜ëŠ”ì§€ ëª…ì‹œ
2. **ì‚¬ìš© ì‹œê¸°**: ì–´ë–¤ ìƒí™©ì—ì„œ ì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ì§€
3. **íŒŒë¼ë¯¸í„° ì„¤ëª…**: ê° íŒŒë¼ë¯¸í„°ì˜ ì˜ë¯¸ì™€ ì˜ˆì‹œ
4. **ë°˜í™˜ê°’ ì„¤ëª…**: ì–´ë–¤ í˜•ì‹ìœ¼ë¡œ ë¬´ì—‡ì„ ë°˜í™˜í•˜ëŠ”ì§€

```python
@tool
def search_database(query: str, limit: int = 10) -> str:
    """ê³ ê° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë ˆì½”ë“œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    ì‚¬ìš©ìê°€ ê³ ê° ì •ë³´ë¥¼ ìš”ì²­í•  ë•Œ ì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

    Args:
        query: ê²€ìƒ‰í•  í‚¤ì›Œë“œ (ê³ ê° ì´ë¦„, ì´ë©”ì¼, ID ë“±)
        limit: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ 10ê°œ)

    Returns:
        JSON í˜•ì‹ì˜ ê³ ê° ì •ë³´ ëª©ë¡
    """
    return f"Results for {query}"
```

ğŸ“– [09-tools.md](../official/09-tools_ko.md#ê¸°ë³¸-tool-ì •ì˜)
</details>

<details>
<summary>Q3: AIMessageì˜ usage_metadataê°€ Noneì¸ ê²½ìš°ê°€ ìˆì–´ìš”</summary>

**A**: ëª¨ë“  í”„ë¡œë°”ì´ë”ê°€ í† í° ì‚¬ìš©ëŸ‰ì„ ë°˜í™˜í•˜ëŠ” ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤.

**í† í° ì‚¬ìš©ëŸ‰ ì§€ì› ì—¬ë¶€**:
- âœ… ì§€ì›: OpenAI, Anthropic, Google Gemini, Azure OpenAI
- âŒ ë¯¸ì§€ì›: ì¼ë¶€ ë¡œì»¬ ëª¨ë¸, ì»¤ìŠ¤í…€ í”„ë¡œë°”ì´ë”

**ìŠ¤íŠ¸ë¦¬ë° ì‹œ ì£¼ì˜ì‚¬í•­**:
- OpenAIì™€ AzureëŠ” ìŠ¤íŠ¸ë¦¬ë°ì—ì„œ í† í° ì‚¬ìš©ëŸ‰ì„ ë°›ìœ¼ë ¤ë©´ ëª…ì‹œì ìœ¼ë¡œ ìš”ì²­í•´ì•¼ í•¨
- `stream_options={"include_usage": True}` ì„¤ì • í•„ìš”

```python
# ìŠ¤íŠ¸ë¦¬ë°ì—ì„œ í† í° ì‚¬ìš©ëŸ‰ ë°›ê¸° (OpenAI)
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-4o-mini")
for chunk in model.stream(
    "Hello",
    stream_options={"include_usage": True}
):
    if chunk.usage_metadata:
        print(chunk.usage_metadata)
```

ğŸ“– [07-models.md](../official/07-models_ko.md#í† í°-ì‚¬ìš©ëŸ‰)
</details>

<details>
<summary>Q4: Dictionary í˜•ì‹ê³¼ Message ê°ì²´ ì¤‘ ì–´ë–¤ ê²ƒì„ ì‚¬ìš©í•´ì•¼ í•˜ë‚˜ìš”?</summary>

**A**: í”„ë¡œì íŠ¸ ê·œëª¨ì™€ ìš”êµ¬ì‚¬í•­ì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤.

**Dictionary í˜•ì‹ì´ ì í•©í•œ ê²½ìš°**:
- ê°„ë‹¨í•œ í”„ë¡œí† íƒ€ì…
- ì™¸ë¶€ APIì™€ ì§ì ‘ ì—°ë™ (OpenAI API í˜•ì‹)
- JSON ì§ë ¬í™”ê°€ ìì£¼ í•„ìš”í•œ ê²½ìš°

**Message ê°ì²´ê°€ ì í•©í•œ ê²½ìš°**:
- íƒ€ì… ì•ˆì •ì„±ì´ ì¤‘ìš”í•œ í”„ë¡œì íŠ¸
- ë©€í‹°ëª¨ë‹¬ ì½˜í…ì¸  (ì´ë¯¸ì§€, ì˜¤ë””ì˜¤ ë“±) ì‚¬ìš©
- ë©”íƒ€ë°ì´í„° (ID, í† í° ì‚¬ìš©ëŸ‰ ë“±) ì ‘ê·¼ í•„ìš”
- IDE ìë™ì™„ì„± ì§€ì› í•„ìš”

```python
# Dictionary: ê°„ë‹¨í•˜ì§€ë§Œ íƒ€ì… ì²´í¬ ì—†ìŒ
messages = [
    {"role": "user", "content": "Hello"}
]

# Message ê°ì²´: íƒ€ì… ì•ˆì „, ìë™ì™„ì„±, ë©”íƒ€ë°ì´í„°
from langchain.messages import HumanMessage
messages = [
    HumanMessage("Hello")
]
```

**ì¶”ì²œ**: ì‹¤ë¬´ì—ì„œëŠ” Message ê°ì²´ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.

ğŸ“– [08-messages.md](../official/08-messages_ko.md#ë”•ì…”ë„ˆë¦¬-í˜•ì‹)
</details>

<details>
<summary>Q5: Toolì—ì„œ ì—ëŸ¬ê°€ ë°œìƒí•˜ë©´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?</summary>

**A**: Tool ì‹¤í–‰ ì¤‘ ì—ëŸ¬ê°€ ë°œìƒí•˜ë©´ Agentê°€ ì—ëŸ¬ë¥¼ ì²˜ë¦¬í•˜ê±°ë‚˜ ì‚¬ìš©ìì—ê²Œ ì „ë‹¬í•©ë‹ˆë‹¤.

**ì—ëŸ¬ ì²˜ë¦¬ ì „ëµ**:

```python
@tool
def risky_operation(param: str) -> str:
    """ì—ëŸ¬ê°€ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì‘ì—…"""
    try:
        # ìœ„í—˜í•œ ì‘ì—…
        result = perform_operation(param)
        return f"Success: {result}"
    except ValueError as e:
        # ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜
        return f"Error: Invalid parameter '{param}'. {str(e)}"
    except Exception as e:
        # ì¼ë°˜ ì—ëŸ¬
        return f"Error: Operation failed. {str(e)}"
```

**ëª¨ë¸ì—ê²Œ ì—ëŸ¬ ì •ë³´ ì „ë‹¬**:
- Toolì´ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•˜ë©´ ëª¨ë¸ì´ ì´ë¥¼ ì½ê³  ì‚¬ìš©ìì—ê²Œ ì„¤ëª…
- ë˜ëŠ” ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì¬ì‹œë„ ê°€ëŠ¥

ğŸ“– [09-tools.md](../official/09-tools_ko.md)
</details>

---

## ğŸ”— ì‹¬í™” í•™ìŠµ

ì´ íŒŒíŠ¸ì˜ ê¸°ì´ˆë¥¼ ë§ˆìŠ¤í„°í–ˆë‹¤ë©´ ë‹¤ìŒ ë‹¨ê³„ë¡œ ë‚˜ì•„ê°€ì„¸ìš”:

### 1. ê³µì‹ ë¬¸ì„œ ì‹¬í™”

- [07-models.md - ê³ ê¸‰ ê¸°ëŠ¥](../official/07-models_ko.md#ê³ ê¸‰-ì£¼ì œ)
  - Structured Output (êµ¬ì¡°í™”ëœ ì¶œë ¥)
  - Multimodal (ë©€í‹°ëª¨ë‹¬)
  - Rate Limiting (ì†ë„ ì œí•œ)
  - Prompt Caching (í”„ë¡¬í”„íŠ¸ ìºì‹±)

- [08-messages.md - Content Blocks](../official/08-messages_ko.md#ì½˜í…ì¸ -ë¸”ë¡-ì°¸ì¡°)
  - í‘œì¤€ ì½˜í…ì¸  ë¸”ë¡
  - ë©€í‹°ëª¨ë‹¬ ì½˜í…ì¸ 
  - ìŠ¤íŠ¸ë¦¬ë°ê³¼ ì²­í¬

- [09-tools.md - Runtime Context](../official/09-tools_ko.md#ì»¨í…ìŠ¤íŠ¸-ì ‘ê·¼)
  - ToolRuntimeìœ¼ë¡œ State ì ‘ê·¼
  - Contextì™€ Store ì‚¬ìš©
  - Stream Writer

### 2. ì‹¤ì „ ì˜ˆì œ

- **ë©€í‹°ëª¨ë‹¬ Chat Model**: ì´ë¯¸ì§€, ì˜¤ë””ì˜¤ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ” ëª¨ë¸
- **Structured Output**: JSON ìŠ¤í‚¤ë§ˆë¡œ ì¶œë ¥ í˜•ì‹ ì œì–´
- **Async Tools**: ë¹„ë™ê¸° ë„êµ¬ë¡œ ì„±ëŠ¥ ìµœì í™”
- **Tool Streaming**: ë„êµ¬ ì‹¤í–‰ ê³¼ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°

### 3. ê´€ë ¨ ê¸°ìˆ 

- **LangSmith**: ëª¨ë¸ í˜¸ì¶œê³¼ ë„êµ¬ ì‹¤í–‰ì„ ì‹œê°í™”í•˜ê³  ë””ë²„ê¹…
- **LangGraph**: ë³µì¡í•œ Agent ì›Œí¬í”Œë¡œìš° êµ¬ì¶•
- **LCEL (LangChain Expression Language)**: ì²´ì¸ êµ¬ì„±ì˜ ê³ ê¸‰ íŒ¨í„´

### 4. ë‹¤ìŒ ë‹¨ê³„

- [Part 3: ì²« ë²ˆì§¸ Agent ë§Œë“¤ê¸°](./part03_first_agent.md) (â­â­â˜†)
  - `create_react_agent()`ë¡œ ì™„ì „í•œ Agent êµ¬ì¶•
  - Tool Calling ìë™ ë£¨í”„
  - System Prompt ì„¤ê³„

- [Part 4: Memoryì™€ ëŒ€í™” ê´€ë¦¬](./part04_memory.md) (â­â­â­)
  - ëŒ€í™” ê¸°ë¡ ê´€ë¦¬
  - Context Window ê´€ë¦¬
  - ìš”ì•½ê³¼ íŠ¸ë¦¬ë°

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

Part 2ë¥¼ ì™„ë£Œí•˜ê¸° ì „ì— ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:

- [ ] `init_chat_model()`ë¡œ OpenAIì™€ Anthropic ëª¨ë¸ì„ ì´ˆê¸°í™”í•  ìˆ˜ ìˆë‹¤
- [ ] Temperature íŒŒë¼ë¯¸í„°ì˜ ì˜ë¯¸ì™€ ìš©ë„ë¥¼ ì´í•´í•œë‹¤
- [ ] SystemMessage, HumanMessage, AIMessageë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™”ë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆë‹¤
- [ ] Dictionary í˜•ì‹ê³¼ Message ê°ì²´ì˜ ì°¨ì´ë¥¼ ì´í•´í•œë‹¤
- [ ] `@tool` ë°ì½”ë ˆì´í„°ë¡œ ê¸°ë³¸ ë„êµ¬ë¥¼ ë§Œë“¤ ìˆ˜ ìˆë‹¤
- [ ] Type hintsì™€ docstringì´ ì™œ ì¤‘ìš”í•œì§€ ì´í•´í•œë‹¤
- [ ] Pydantic ìŠ¤í‚¤ë§ˆë¡œ ë³µì¡í•œ ì…ë ¥ì„ ì •ì˜í•  ìˆ˜ ìˆë‹¤
- [ ] Tool Callingì˜ ì „ì²´ íë¦„ì„ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤
- [ ] ëª¨ë“  ì‹¤ìŠµ ê³¼ì œë¥¼ ì™„ë£Œí–ˆë‹¤
- [ ] ì˜ˆì œ ì½”ë“œë¥¼ ì§ì ‘ ì‹¤í–‰í•˜ê³  ìˆ˜ì •í•´ë´¤ë‹¤

---

## ë‹¤ìŒ ë‹¨ê³„

âœ… Part 2 ì™„ë£Œ!
â¡ï¸ [Part 3: ì²« ë²ˆì§¸ Agent ë§Œë“¤ê¸°](./part03_first_agent.md)

ì´ì œ Chat Models, Messages, Toolsì˜ ê¸°ë³¸ì„ ì´í•´í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ íŒŒíŠ¸ì—ì„œëŠ” ì´ êµ¬ì„± ìš”ì†Œë“¤ì„ ê²°í•©í•˜ì—¬ ì‹¤ì œë¡œ ë™ì‘í•˜ëŠ” Agentë¥¼ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤!

---

**í•™ìŠµ ì§„ë„**: â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 20% (Part 2/10 ì™„ë£Œ)

*ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: 2026-03-01*
