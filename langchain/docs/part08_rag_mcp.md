# Part 8: RAGì™€ MCP (Retrieval Augmented Generation & Model Context Protocol)

> ğŸ“š **í•™ìŠµ ì‹œê°„**: ì•½ 4-5ì‹œê°„
> ğŸ¯ **ë‚œì´ë„**: â­â­â­â­â˜† (ê³ ê¸‰)
> ğŸ“– **ê³µì‹ ë¬¸ì„œ**: [28-retrieval.md](../official/28-retrieval_ko.md), [20-model-context-protocol.md](../official/20-model-context-protocol_ko.md)
> ğŸ’» **ì˜ˆì œ ì½”ë“œ**: [part08_rag_mcp ë””ë ‰í† ë¦¬](../src/part08_rag_mcp/)

---

## ğŸ“‹ í•™ìŠµ ëª©í‘œ

ì´ íŒŒíŠ¸ë¥¼ ì™„ë£Œí•˜ë©´ ë‹¤ìŒì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- [ ] RAG (Retrieval Augmented Generation)ì˜ ê°œë…ê³¼ í•„ìš”ì„±ì„ ì´í•´í•œë‹¤
- [ ] Vector Storeë¥¼ êµ¬ì¶•í•˜ê³  ë¬¸ì„œë¥¼ ì„ë² ë”©í•  ìˆ˜ ìˆë‹¤
- [ ] ê¸°ë³¸ RAG ì‹œìŠ¤í…œì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤
- [ ] Agentic RAG íŒ¨í„´ì„ ì´í•´í•˜ê³  êµ¬í˜„í•  ìˆ˜ ìˆë‹¤
- [ ] MCP (Model Context Protocol)ì˜ ê°œë…ê³¼ ì•„í‚¤í…ì²˜ë¥¼ ì´í•´í•œë‹¤
- [ ] MCP ì„œë²„ë¥¼ êµ¬í˜„í•˜ê³  ë„êµ¬ë¥¼ ì œê³µí•  ìˆ˜ ìˆë‹¤
- [ ] MCP í´ë¼ì´ì–¸íŠ¸ë¥¼ í†µí•´ ì™¸ë¶€ ë„êµ¬ì— ì ‘ê·¼í•  ìˆ˜ ìˆë‹¤
- [ ] Agentì™€ MCPë¥¼ í†µí•©í•˜ì—¬ í™•ì¥ ê°€ëŠ¥í•œ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆë‹¤

---

## ğŸ“š ê°œìš”

**RAG (Retrieval Augmented Generation)**ì™€ **MCP (Model Context Protocol)**ëŠ” LLMì˜ í•µì‹¬ ì œì•½ì‚¬í•­ì„ í•´ê²°í•˜ëŠ” ë‘ ê°€ì§€ ì¤‘ìš”í•œ ê¸°ìˆ ì…ë‹ˆë‹¤.

### LLMì˜ í•µì‹¬ ì œì•½ì‚¬í•­

LLMì€ ê°•ë ¥í•˜ì§€ë§Œ ë‘ ê°€ì§€ ê·¼ë³¸ì ì¸ í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤:

1. **ìœ í•œí•œ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°**: í•œ ë²ˆì— ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ ì–‘ì´ ì œí•œë¨
2. **ì •ì ì¸ ì§€ì‹**: í•™ìŠµ ë°ì´í„°ê°€ íŠ¹ì • ì‹œì ì— ê³ ì •ë˜ì–´ ìµœì‹  ì •ë³´ ë¶€ì¡±

### RAGì™€ MCPì˜ ì—­í• 

**RAG**ëŠ” ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ LLMì— ì œê³µí•¨ìœ¼ë¡œì¨ ì´ ë‘ ê°€ì§€ ë¬¸ì œë¥¼ ëª¨ë‘ í•´ê²°í•©ë‹ˆë‹¤:
- í•„ìš”í•œ ì •ë³´ë§Œ ê²€ìƒ‰í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° íš¨ìœ¨ì  ì‚¬ìš©
- ì‹¤ì‹œê°„ìœ¼ë¡œ ìµœì‹  ì •ë³´ ê²€ìƒ‰ ê°€ëŠ¥

**MCP**ëŠ” ì™¸ë¶€ ë„êµ¬ì™€ ë°ì´í„° ì†ŒìŠ¤ë¥¼ í‘œì¤€í™”ëœ ë°©ì‹ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ Agentì˜ ëŠ¥ë ¥ì„ í™•ì¥í•©ë‹ˆë‹¤:
- ë‹¤ì–‘í•œ ë„êµ¬ë¥¼ ì¼ê´€ëœ ì¸í„°í˜ì´ìŠ¤ë¡œ ì œê³µ
- ì„œë²„-í´ë¼ì´ì–¸íŠ¸ êµ¬ì¡°ë¡œ í™•ì¥ ê°€ëŠ¥í•œ ì‹œìŠ¤í…œ êµ¬ì¶•

### ì‹¤ì „ í™œìš© ì‚¬ë¡€

**1. ê¸°ì—… ë¬¸ì„œ Q&A ì‹œìŠ¤í…œ**
```python
# ìˆ˜ì²œ ê°œì˜ ë‚´ë¶€ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ì—¬ ì •í™•í•œ ë‹µë³€ ì œê³µ
vectorstore = FAISS.from_documents(company_docs, embeddings)
retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

@tool
def search_company_docs(query: str) -> str:
    """íšŒì‚¬ ë¬¸ì„œì—ì„œ ì •ë³´ ê²€ìƒ‰"""
    docs = retriever.invoke(query)
    return "\n".join([d.page_content for d in docs])
```

**2. ìµœì‹  ì •ë³´ ê¸°ë°˜ ë‰´ìŠ¤ ë´‡**
```python
# ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ê³¼ RAGë¥¼ ê²°í•©í•˜ì—¬ ìµœì‹  ë‰´ìŠ¤ ì œê³µ
@tool
def search_recent_news(topic: str) -> str:
    """ìµœì‹  ë‰´ìŠ¤ ê²€ìƒ‰ ë° ìš”ì•½"""
    # 1. ì›¹ì—ì„œ ìµœì‹  ê¸°ì‚¬ ê²€ìƒ‰
    # 2. Vector Storeì— ì„ì‹œ ì €ì¥
    # 3. ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰
    # 4. LLMì´ ìš”ì•½
```

**3. MCP ê¸°ë°˜ ê°œë°œ ë„ìš°ë¯¸**
```python
# ì—¬ëŸ¬ MCP ì„œë²„ë¥¼ í†µí•´ ë‹¤ì–‘í•œ ë„êµ¬ ì œê³µ
client = MultiServerMCPClient({
    "github": {...},      # GitHub API ì ‘ê·¼
    "database": {...},    # DB ì¿¼ë¦¬ ì‹¤í–‰
    "filesystem": {...},  # íŒŒì¼ ì‹œìŠ¤í…œ ì‘ì—…
})

tools = await client.get_tools()
agent = create_agent("gpt-4o-mini", tools)
```

**4. ê³ ê° ì§€ì› ì±—ë´‡**
```python
# FAQ, ì œí’ˆ ë§¤ë‰´ì–¼, ê³¼ê±° í‹°ì¼“ì„ RAGë¡œ ê²€ìƒ‰
# MCPë¡œ CRM ì‹œìŠ¤í…œ ì—°ë™í•˜ì—¬ ê³ ê° ì •ë³´ ì¡°íšŒ
```

### RAG vs MCP ë¹„êµ

| ì¸¡ë©´ | RAG | MCP |
|------|-----|-----|
| **ëª©ì ** | ì™¸ë¶€ ì§€ì‹ ê²€ìƒ‰ | ì™¸ë¶€ ë„êµ¬ ì—°ê²° |
| **í•µì‹¬ ê°œë…** | Vector Store, Embedding | ì„œë²„-í´ë¼ì´ì–¸íŠ¸, Protocol |
| **ì£¼ìš” ì‘ì—…** | ë¬¸ì„œ ê²€ìƒ‰, ìœ ì‚¬ë„ ê³„ì‚° | Tool/Resource ì œê³µ |
| **ì‚¬ìš© ì‹œì ** | ì§€ì‹ì´ í•„ìš”í•  ë•Œ | ì‘ì—… ì‹¤í–‰ì´ í•„ìš”í•  ë•Œ |
| **í™•ì¥ì„±** | ë¬¸ì„œ ì¶”ê°€ë¡œ í™•ì¥ | ì„œë²„ ì¶”ê°€ë¡œ í™•ì¥ |

### í†µí•© ì•„í‚¤í…ì²˜

RAGì™€ MCPëŠ” í•¨ê»˜ ì‚¬ìš©ë  ë•Œ ê°€ì¥ ê°•ë ¥í•©ë‹ˆë‹¤:

```mermaid
flowchart TB
    user([ì‚¬ìš©ì ì§ˆë¬¸])
    agent[Agent]
    rag[RAG Retriever]
    mcp[MCP Tools]
    vectordb[(Vector Store)]
    mcpserver[MCP Server]
    response([ì‘ë‹µ])

    user --> agent
    agent --> rag
    agent --> mcp
    rag --> vectordb
    mcp --> mcpserver
    vectordb --> agent
    mcpserver --> agent
    agent --> response
```

---

## 1. RAG ê¸°ì´ˆ

### 1.1 RAGë€ ë¬´ì—‡ì¸ê°€?

**Retrieval Augmented Generation (RAG)**ëŠ” LLMì˜ ìƒì„± ëŠ¥ë ¥ê³¼ ì™¸ë¶€ ì§€ì‹ ê²€ìƒ‰ì„ ê²°í•©í•œ ê¸°ë²•ì…ë‹ˆë‹¤.

#### RAGê°€ ì—†ì„ ë•Œì˜ ë¬¸ì œ

```python
# âŒ RAG ì—†ì´ - LLMì˜ ë‚´ì¬ëœ ì§€ì‹ì—ë§Œ ì˜ì¡´
agent = create_agent("gpt-4o-mini", tools=[])
response = agent.invoke({
    "messages": [{"role": "user", "content": "2024ë…„ ìš°ë¦¬ íšŒì‚¬ì˜ Q3 ë§¤ì¶œì€?"}]
})
# ê²°ê³¼: "ì£„ì†¡í•˜ì§€ë§Œ ê·¸ ì •ë³´ë¥¼ ëª¨ë¦…ë‹ˆë‹¤" ë˜ëŠ” ì˜ëª»ëœ ì¶”ì¸¡
```

#### RAGë¥¼ ì‚¬ìš©í•  ë•Œ

```python
# âœ… RAG ì‚¬ìš© - ì‹¤ì œ ë¬¸ì„œì—ì„œ ê²€ìƒ‰í•˜ì—¬ ì •í™•í•œ ë‹µë³€
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings

# íšŒì‚¬ ë¬¸ì„œë¥¼ Vector Storeì— ì €ì¥
company_docs = ["2024 Q3 ë§¤ì¶œ: $5.2M", "2024 Q2 ë§¤ì¶œ: $4.8M", ...]
vectorstore = FAISS.from_texts(company_docs, OpenAIEmbeddings())

@tool
def search_financials(query: str) -> str:
    """ì¬ë¬´ ì •ë³´ ê²€ìƒ‰"""
    docs = vectorstore.similarity_search(query, k=3)
    return "\n".join([d.page_content for d in docs])

agent = create_agent("gpt-4o-mini", tools=[search_financials])
response = agent.invoke({
    "messages": [{"role": "user", "content": "2024ë…„ ìš°ë¦¬ íšŒì‚¬ì˜ Q3 ë§¤ì¶œì€?"}]
})
# ê²°ê³¼: "2024ë…„ Q3 ë§¤ì¶œì€ $5.2Mì…ë‹ˆë‹¤."
```

### 1.2 Vector Databaseì˜ ì´í•´

Vector DatabaseëŠ” í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•˜ê³ , ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

#### ì‘ë™ ì›ë¦¬

```mermaid
flowchart LR
    text1[ë¬¸ì„œ: 'ê³ ì–‘ì´ëŠ” ê·€ì—½ë‹¤']
    text2[ë¬¸ì„œ: 'ê°•ì•„ì§€ëŠ” ì¶©ì„±ìŠ¤ëŸ½ë‹¤']
    text3[ë¬¸ì„œ: 'íŒŒì´ì¬ì€ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë‹¤']

    embed1[ë²¡í„°: 0.2, 0.8, 0.1, ...]
    embed2[ë²¡í„°: 0.3, 0.7, 0.15, ...]
    embed3[ë²¡í„°: 0.9, 0.1, 0.85, ...]

    query[ì¿¼ë¦¬: 'ì• ì™„ë™ë¬¼']
    qembed[ë²¡í„°: 0.25, 0.75, 0.12, ...]

    result[ê°€ì¥ ìœ ì‚¬: 'ê³ ì–‘ì´ëŠ” ê·€ì—½ë‹¤']

    text1 --> embed1
    text2 --> embed2
    text3 --> embed3

    query --> qembed
    qembed -.ìœ ì‚¬ë„ ê³„ì‚°.-> embed1
    qembed -.ìœ ì‚¬ë„ ê³„ì‚°.-> embed2
    qembed -.ìœ ì‚¬ë„ ê³„ì‚°.-> embed3

    embed1 --> result
```

#### ì£¼ìš” Vector Store ë¹„êµ

| Vector Store | íƒ€ì… | íŠ¹ì§• | ì‚¬ìš© ì‚¬ë¡€ |
|--------------|------|------|-----------|
| **FAISS** | ë¡œì»¬ ì¸ë©”ëª¨ë¦¬ | ë¹ ë¦„, ë¬´ë£Œ, ë¡œì»¬ ì‹¤í–‰ | í”„ë¡œí† íƒ€ì…, ì†Œê·œëª¨ ë°ì´í„° |
| **Chroma** | ë¡œì»¬/ì„œë²„ | ì‚¬ìš© ì‰¬ì›€, ë©”íƒ€ë°ì´í„° í•„í„°ë§ | ì¤‘ì†Œê·œëª¨ ì• í”Œë¦¬ì¼€ì´ì…˜ |
| **Pinecone** | í´ë¼ìš°ë“œ | í™•ì¥ì„±, ê´€ë¦¬í˜• ì„œë¹„ìŠ¤ | ëŒ€ê·œëª¨ í”„ë¡œë•ì…˜ |
| **Weaviate** | í´ë¼ìš°ë“œ/ì˜¨í”„ë ˆë¯¸ìŠ¤ | ê³ ê¸‰ ê¸°ëŠ¥, GraphQL | ë³µì¡í•œ ê²€ìƒ‰ ìš”êµ¬ì‚¬í•­ |
| **Qdrant** | ë¡œì»¬/í´ë¼ìš°ë“œ | ë¹ ë¦„, í•„í„°ë§ ê°•ë ¥ | ê³ ì„±ëŠ¥ ê²€ìƒ‰ |

### 1.3 Embeddingì˜ ì´í•´

Embeddingì€ í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ëŠ” ë²¡í„° ê³µê°„ì—ì„œ ê°€ê¹Œìš´ ìœ„ì¹˜ì— ë§¤í•‘ë©ë‹ˆë‹¤.

#### Embedding ëª¨ë¸ ì„ íƒ

```python
# OpenAI Embeddings (ê¶Œì¥)
from langchain_openai import OpenAIEmbeddings
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

# Cohere Embeddings (ë‹¤êµ­ì–´ ì§€ì› ê°•í•¨)
from langchain_cohere import CohereEmbeddings
embeddings = CohereEmbeddings(model="embed-multilingual-v3.0")

# HuggingFace Embeddings (ë¬´ë£Œ, ë¡œì»¬)
from langchain_huggingface import HuggingFaceEmbeddings
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
```

#### Embedding í’ˆì§ˆ ë¹„êµ

| ëª¨ë¸ | ì°¨ì› | ì„±ëŠ¥ | ë¹„ìš© | íŠ¹ì§• |
|------|------|------|------|------|
| text-embedding-3-small | 1536 | ìš°ìˆ˜ | ë‚®ìŒ | ë²”ìš©, ë¹ ë¦„ |
| text-embedding-3-large | 3072 | ìµœê³  | ì¤‘ê°„ | ìµœê³  í’ˆì§ˆ |
| embed-multilingual-v3.0 | 1024 | ìš°ìˆ˜ | ì¤‘ê°„ | 100+ ì–¸ì–´ |
| all-MiniLM-L6-v2 | 384 | ì–‘í˜¸ | ë¬´ë£Œ | ë¡œì»¬, ë¹ ë¦„ |

### 1.4 Retrieval ê³¼ì • ìƒì„¸

RAGì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ë‹¨ê³„ë³„ë¡œ ì‚´í´ë´…ì‹œë‹¤.

```mermaid
flowchart TD
    subgraph "ì˜¤í”„ë¼ì¸ ì¸ë±ì‹±"
        docs[ì›ë³¸ ë¬¸ì„œ]
        load[ë¬¸ì„œ ë¡œë”©]
        split[ì²­í‚¹]
        embed[ì„ë² ë”© ìƒì„±]
        store[(Vector Store ì €ì¥)]

        docs --> load
        load --> split
        split --> embed
        embed --> store
    end

    subgraph "ì˜¨ë¼ì¸ ê²€ìƒ‰"
        query[ì‚¬ìš©ì ì¿¼ë¦¬]
        qembed[ì¿¼ë¦¬ ì„ë² ë”©]
        search[ìœ ì‚¬ë„ ê²€ìƒ‰]
        rerank[ì¬ìˆœìœ„í™”]
        context[ì»¨í…ìŠ¤íŠ¸ ìƒì„±]

        query --> qembed
        qembed --> search
        store --> search
        search --> rerank
        rerank --> context
    end

    subgraph "ìƒì„±"
        llm[LLM]
        response[ì‘ë‹µ ìƒì„±]

        context --> llm
        llm --> response
    end
```

#### 1ë‹¨ê³„: ë¬¸ì„œ ë¡œë”©

```python
from langchain_community.document_loaders import (
    TextLoader,
    PDFLoader,
    WebBaseLoader,
    CSVLoader
)

# í…ìŠ¤íŠ¸ íŒŒì¼
loader = TextLoader("./docs/company_policy.txt")
docs = loader.load()

# PDF íŒŒì¼
loader = PDFLoader("./docs/manual.pdf")
docs = loader.load()

# ì›¹ í˜ì´ì§€
loader = WebBaseLoader("https://example.com/docs")
docs = loader.load()

# CSV íŒŒì¼
loader = CSVLoader("./data/products.csv")
docs = loader.load()
```

#### 2ë‹¨ê³„: í…ìŠ¤íŠ¸ ì²­í‚¹ (Text Splitting)

ì²­í‚¹ì€ ê¸´ ë¬¸ì„œë¥¼ ì‘ì€ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì ì ˆí•œ ì²­í‚¹ì€ RAG í’ˆì§ˆì— í° ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.

```python
from langchain.text_splitter import (
    RecursiveCharacterTextSplitter,
    CharacterTextSplitter,
    TokenTextSplitter
)

# RecursiveCharacterTextSplitter (ê¶Œì¥)
# - ë¬¸ë‹¨, ë¬¸ì¥, ë‹¨ì–´ ìˆœìœ¼ë¡œ ì¬ê·€ì  ë¶„í• 
splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,      # ì²­í¬ í¬ê¸°
    chunk_overlap=200,    # ì²­í¬ ê°„ ê²¹ì¹¨
    length_function=len,
)
chunks = splitter.split_documents(docs)

# TokenTextSplitter
# - í† í° ê¸°ë°˜ ë¶„í•  (LLM ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ê³ ë ¤)
splitter = TokenTextSplitter(
    chunk_size=512,
    chunk_overlap=50
)
chunks = splitter.split_documents(docs)
```

**ì²­í‚¹ ì „ëµ ê°€ì´ë“œ:**

| Chunk Size | Overlap | ì‚¬ìš© ì‚¬ë¡€ |
|------------|---------|-----------|
| 500-1000 | 100-200 | ì¼ë°˜ì ì¸ ë¬¸ì„œ |
| 200-500 | 50-100 | ì§§ì€ ë‹¨ë½, FAQ |
| 1000-2000 | 200-400 | ê¸´ ê¸°ìˆ  ë¬¸ì„œ |
| 100-300 | 20-50 | ì½”ë“œ ìŠ¤ë‹ˆí« |

#### 3ë‹¨ê³„: ì„ë² ë”© ë° ì €ì¥

```python
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS

# ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

# Vector Store ìƒì„± ë° ì €ì¥
vectorstore = FAISS.from_documents(
    documents=chunks,
    embedding=embeddings
)

# ë””ìŠ¤í¬ì— ì €ì¥ (ì„ íƒì‚¬í•­)
vectorstore.save_local("./vectorstore")

# ë‚˜ì¤‘ì— ë¡œë“œ
vectorstore = FAISS.load_local(
    "./vectorstore",
    embeddings,
    allow_dangerous_deserialization=True
)
```

#### 4ë‹¨ê³„: ê²€ìƒ‰ ë° í™œìš©

```python
# 1. ìœ ì‚¬ë„ ê²€ìƒ‰
results = vectorstore.similarity_search(
    "íšŒì‚¬ì˜ íœ´ê°€ ì •ì±…ì€?",
    k=3  # ìƒìœ„ 3ê°œ ê²°ê³¼
)

# 2. ìœ ì‚¬ë„ ì ìˆ˜ì™€ í•¨ê»˜ ê²€ìƒ‰
results = vectorstore.similarity_search_with_score(
    "íšŒì‚¬ì˜ íœ´ê°€ ì •ì±…ì€?",
    k=3
)
for doc, score in results:
    print(f"Score: {score:.4f}")
    print(f"Content: {doc.page_content[:100]}...")

# 3. MMR (Maximum Marginal Relevance) ê²€ìƒ‰
# - ë‹¤ì–‘ì„±ì„ ê³ ë ¤í•œ ê²€ìƒ‰
results = vectorstore.max_marginal_relevance_search(
    "íšŒì‚¬ì˜ íœ´ê°€ ì •ì±…ì€?",
    k=3,
    fetch_k=10,  # ë¨¼ì € 10ê°œ ê°€ì ¸ì˜¨ í›„ 3ê°œ ì„ íƒ
    lambda_mult=0.5  # 0=ë‹¤ì–‘ì„± ì¤‘ì‹œ, 1=ìœ ì‚¬ë„ ì¤‘ì‹œ
)
```

> ğŸ’» **ì˜ˆì œ ì½”ë“œ**: [01_rag_basics.py](../src/part08_rag_mcp/01_rag_basics.py)

---

## 2. Vector Store êµ¬ì¶•

### 2.1 Chroma ì‚¬ìš©ë²•

ChromaëŠ” ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ ì˜¤í”ˆì†ŒìŠ¤ Vector Databaseì…ë‹ˆë‹¤.

```python
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings

# ê¸°ë³¸ ì‚¬ìš©
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_texts(
    texts=["ë¬¸ì„œ1", "ë¬¸ì„œ2", "ë¬¸ì„œ3"],
    embedding=embeddings,
    persist_directory="./chroma_db"  # ì˜êµ¬ ì €ì¥
)

# ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì €ì¥
vectorstore = Chroma.from_texts(
    texts=["ë¬¸ì„œ1", "ë¬¸ì„œ2"],
    embedding=embeddings,
    metadatas=[
        {"source": "doc1.pdf", "page": 1},
        {"source": "doc2.pdf", "page": 5}
    ]
)

# ë©”íƒ€ë°ì´í„° í•„í„°ë§ ê²€ìƒ‰
results = vectorstore.similarity_search(
    "ê²€ìƒ‰ ì¿¼ë¦¬",
    k=3,
    filter={"source": "doc1.pdf"}  # doc1.pdfì—ì„œë§Œ ê²€ìƒ‰
)
```

### 2.2 FAISS ì‚¬ìš©ë²•

FAISS (Facebook AI Similarity Search)ëŠ” ë¹ ë¥¸ ìœ ì‚¬ë„ ê²€ìƒ‰ì— ìµœì í™”ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.

```python
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings

# ê¸°ë³¸ ì‚¬ìš©
embeddings = OpenAIEmbeddings()
vectorstore = FAISS.from_texts(
    texts=["ë¬¸ì„œ1", "ë¬¸ì„œ2", "ë¬¸ì„œ3"],
    embedding=embeddings
)

# ì €ì¥ ë° ë¡œë“œ
vectorstore.save_local("./faiss_index")
loaded_vectorstore = FAISS.load_local(
    "./faiss_index",
    embeddings,
    allow_dangerous_deserialization=True
)

# ë²¡í„°ìŠ¤í† ì–´ ë³‘í•©
vectorstore1 = FAISS.from_texts(["doc1"], embeddings)
vectorstore2 = FAISS.from_texts(["doc2"], embeddings)
vectorstore1.merge_from(vectorstore2)  # ë³‘í•©
```

### 2.3 ë¬¸ì„œ ë¡œë”© ë° ì²­í‚¹ ì „ëµ

íš¨ê³¼ì ì¸ RAGë¥¼ ìœ„í•œ ë¬¸ì„œ ì²˜ë¦¬ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ì…ë‹ˆë‹¤.

#### ë‹¤ì–‘í•œ Document Loader

```python
# 1. ë””ë ‰í† ë¦¬ ì „ì²´ ë¡œë“œ
from langchain_community.document_loaders import DirectoryLoader

loader = DirectoryLoader(
    "./docs",
    glob="**/*.pdf",  # PDF íŒŒì¼ë§Œ
    loader_cls=PDFLoader
)
docs = loader.load()

# 2. GitHub ì €ì¥ì†Œ ë¡œë“œ
from langchain_community.document_loaders import GitHubLoader

loader = GitHubLoader(
    repo="langchain-ai/langchain",
    branch="main",
    file_filter=lambda file_path: file_path.endswith(".md")
)
docs = loader.load()

# 3. Notion í˜ì´ì§€ ë¡œë“œ
from langchain_community.document_loaders import NotionDirectoryLoader

loader = NotionDirectoryLoader("./notion_export")
docs = loader.load()

# 4. Google Drive ë¡œë“œ
from langchain_community.document_loaders import GoogleDriveLoader

loader = GoogleDriveLoader(
    folder_id="your_folder_id",
    token_path="token.json",
    recursive=True
)
docs = loader.load()
```

#### ê³ ê¸‰ ì²­í‚¹ ì „ëµ

```python
from langchain.text_splitter import (
    RecursiveCharacterTextSplitter,
    MarkdownHeaderTextSplitter,
    Language,
    RecursiveCharacterTextSplitter
)

# 1. ë§ˆí¬ë‹¤ìš´ í—¤ë” ê¸°ë°˜ ë¶„í• 
markdown_splitter = MarkdownHeaderTextSplitter(
    headers_to_split_on=[
        ("#", "Header 1"),
        ("##", "Header 2"),
        ("###", "Header 3"),
    ]
)
md_docs = markdown_splitter.split_text(markdown_text)

# 2. ì½”ë“œ ë¶„í•  (ì–¸ì–´ë³„)
python_splitter = RecursiveCharacterTextSplitter.from_language(
    language=Language.PYTHON,
    chunk_size=500,
    chunk_overlap=50
)
python_docs = python_splitter.split_documents(code_docs)

# 3. ì‹œë§¨í‹± ì²­í‚¹ (ë¬¸ì¥ ì˜ë¯¸ ê¸°ë°˜)
from langchain_experimental.text_splitter import SemanticChunker

semantic_chunker = SemanticChunker(
    embeddings=OpenAIEmbeddings(),
    breakpoint_threshold_type="percentile"  # ì˜ë¯¸ ë³€í™” ê°ì§€
)
semantic_docs = semantic_chunker.split_documents(docs)
```

### 2.4 Embedding ìƒì„± ë° ìµœì í™”

#### Embedding ë°°ì¹˜ ì²˜ë¦¬

```python
from langchain_openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",
    chunk_size=1000  # API í˜¸ì¶œë‹¹ ë¬¸ì„œ ìˆ˜
)

# ëŒ€ëŸ‰ ë¬¸ì„œ íš¨ìœ¨ì  ì²˜ë¦¬
texts = [f"ë¬¸ì„œ {i}" for i in range(10000)]
vectorstore = FAISS.from_texts(
    texts=texts,
    embedding=embeddings
)
```

#### Embedding ìºì‹±

```python
from langchain.embeddings import CacheBackedEmbeddings
from langchain.storage import LocalFileStore

# íŒŒì¼ ì‹œìŠ¤í…œ ìºì‹œ
cache_dir = LocalFileStore("./embedding_cache")
cached_embeddings = CacheBackedEmbeddings.from_bytes_store(
    underlying_embeddings=OpenAIEmbeddings(),
    document_embedding_cache=cache_dir,
    namespace="openai-embeddings"
)

# ê°™ì€ í…ìŠ¤íŠ¸ëŠ” ìºì‹œì—ì„œ ê°€ì ¸ì˜´ (API í˜¸ì¶œ ì ˆì•½)
vectorstore = FAISS.from_texts(texts, cached_embeddings)
```

### 2.5 ê²€ìƒ‰ ì „ëµ ë° ìœ ì‚¬ë„

#### ë‹¤ì–‘í•œ ê²€ìƒ‰ ë°©ë²•

```python
# 1. ê¸°ë³¸ ìœ ì‚¬ë„ ê²€ìƒ‰ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
results = vectorstore.similarity_search("ì¿¼ë¦¬", k=5)

# 2. ìœ ì‚¬ë„ ì ìˆ˜ ì„ê³„ê°’
results = vectorstore.similarity_search_with_relevance_scores(
    "ì¿¼ë¦¬",
    k=5,
    score_threshold=0.7  # 0.7 ì´ìƒë§Œ ë°˜í™˜
)

# 3. MMR (ë‹¤ì–‘ì„± ê³ ë ¤)
results = vectorstore.max_marginal_relevance_search(
    "ì¿¼ë¦¬",
    k=5,
    fetch_k=20,
    lambda_mult=0.5
)

# 4. ë©”íƒ€ë°ì´í„° í•„í„°ë§
results = vectorstore.similarity_search(
    "ì¿¼ë¦¬",
    k=5,
    filter={"department": "engineering", "year": 2024}
)
```

#### Retrieverë¡œ ë³€í™˜

```python
# Vector Storeë¥¼ Retrieverë¡œ ë³€í™˜
retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 5}
)

# MMR Retriever
mmr_retriever = vectorstore.as_retriever(
    search_type="mmr",
    search_kwargs={"k": 5, "fetch_k": 20, "lambda_mult": 0.5}
)

# ìœ ì‚¬ë„ ì„ê³„ê°’ Retriever
threshold_retriever = vectorstore.as_retriever(
    search_type="similarity_score_threshold",
    search_kwargs={"score_threshold": 0.7, "k": 5}
)

# Retriever ì‚¬ìš©
docs = retriever.invoke("ì¿¼ë¦¬")
```

> ğŸ’» **ì˜ˆì œ ì½”ë“œ**: [02_vector_store.py](../src/part08_rag_mcp/02_vector_store.py)

---

## 3. Agentic RAG

Agentic RAGëŠ” Agentê°€ ê²€ìƒ‰ ì „ëµì„ ìŠ¤ìŠ¤ë¡œ ê²°ì •í•˜ëŠ” ê³ ê¸‰ RAG íŒ¨í„´ì…ë‹ˆë‹¤.

### 3.1 Self-RAG (ìê¸° ê²€ì¦ RAG)

Self-RAGëŠ” Agentê°€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìŠ¤ìŠ¤ë¡œ í‰ê°€í•˜ê³  í•„ìš”ì‹œ ì¬ê²€ìƒ‰í•˜ëŠ” íŒ¨í„´ì…ë‹ˆë‹¤.

```mermaid
flowchart TD
    query[ì‚¬ìš©ì ì§ˆë¬¸]
    retrieve1[1ì°¨ ê²€ìƒ‰]
    evaluate{ê²€ìƒ‰ ê²°ê³¼<br/>ì¶©ë¶„í•œê°€?}
    refine[ì¿¼ë¦¬ ê°œì„ ]
    retrieve2[2ì°¨ ê²€ìƒ‰]
    generate[ë‹µë³€ ìƒì„±]
    verify{ë‹µë³€ì´<br/>ì •í™•í•œê°€?}
    response[ìµœì¢… ì‘ë‹µ]

    query --> retrieve1
    retrieve1 --> evaluate
    evaluate -->|ì˜ˆ| generate
    evaluate -->|ì•„ë‹ˆì˜¤| refine
    refine --> retrieve2
    retrieve2 --> generate
    generate --> verify
    verify -->|ì˜ˆ| response
    verify -->|ì•„ë‹ˆì˜¤| refine
```

#### Self-RAG êµ¬í˜„

```python
from langchain.agents import create_agent
from langchain.tools import tool

# ê²€ìƒ‰ ë„êµ¬
@tool
def search_docs(query: str) -> str:
    """ë¬¸ì„œì—ì„œ ì •ë³´ ê²€ìƒ‰"""
    docs = vectorstore.similarity_search(query, k=5)
    return "\n".join([d.page_content for d in docs])

# ê²€ìƒ‰ ê²°ê³¼ í‰ê°€ ë„êµ¬
@tool
def evaluate_relevance(query: str, context: str) -> str:
    """ê²€ìƒ‰ ê²°ê³¼ì˜ ê´€ë ¨ì„± í‰ê°€"""
    # LLMì„ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ì„± í‰ê°€
    prompt = f"""
    ì§ˆë¬¸: {query}
    ê²€ìƒ‰ ê²°ê³¼: {context}

    ì´ ê²€ìƒ‰ ê²°ê³¼ê°€ ì§ˆë¬¸ì— ë‹µí•˜ê¸°ì— ì¶©ë¶„í•œê°€ìš”?
    ì¶©ë¶„í•˜ë©´ 'SUFFICIENT', ë¶€ì¡±í•˜ë©´ 'INSUFFICIENT'ë¥¼ ë°˜í™˜í•˜ì„¸ìš”.
    """
    # ... LLM í˜¸ì¶œ ë¡œì§
    return "SUFFICIENT" or "INSUFFICIENT"

# Self-RAG Agent
agent = create_agent(
    model="gpt-4o-mini",
    tools=[search_docs, evaluate_relevance],
    system_prompt="""
    ë‹¹ì‹ ì€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í‰ê°€í•˜ê³  í•„ìš”ì‹œ ì¬ê²€ìƒ‰í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

    ì‘ì—… ìˆœì„œ:
    1. search_docsë¡œ ë¬¸ì„œ ê²€ìƒ‰
    2. evaluate_relevanceë¡œ ê²€ìƒ‰ ê²°ê³¼ í‰ê°€
    3. ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ ì¿¼ë¦¬ë¥¼ ê°œì„ í•˜ì—¬ ì¬ê²€ìƒ‰
    4. ì¶©ë¶„í•œ ì •ë³´ê°€ ëª¨ì´ë©´ ë‹µë³€ ìƒì„±
    """
)
```

### 3.2 Corrective RAG (êµì • RAG)

Corrective RAGëŠ” ê²€ìƒ‰ ê²°ê³¼ì˜ í’ˆì§ˆì„ ê°œì„ í•˜ê¸° ìœ„í•´ ì—¬ëŸ¬ ì „ëµì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

```python
# 1. ì¿¼ë¦¬ ì¬ì‘ì„±
@tool
def rewrite_query(original_query: str, feedback: str) -> str:
    """ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ê°œì„ í•˜ì—¬ ì¬ì‘ì„±"""
    prompt = f"""
    ì›ë˜ ì§ˆë¬¸: {original_query}
    ì´ì „ ê²€ìƒ‰ í”¼ë“œë°±: {feedback}

    ë” ë‚˜ì€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•´ ì§ˆë¬¸ì„ ì¬ì‘ì„±í•˜ì„¸ìš”.
    """
    # LLMìœ¼ë¡œ ì¿¼ë¦¬ ì¬ì‘ì„±
    return improved_query

# 2. ë‹¤ì¤‘ ì¿¼ë¦¬ ìƒì„±
@tool
def generate_multiple_queries(query: str) -> list[str]:
    """í•˜ë‚˜ì˜ ì§ˆë¬¸ì„ ì—¬ëŸ¬ ê´€ì ì˜ ì¿¼ë¦¬ë¡œ ë³€í™˜"""
    prompt = f"""
    ì§ˆë¬¸: {query}

    ì´ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ í•„ìš”í•œ 3ê°€ì§€ ë‹¤ë¥¸ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”.
    """
    # LLMìœ¼ë¡œ ë‹¤ì¤‘ ì¿¼ë¦¬ ìƒì„±
    return [query1, query2, query3]

# 3. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
@tool
def hybrid_search(query: str) -> str:
    """ë²¡í„° ê²€ìƒ‰ê³¼ í‚¤ì›Œë“œ ê²€ìƒ‰ì„ ê²°í•©"""
    # ë²¡í„° ê²€ìƒ‰
    vector_results = vectorstore.similarity_search(query, k=5)

    # í‚¤ì›Œë“œ ê²€ìƒ‰ (BM25)
    from langchain.retrievers import BM25Retriever
    bm25_retriever = BM25Retriever.from_documents(documents)
    keyword_results = bm25_retriever.invoke(query)

    # ê²°ê³¼ ë³‘í•© ë° ì¬ìˆœìœ„í™”
    combined = merge_and_rerank(vector_results, keyword_results)
    return combined
```

### 3.3 Agentì™€ Retriever í†µí•©

Retrieverë¥¼ Agentì˜ ë„êµ¬ë¡œ í†µí•©í•˜ëŠ” ì—¬ëŸ¬ ë°©ë²•:

#### ë°©ë²• 1: Toolë¡œ ë˜í•‘

```python
from langchain.agents import create_agent
from langchain.tools import tool

@tool
def search_knowledge_base(query: str) -> str:
    """íšŒì‚¬ ì§€ì‹ ë² ì´ìŠ¤ ê²€ìƒ‰"""
    retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
    docs = retriever.invoke(query)
    return "\n\n".join([f"ë¬¸ì„œ {i+1}:\n{d.page_content}" for i, d in enumerate(docs)])

agent = create_agent(
    model="gpt-4o-mini",
    tools=[search_knowledge_base]
)
```

#### ë°©ë²• 2: create_retriever_tool ì‚¬ìš©

```python
from langchain.tools.retriever import create_retriever_tool

retriever = vectorstore.as_retriever()

retriever_tool = create_retriever_tool(
    retriever=retriever,
    name="search_company_docs",
    description="íšŒì‚¬ ë‚´ë¶€ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì •ì±…, í”„ë¡œì„¸ìŠ¤, ê°€ì´ë“œë¼ì¸ì„ ì°¾ì„ ë•Œ ì‚¬ìš©í•˜ì„¸ìš”."
)

agent = create_agent(
    model="gpt-4o-mini",
    tools=[retriever_tool]
)
```

#### ë°©ë²• 3: ì—¬ëŸ¬ Retriever í†µí•©

```python
# ê° ë„ë©”ì¸ë³„ Retriever
hr_retriever = hr_vectorstore.as_retriever()
tech_retriever = tech_vectorstore.as_retriever()
finance_retriever = finance_vectorstore.as_retriever()

# ê°ê° ë„êµ¬ë¡œ ë³€í™˜
hr_tool = create_retriever_tool(
    hr_retriever,
    "search_hr_docs",
    "ì¸ì‚¬ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ (íœ´ê°€, ë³µì§€, ì±„ìš© ë“±)"
)

tech_tool = create_retriever_tool(
    tech_retriever,
    "search_tech_docs",
    "ê¸°ìˆ  ë¬¸ì„œ ê²€ìƒ‰ (ì•„í‚¤í…ì²˜, API, ê°œë°œ ê°€ì´ë“œ ë“±)"
)

finance_tool = create_retriever_tool(
    finance_retriever,
    "search_finance_docs",
    "ì¬ë¬´ ë¬¸ì„œ ê²€ìƒ‰ (ì˜ˆì‚°, ë¹„ìš©, ë³´ê³ ì„œ ë“±)"
)

# Agentê°€ ì ì ˆí•œ Retriever ì„ íƒ
agent = create_agent(
    model="gpt-4o-mini",
    tools=[hr_tool, tech_tool, finance_tool],
    system_prompt="ì§ˆë¬¸ì˜ ë„ë©”ì¸ì— ë§ëŠ” ê²€ìƒ‰ ë„êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”."
)
```

### 3.4 Query Planning (ì¿¼ë¦¬ ê³„íš)

ë³µì¡í•œ ì§ˆë¬¸ì„ ì—¬ëŸ¬ ë‹¨ê³„ì˜ ê²€ìƒ‰ìœ¼ë¡œ ë¶„í•´í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.

```python
@tool
def plan_search_strategy(question: str) -> str:
    """ë³µì¡í•œ ì§ˆë¬¸ì„ ê²€ìƒ‰ ë‹¨ê³„ë¡œ ë¶„í•´"""
    prompt = f"""
    ì§ˆë¬¸: {question}

    ì´ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•œ ê²€ìƒ‰ ê³„íšì„ ì„¸ìš°ì„¸ìš”:
    1. ì–´ë–¤ ì •ë³´ê°€ í•„ìš”í•œê°€?
    2. ì–´ë–¤ ìˆœì„œë¡œ ê²€ìƒ‰í•´ì•¼ í•˜ëŠ”ê°€?
    3. ê° ë‹¨ê³„ì—ì„œ ì–´ë–¤ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•  ê²ƒì¸ê°€?

    JSON í˜•ì‹ìœ¼ë¡œ ê³„íšì„ ë°˜í™˜í•˜ì„¸ìš”.
    """
    # LLMìœ¼ë¡œ ê³„íš ìƒì„±
    return plan_json

# ì˜ˆì‹œ ì§ˆë¬¸: "ìš°ë¦¬ íšŒì‚¬ì˜ 2024ë…„ Q3 ë§¤ì¶œê³¼ ì‘ë…„ ê°™ì€ ê¸°ê°„ì„ ë¹„êµí•˜ë©´?"
# ê³„íš:
# 1. "2024ë…„ Q3 ë§¤ì¶œ" ê²€ìƒ‰
# 2. "2023ë…„ Q3 ë§¤ì¶œ" ê²€ìƒ‰
# 3. ë‘ ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬ ë‹µë³€
```

#### ë‹¨ê³„ë³„ ì‹¤í–‰ Agent

```python
@tool
def execute_search_plan(plan: str) -> str:
    """ê²€ìƒ‰ ê³„íšì„ ë‹¨ê³„ë³„ë¡œ ì‹¤í–‰"""
    import json
    steps = json.loads(plan)

    results = []
    for step in steps["steps"]:
        query = step["query"]
        docs = vectorstore.similarity_search(query, k=3)
        results.append({
            "step": step["step"],
            "query": query,
            "results": [d.page_content for d in docs]
        })

    return json.dumps(results, ensure_ascii=False)

agent = create_agent(
    model="gpt-4o-mini",
    tools=[plan_search_strategy, execute_search_plan, search_docs],
    system_prompt="""
    ë³µì¡í•œ ì§ˆë¬¸ì€ ë‹¤ìŒ ìˆœì„œë¡œ ì²˜ë¦¬í•˜ì„¸ìš”:
    1. plan_search_strategyë¡œ ê²€ìƒ‰ ê³„íš ìˆ˜ë¦½
    2. execute_search_planìœ¼ë¡œ ê³„íš ì‹¤í–‰
    3. ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ë‹µë³€
    """
)
```

> ğŸ’» **ì˜ˆì œ ì½”ë“œ**: [03_agentic_rag.py](../src/part08_rag_mcp/03_agentic_rag.py)

---

## 4. MCP ê¸°ì´ˆ

### 4.1 Model Context Protocolì´ë€?

**Model Context Protocol (MCP)**ëŠ” LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì™¸ë¶€ ë„êµ¬ì™€ ë°ì´í„° ì†ŒìŠ¤ë¥¼ í‘œì¤€í™”ëœ ë°©ì‹ìœ¼ë¡œ ì—°ê²°í•˜ê¸° ìœ„í•œ ì˜¤í”ˆ í”„ë¡œí† ì½œì…ë‹ˆë‹¤.

#### MCPê°€ í•´ê²°í•˜ëŠ” ë¬¸ì œ

**MCP ì´ì „:**
```python
# ê° ì™¸ë¶€ ì„œë¹„ìŠ¤ë§ˆë‹¤ ë‹¤ë¥¸ ì—°ê²° ë°©ì‹
github_client = GitHubAPI(token=github_token)
database_client = DBClient(connection_string=db_url)
filesystem_client = FileSystem(root_path=root)

# ê°ê° ë‹¤ë¥¸ ì¸í„°í˜ì´ìŠ¤
github_data = github_client.get_repos()
db_data = database_client.query("SELECT * FROM users")
files = filesystem_client.list_files()
```

**MCP ì‚¬ìš©:**
```python
# í†µì¼ëœ MCP ì¸í„°í˜ì´ìŠ¤
client = MultiServerMCPClient({
    "github": {"transport": "http", "url": "http://localhost:8001/mcp"},
    "database": {"transport": "http", "url": "http://localhost:8002/mcp"},
    "filesystem": {"transport": "stdio", "command": "python", "args": ["fs_server.py"]}
})

# ëª¨ë“  ë„êµ¬ë¥¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì‚¬ìš©
tools = await client.get_tools()
agent = create_agent("gpt-4o-mini", tools)
```

#### MCPì˜ í•µì‹¬ ê°œë…

| ê°œë… | ì„¤ëª… | ì˜ˆì‹œ |
|------|------|------|
| **Server** | ë„êµ¬ì™€ ë¦¬ì†ŒìŠ¤ë¥¼ ì œê³µí•˜ëŠ” í”„ë¡œì„¸ìŠ¤ | GitHub API ì„œë²„, DB ì¿¼ë¦¬ ì„œë²„ |
| **Client** | ì„œë²„ì— ì—°ê²°í•˜ì—¬ ë„êµ¬ë¥¼ ì‚¬ìš© | LangChain Agent |
| **Transport** | ì„œë²„-í´ë¼ì´ì–¸íŠ¸ í†µì‹  ë°©ì‹ | HTTP, stdio |
| **Tool** | ì‹¤í–‰ ê°€ëŠ¥í•œ í•¨ìˆ˜ | íŒŒì¼ ì½ê¸°, DB ì¿¼ë¦¬ |
| **Resource** | ì½ê¸° ê°€ëŠ¥í•œ ë°ì´í„° | íŒŒì¼ ë‚´ìš©, API ì‘ë‹µ |
| **Prompt** | ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ | ì½”ë“œ ë¦¬ë·°, ìš”ì•½ |

### 4.2 MCP ì•„í‚¤í…ì²˜

```mermaid
flowchart TB
    subgraph "Client Side"
        agent[LangChain Agent]
        mcp_client[MCP Client]
    end

    subgraph "MCP Protocol Layer"
        protocol[MCP Protocol<br/>HTTP / stdio]
    end

    subgraph "Server Side"
        server1[MCP Server 1<br/>GitHub]
        server2[MCP Server 2<br/>Database]
        server3[MCP Server 3<br/>Filesystem]

        tools1[Tools:<br/>create_issue<br/>search_code]
        tools2[Tools:<br/>query_db<br/>insert_data]
        tools3[Tools:<br/>read_file<br/>write_file]

        server1 --> tools1
        server2 --> tools2
        server3 --> tools3
    end

    agent --> mcp_client
    mcp_client <--> protocol
    protocol <--> server1
    protocol <--> server2
    protocol <--> server3
```

### 4.3 ì„œë²„/í´ë¼ì´ì–¸íŠ¸ êµ¬ì¡°

#### ì„œë²„ì˜ ì—­í• 

MCP ì„œë²„ëŠ” ë‹¤ìŒì„ ì œê³µí•©ë‹ˆë‹¤:

1. **Tools**: ì‹¤í–‰ ê°€ëŠ¥í•œ í•¨ìˆ˜
2. **Resources**: ì½ê¸° ê°€ëŠ¥í•œ ë°ì´í„°
3. **Prompts**: ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í…œí”Œë¦¿

```python
# MCP ì„œë²„ ì˜ˆì‹œ (FastMCP ì‚¬ìš©)
from fastmcp import FastMCP

mcp = FastMCP("MyServer")

# Tool ì œê³µ
@mcp.tool()
def calculate(a: int, b: int, operation: str) -> int:
    """ê°„ë‹¨í•œ ê³„ì‚°ê¸°"""
    if operation == "add":
        return a + b
    elif operation == "multiply":
        return a * b
    return 0

# Resource ì œê³µ
@mcp.resource("config://app")
async def get_config():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì • ë°˜í™˜"""
    return {"version": "1.0", "mode": "production"}

# Prompt ì œê³µ
@mcp.prompt()
def code_review_prompt(language: str):
    """ì½”ë“œ ë¦¬ë·° í”„ë¡¬í”„íŠ¸"""
    return f"ë‹¤ìŒ {language} ì½”ë“œë¥¼ ë¦¬ë·°í•˜ì„¸ìš”..."

if __name__ == "__main__":
    mcp.run(transport="http")  # HTTP ì„œë²„ë¡œ ì‹¤í–‰
```

#### í´ë¼ì´ì–¸íŠ¸ì˜ ì—­í• 

MCP í´ë¼ì´ì–¸íŠ¸ëŠ” ì„œë²„ì— ì—°ê²°í•˜ì—¬:

1. ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
2. ë„êµ¬ ì‹¤í–‰ ìš”ì²­
3. ë¦¬ì†ŒìŠ¤ ì½ê¸°
4. í”„ë¡¬í”„íŠ¸ ë¡œë“œ

```python
from langchain_mcp_adapters.client import MultiServerMCPClient

# ì—¬ëŸ¬ MCP ì„œë²„ì— ì—°ê²°
client = MultiServerMCPClient({
    "math": {
        "transport": "stdio",
        "command": "python",
        "args": ["math_server.py"]
    },
    "weather": {
        "transport": "http",
        "url": "http://localhost:8000/mcp"
    }
})

# ëª¨ë“  ì„œë²„ì˜ ë„êµ¬ ê°€ì ¸ì˜¤ê¸°
tools = await client.get_tools()

# Agentì—ì„œ ì‚¬ìš©
agent = create_agent("gpt-4o-mini", tools)
```

#### Transport ë°©ì‹ ë¹„êµ

| Transport | ì„¤ëª… | ì¥ì  | ë‹¨ì  | ì‚¬ìš© ì‚¬ë¡€ |
|-----------|------|------|------|-----------|
| **stdio** | í‘œì¤€ ì…ì¶œë ¥ | ê°„ë‹¨, ë¡œì»¬ | ì›ê²© ë¶ˆê°€ | ë¡œì»¬ ë„êµ¬ |
| **HTTP** | HTTP ìš”ì²­ | ì›ê²© ê°€ëŠ¥, í™•ì¥ì„± | ì„¤ì • ë³µì¡ | í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ |
| **SSE** | Server-Sent Events | ìŠ¤íŠ¸ë¦¬ë° | ë‹¨ë°©í–¥ | ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ |

> ğŸ’» **ì˜ˆì œ ì½”ë“œ**: [04_mcp_client.py](../src/part08_rag_mcp/04_mcp_client.py)

---

## 5. MCP ì„œë²„ êµ¬í˜„

### 5.1 MCP ì„œë²„ ë§Œë“¤ê¸° (FastMCP)

FastMCPë¥¼ ì‚¬ìš©í•˜ë©´ MCP ì„œë²„ë¥¼ ì‰½ê²Œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### ê¸°ë³¸ ì„œë²„ êµ¬ì¡°

```python
from fastmcp import FastMCP

# ì„œë²„ ì´ˆê¸°í™”
mcp = FastMCP("MyServer", description="ë‚˜ë§Œì˜ MCP ì„œë²„")

# Tool ì •ì˜
@mcp.tool()
def greet(name: str) -> str:
    """ì‚¬ìš©ìì—ê²Œ ì¸ì‚¬"""
    return f"ì•ˆë…•í•˜ì„¸ìš”, {name}ë‹˜!"

@mcp.tool()
async def async_operation(data: str) -> str:
    """ë¹„ë™ê¸° ì‘ì—… ì˜ˆì‹œ"""
    await asyncio.sleep(1)
    return f"ì²˜ë¦¬ ì™„ë£Œ: {data}"

# ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    mcp.run(transport="stdio")
```

#### Transport ì„ íƒ

```python
# stdio transport (ë¡œì»¬)
mcp.run(transport="stdio")

# HTTP transport (ì›ê²©)
mcp.run(transport="http", port=8000)

# Streamable HTTP transport (ìŠ¤íŠ¸ë¦¬ë°)
mcp.run(transport="streamable-http", port=8000)
```

### 5.2 Tool ì œê³µí•˜ê¸°

Toolì€ Agentê°€ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

#### ê¸°ë³¸ Tool

```python
@mcp.tool()
def add_numbers(a: int, b: int) -> int:
    """ë‘ ìˆ«ìë¥¼ ë”í•©ë‹ˆë‹¤"""
    return a + b

@mcp.tool()
def search_database(query: str, limit: int = 10) -> list[dict]:
    """ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰"""
    # ì‹¤ì œ DB ê²€ìƒ‰ ë¡œì§
    results = db.query(query).limit(limit).all()
    return [{"id": r.id, "name": r.name} for r in results]
```

#### Tool íƒ€ì… íŒíŒ…

```python
from typing import Literal
from pydantic import BaseModel, Field

class SearchParams(BaseModel):
    query: str = Field(description="ê²€ìƒ‰ ì¿¼ë¦¬")
    category: Literal["tech", "hr", "finance"] = Field(description="ê²€ìƒ‰ ì¹´í…Œê³ ë¦¬")
    limit: int = Field(default=10, ge=1, le=100, description="ê²°ê³¼ ê°œìˆ˜")

@mcp.tool()
def advanced_search(params: SearchParams) -> list[dict]:
    """ê³ ê¸‰ ê²€ìƒ‰ (íƒ€ì… ì•ˆì „)"""
    results = db.search(
        query=params.query,
        category=params.category,
        limit=params.limit
    )
    return results
```

#### ì—ëŸ¬ ì²˜ë¦¬

```python
@mcp.tool()
def safe_divide(a: float, b: float) -> float:
    """ì•ˆì „í•œ ë‚˜ëˆ—ì…ˆ"""
    if b == 0:
        raise ValueError("0ìœ¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    return a / b

@mcp.tool()
async def fetch_with_retry(url: str, max_retries: int = 3) -> str:
    """ì¬ì‹œë„ ë¡œì§ì´ ìˆëŠ” HTTP ìš”ì²­"""
    for attempt in range(max_retries):
        try:
            response = await httpx.get(url, timeout=10.0)
            response.raise_for_status()
            return response.text
        except httpx.HTTPError as e:
            if attempt == max_retries - 1:
                raise
            await asyncio.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
```

### 5.3 Resource ì œê³µí•˜ê¸°

ResourceëŠ” ì½ê¸° ê°€ëŠ¥í•œ ë°ì´í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

```python
# ì •ì  ë¦¬ì†ŒìŠ¤
@mcp.resource("config://database")
def get_db_config():
    """ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •"""
    return {
        "host": "localhost",
        "port": 5432,
        "database": "myapp"
    }

# ë™ì  ë¦¬ì†ŒìŠ¤
@mcp.resource("file://{path}")
async def read_file(path: str) -> str:
    """íŒŒì¼ ì½ê¸°"""
    async with aiofiles.open(path, 'r') as f:
        content = await f.read()
    return content

# ë¦¬ì†ŒìŠ¤ ëª©ë¡
@mcp.resource("list://files")
def list_files() -> list[str]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼ ëª©ë¡"""
    import os
    return os.listdir("./data")
```

### 5.4 ì„œë²„ ì‹¤í–‰ ë° í…ŒìŠ¤íŠ¸

#### ì„œë²„ ì‹¤í–‰

```bash
# stdio transport
python my_mcp_server.py

# HTTP transport
python my_mcp_server.py --transport http --port 8000
```

#### ì„œë²„ í…ŒìŠ¤íŠ¸ (í´ë¼ì´ì–¸íŠ¸ì—ì„œ)

```python
from langchain_mcp_adapters.client import MultiServerMCPClient

# stdio ì„œë²„ ì—°ê²°
client = MultiServerMCPClient({
    "test": {
        "transport": "stdio",
        "command": "python",
        "args": ["my_mcp_server.py"]
    }
})

# ë„êµ¬ ëª©ë¡ í™•ì¸
tools = await client.get_tools()
for tool in tools:
    print(f"Tool: {tool.name}")
    print(f"Description: {tool.description}")
    print(f"Parameters: {tool.args}")

# ë„êµ¬ ì§ì ‘ í˜¸ì¶œ (Agent ì—†ì´ í…ŒìŠ¤íŠ¸)
async with client.session("test") as session:
    from langchain_mcp_adapters.tools import load_mcp_tools
    tools = await load_mcp_tools(session)

    # Tool ì°¾ê¸°
    add_tool = next(t for t in tools if t.name == "add_numbers")

    # ì‹¤í–‰
    result = await add_tool.ainvoke({"a": 5, "b": 3})
    print(f"Result: {result}")
```

### 5.5 ì‹¤ì „ MCP ì„œë²„ ì˜ˆì‹œ

#### íŒŒì¼ ì‹œìŠ¤í…œ ì„œë²„

```python
from fastmcp import FastMCP
import os
import aiofiles

mcp = FastMCP("FileSystem")

@mcp.tool()
async def read_file(path: str) -> str:
    """íŒŒì¼ ì½ê¸°"""
    async with aiofiles.open(path, 'r') as f:
        return await f.read()

@mcp.tool()
async def write_file(path: str, content: str) -> str:
    """íŒŒì¼ ì“°ê¸°"""
    async with aiofiles.open(path, 'w') as f:
        await f.write(content)
    return f"íŒŒì¼ ì €ì¥ ì™„ë£Œ: {path}"

@mcp.tool()
def list_directory(path: str = ".") -> list[str]:
    """ë””ë ‰í† ë¦¬ ëª©ë¡"""
    return os.listdir(path)

@mcp.tool()
def file_info(path: str) -> dict:
    """íŒŒì¼ ì •ë³´"""
    stat = os.stat(path)
    return {
        "size": stat.st_size,
        "created": stat.st_ctime,
        "modified": stat.st_mtime,
        "is_file": os.path.isfile(path),
        "is_directory": os.path.isdir(path)
    }

if __name__ == "__main__":
    mcp.run(transport="stdio")
```

#### ë°ì´í„°ë² ì´ìŠ¤ ì„œë²„

```python
from fastmcp import FastMCP
import sqlite3
from typing import List, Dict, Any

mcp = FastMCP("Database")

# DB ì—°ê²° (ì „ì—­)
conn = sqlite3.connect("app.db")
conn.row_factory = sqlite3.Row

@mcp.tool()
def query_database(sql: str, params: List[Any] = None) -> List[Dict]:
    """SQL ì¿¼ë¦¬ ì‹¤í–‰ (SELECT)"""
    if not sql.strip().upper().startswith("SELECT"):
        raise ValueError("SELECT ì¿¼ë¦¬ë§Œ í—ˆìš©ë©ë‹ˆë‹¤")

    cursor = conn.cursor()
    cursor.execute(sql, params or [])
    rows = cursor.fetchall()
    return [dict(row) for row in rows]

@mcp.tool()
def insert_data(table: str, data: Dict[str, Any]) -> int:
    """ë°ì´í„° ì‚½ì…"""
    columns = ", ".join(data.keys())
    placeholders = ", ".join(["?" for _ in data])
    sql = f"INSERT INTO {table} ({columns}) VALUES ({placeholders})"

    cursor = conn.cursor()
    cursor.execute(sql, list(data.values()))
    conn.commit()
    return cursor.lastrowid

@mcp.tool()
def get_table_schema(table: str) -> List[Dict]:
    """í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì¡°íšŒ"""
    cursor = conn.cursor()
    cursor.execute(f"PRAGMA table_info({table})")
    return [dict(row) for row in cursor.fetchall()]

if __name__ == "__main__":
    mcp.run(transport="http", port=8001)
```

> ğŸ’» **ì˜ˆì œ ì½”ë“œ**: [05_mcp_server.py](../src/part08_rag_mcp/05_mcp_server.py)

---

## 6. Agent MCP í†µí•©

### 6.1 Agentì—ì„œ MCP ì‚¬ìš©

MCP ë„êµ¬ë¥¼ Agentì— í†µí•©í•˜ëŠ” ì „ì²´ í”„ë¡œì„¸ìŠ¤ì…ë‹ˆë‹¤.

#### ê¸°ë³¸ í†µí•©

```python
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain.agents import create_agent

# MCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = MultiServerMCPClient({
    "filesystem": {
        "transport": "stdio",
        "command": "python",
        "args": ["filesystem_server.py"]
    },
    "database": {
        "transport": "http",
        "url": "http://localhost:8001/mcp"
    }
})

# ë„êµ¬ ê°€ì ¸ì˜¤ê¸°
tools = await client.get_tools()

# Agent ìƒì„±
agent = create_agent(
    model="gpt-4o-mini",
    tools=tools,
    system_prompt="ë‹¹ì‹ ì€ íŒŒì¼ ì‹œìŠ¤í…œê³¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤."
)

# Agent ì‹¤í–‰
response = await agent.ainvoke({
    "messages": [{"role": "user", "content": "ë°ì´í„°ë² ì´ìŠ¤ì˜ users í…Œì´ë¸”ì—ì„œ ëª¨ë“  ì‚¬ìš©ìë¥¼ ì¡°íšŒí•˜ê³  ê²°ê³¼ë¥¼ result.txt íŒŒì¼ì— ì €ì¥í•´ì£¼ì„¸ìš”."}]
})
```

### 6.2 ì—¬ëŸ¬ MCP ì„œë²„ ì‚¬ìš©

ì—¬ëŸ¬ MCP ì„œë²„ë¥¼ ë™ì‹œì— ì‚¬ìš©í•˜ì—¬ Agentì˜ ëŠ¥ë ¥ì„ í™•ì¥í•©ë‹ˆë‹¤.

```python
client = MultiServerMCPClient({
    # íŒŒì¼ ì‹œìŠ¤í…œ
    "filesystem": {
        "transport": "stdio",
        "command": "python",
        "args": ["servers/filesystem.py"]
    },

    # ë°ì´í„°ë² ì´ìŠ¤
    "database": {
        "transport": "http",
        "url": "http://localhost:8001/mcp"
    },

    # GitHub API
    "github": {
        "transport": "http",
        "url": "http://localhost:8002/mcp",
        "headers": {
            "Authorization": f"Bearer {github_token}"
        }
    },

    # Slack API
    "slack": {
        "transport": "http",
        "url": "http://localhost:8003/mcp",
        "headers": {
            "Authorization": f"Bearer {slack_token}"
        }
    }
})

# ëª¨ë“  ì„œë²„ì˜ ë„êµ¬ ê°€ì ¸ì˜¤ê¸°
tools = await client.get_tools()

# Agentê°€ í•„ìš”ì— ë”°ë¼ ì ì ˆí•œ ë„êµ¬ ì„ íƒ
agent = create_agent(
    model="gpt-4o-mini",
    tools=tools,
    system_prompt="""
    ë‹¹ì‹ ì€ ë‹¤ì–‘í•œ ì‹œìŠ¤í…œì— ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” í†µí•© ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

    ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œìŠ¤í…œ:
    - íŒŒì¼ ì‹œìŠ¤í…œ: íŒŒì¼ ì½ê¸°/ì“°ê¸°
    - ë°ì´í„°ë² ì´ìŠ¤: ë°ì´í„° ì¡°íšŒ/ì‚½ì…
    - GitHub: ì´ìŠˆ ìƒì„±, ì½”ë“œ ê²€ìƒ‰
    - Slack: ë©”ì‹œì§€ ì „ì†¡, ì±„ë„ ì •ë³´

    ì‚¬ìš©ì ìš”ì²­ì— ê°€ì¥ ì í•©í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.
    """
)
```

### 6.3 MCP Tool ë™ì  ë¡œë”©

ì‹¤í–‰ ì¤‘ì— MCP ë„êµ¬ë¥¼ ë™ì ìœ¼ë¡œ ë¡œë“œí•˜ê³  ì œê±°í•©ë‹ˆë‹¤.

```python
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_mcp_adapters.tools import load_mcp_tools

# ì„¸ì…˜ ê¸°ë°˜ ë„êµ¬ ë¡œë”©
async def create_agent_with_mcp(server_configs: dict):
    """ì„¤ì •ì— ë”°ë¼ ë™ì ìœ¼ë¡œ Agent ìƒì„±"""
    client = MultiServerMCPClient(server_configs)

    async with client.session("server_name") as session:
        # íŠ¹ì • ì„œë²„ì˜ ë„êµ¬ë§Œ ë¡œë“œ
        tools = await load_mcp_tools(session)

        agent = create_agent(
            model="gpt-4o-mini",
            tools=tools
        )

        return agent

# ì¡°ê±´ë¶€ ë„êµ¬ ë¡œë”©
async def load_tools_by_permission(user_role: str):
    """ì‚¬ìš©ì ê¶Œí•œì— ë”°ë¼ ë„êµ¬ ë¡œë“œ"""
    base_config = {
        "readonly": {
            "transport": "stdio",
            "command": "python",
            "args": ["readonly_server.py"]
        }
    }

    if user_role == "admin":
        base_config["admin"] = {
            "transport": "stdio",
            "command": "python",
            "args": ["admin_server.py"]
        }

    client = MultiServerMCPClient(base_config)
    tools = await client.get_tools()
    return tools
```

### 6.4 Error Handling ë° ì¬ì‹œë„

MCP ë„êµ¬ í˜¸ì¶œ ì‹œ ì—ëŸ¬ë¥¼ ì²˜ë¦¬í•˜ê³  ì¬ì‹œë„í•©ë‹ˆë‹¤.

```python
from langchain_mcp_adapters.interceptors import MCPToolCallRequest

# ì¬ì‹œë„ ì¸í„°ì…‰í„°
async def retry_interceptor(
    request: MCPToolCallRequest,
    handler,
    max_retries: int = 3
):
    """ì‹¤íŒ¨í•œ ë„êµ¬ í˜¸ì¶œì„ ì¬ì‹œë„"""
    last_error = None

    for attempt in range(max_retries):
        try:
            return await handler(request)
        except Exception as e:
            last_error = e
            if attempt < max_retries - 1:
                print(f"ë„êµ¬ '{request.name}' ì‹¤íŒ¨, ì¬ì‹œë„ ì¤‘... ({attempt + 1}/{max_retries})")
                await asyncio.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„

    raise last_error

# ë¡œê¹… ì¸í„°ì…‰í„°
async def logging_interceptor(
    request: MCPToolCallRequest,
    handler
):
    """ë„êµ¬ í˜¸ì¶œì„ ë¡œê¹…"""
    print(f"[MCP] ë„êµ¬ í˜¸ì¶œ: {request.name}")
    print(f"[MCP] ì¸ì: {request.args}")

    try:
        result = await handler(request)
        print(f"[MCP] ê²°ê³¼: {str(result)[:100]}...")
        return result
    except Exception as e:
        print(f"[MCP] ì—ëŸ¬: {str(e)}")
        raise

# ì¸í„°ì…‰í„° ì ìš©
client = MultiServerMCPClient(
    server_configs,
    tool_interceptors=[logging_interceptor, retry_interceptor]
)
```

### 6.5 ì‹¤ì „ íŒ¨í„´: RAG + MCP í†µí•©

RAGì™€ MCPë¥¼ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” ì‹¤ì „ íŒ¨í„´ì…ë‹ˆë‹¤.

```python
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain.agents import create_agent
from langchain.tools import tool

# 1. RAG ì„¤ì •
vectorstore = FAISS.from_texts(
    ["ë¬¸ì„œ1", "ë¬¸ì„œ2", "ë¬¸ì„œ3"],
    OpenAIEmbeddings()
)

@tool
def search_knowledge_base(query: str) -> str:
    """ë‚´ë¶€ ì§€ì‹ ë² ì´ìŠ¤ ê²€ìƒ‰"""
    docs = vectorstore.similarity_search(query, k=3)
    return "\n".join([d.page_content for d in docs])

# 2. MCP ì„¤ì •
mcp_client = MultiServerMCPClient({
    "database": {
        "transport": "http",
        "url": "http://localhost:8001/mcp"
    },
    "api": {
        "transport": "http",
        "url": "http://localhost:8002/mcp"
    }
})

mcp_tools = await mcp_client.get_tools()

# 3. RAG + MCP ë„êµ¬ í†µí•©
all_tools = [search_knowledge_base] + mcp_tools

# 4. í†µí•© Agent
agent = create_agent(
    model="gpt-4o-mini",
    tools=all_tools,
    system_prompt="""
    ë‹¹ì‹ ì€ ë‚´ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì™€ ì™¸ë¶€ ì‹œìŠ¤í…œì— ëª¨ë‘ ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

    ì‘ì—… ìˆœì„œ:
    1. ë¨¼ì € search_knowledge_baseë¡œ ë‚´ë¶€ ë¬¸ì„œ ê²€ìƒ‰
    2. ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ database ë„êµ¬ë¡œ ì‹¤ì‹œê°„ ë°ì´í„° ì¡°íšŒ
    3. í•„ìš”ì‹œ api ë„êµ¬ë¡œ ì™¸ë¶€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    4. ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì •í™•í•œ ë‹µë³€ ì œê³µ
    """
)

# 5. ì‹¤í–‰
response = await agent.ainvoke({
    "messages": [{"role": "user", "content": "ìµœì‹  ì‚¬ìš©ì í†µê³„ì™€ ê´€ë ¨ ì •ì±…ì„ ì•Œë ¤ì£¼ì„¸ìš”."}]
})

# Agent ë™ì‘:
# 1. search_knowledge_base("ì‚¬ìš©ì ì •ì±…") â†’ ë‚´ë¶€ ë¬¸ì„œ ê²€ìƒ‰
# 2. query_database("SELECT COUNT(*) FROM users WHERE created_at > ...") â†’ ì‹¤ì‹œê°„ í†µê³„
# 3. ë‘ ì •ë³´ë¥¼ ê²°í•©í•˜ì—¬ ë‹µë³€
```

> ğŸ’» **ì˜ˆì œ ì½”ë“œ**: [06_mcp_agent.py](../src/part08_rag_mcp/06_mcp_agent.py)

---

## ğŸ“ ì‹¤ìŠµ ê³¼ì œ

### ê³¼ì œ 1: ê¸°ìˆ  ë¬¸ì„œ Q&A (Vector Store RAG) (â­â­â­)

**ëª©í‘œ**: ë¬¸ì„œë¥¼ Vector Storeì— ì €ì¥í•˜ê³  ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ê¸°ë³¸ RAG ì‹œìŠ¤í…œ êµ¬í˜„

**ìš”êµ¬ì‚¬í•­**:
1. ë¬¸ì„œë¥¼ Vector Storeì— ì €ì¥
2. ìœ ì‚¬ë„ ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°
3. ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìƒì„±

**íŒíŠ¸**:
```python
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter

# ë¬¸ì„œ ì¤€ë¹„
docs = [Document(page_content="..."), ...]

# ì²­í‚¹
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
chunks = splitter.split_documents(docs)

# Vector Store
vectorstore = FAISS.from_documents(chunks, OpenAIEmbeddings())

# ìœ ì‚¬ë„ ê²€ìƒ‰
results = vectorstore.similarity_search("ì¿¼ë¦¬", k=3)
```

**í‰ê°€ ê¸°ì¤€**:
- [ ] ë¬¸ì„œ ë¡œë“œ ë° ì²­í‚¹ ì˜¬ë°”ë¥´ê²Œ êµ¬í˜„
- [ ] Vector Store ì •ìƒ ì‘ë™
- [ ] ê²€ìƒ‰ í’ˆì§ˆ (ê´€ë ¨ ë¬¸ì„œ ì •í™•íˆ ì°¾ê¸°)
- [ ] Context ê¸°ë°˜ ë‹µë³€ ìƒì„± í’ˆì§ˆ

**í•´ë‹µ**: [solutions/exercise_01.py](../src/part08_rag_mcp/solutions/exercise_01.py)

---

### ê³¼ì œ 2: ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ Agent (Agentic RAG) (â­â­â­â­)

**ëª©í‘œ**: Agentê°€ í•„ìš”ì‹œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ììœ¨ì ìœ¼ë¡œ ì •ë³´ë¥¼ íƒìƒ‰í•˜ëŠ” Agentic RAG ì‹œìŠ¤í…œ êµ¬í˜„

**ìš”êµ¬ì‚¬í•­**:
1. Agentê°€ í•„ìš”ì‹œ ë¬¸ì„œ ê²€ìƒ‰
2. ê²€ìƒ‰ ë„êµ¬ì™€ LLM í†µí•©
3. ììœ¨ì ì¸ ì •ë³´ íƒìƒ‰

**íŒíŠ¸**:
```python
from langchain_core.tools import tool
from langgraph.prebuilt import create_react_agent

@tool
def search_documentation(query: str) -> str:
    """ë¬¸ì„œ ê²€ìƒ‰"""
    vectorstore = get_vectorstore()
    results = vectorstore.similarity_search(query, k=2)
    return "\n\n".join([doc.page_content for doc in results])

@tool
def get_example_code(topic: str) -> str:
    """ì˜ˆì œ ì½”ë“œ ì œê³µ"""
    # ì£¼ì œë³„ ì˜ˆì œ ì½”ë“œ ë°˜í™˜

# Agentì— ë„êµ¬ ì œê³µ
model = ChatOpenAI(model="gpt-4o-mini")
agent = create_react_agent(model, [search_documentation, get_example_code])
```

**í‰ê°€ ê¸°ì¤€**:
- [ ] Agentê°€ í•„ìš” ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ì—¬ ê²€ìƒ‰
- [ ] ê²€ìƒ‰ ë„êµ¬ì™€ LLMì˜ ìì—°ìŠ¤ëŸ¬ìš´ í†µí•©
- [ ] ë³µì¡í•œ ì§ˆë¬¸ì— ëŒ€í•œ ììœ¨ì  ì •ë³´ íƒìƒ‰
- [ ] ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ì˜ ì •í™•í•œ ë‹µë³€

**í•´ë‹µ**: [solutions/exercise_02.py](../src/part08_rag_mcp/solutions/exercise_02.py)

---

### ê³¼ì œ 3: MCP ê¸°ë°˜ í†µí•© ì‹œìŠ¤í…œ (â­â­â­â­)

**ëª©í‘œ**: MCP íŒ¨í„´ì„ ì´í•´í•˜ê³  ì™¸ë¶€ ë„êµ¬ë¥¼ í†µí•©í•˜ëŠ” Agent ì‹œìŠ¤í…œ êµ¬ì¶•

**ìš”êµ¬ì‚¬í•­**:
1. MCP(Model Context Protocol) ê°œë… ì´í•´
2. ì™¸ë¶€ ë„êµ¬ í†µí•© ì‹œë®¬ë ˆì´ì…˜ (íŒŒì¼ì‹œìŠ¤í…œ, DB, API ë“±)
3. í†µí•© Agent ì‹œìŠ¤í…œ êµ¬ì¶•

**íŒíŠ¸**:
```python
from langchain_core.tools import tool
from langgraph.prebuilt import create_react_agent

# MCP ë„êµ¬ ì‹œë®¬ë ˆì´ì…˜
@tool
def filesystem_read(path: str) -> str:
    """íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ íŒŒì¼ì„ ì½ìŠµë‹ˆë‹¤"""
    # ...

@tool
def database_query(sql: str) -> str:
    """ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤"""
    # ...

@tool
def api_call(endpoint: str, method: str = "GET") -> str:
    """ì™¸ë¶€ APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤"""
    # ...

# í†µí•© Agent
model = ChatOpenAI(model="gpt-4o-mini")
agent = create_react_agent(model, [filesystem_read, database_query, api_call])
```

**í‰ê°€ ê¸°ì¤€**:
- [ ] ë‹¤ì–‘í•œ ì™¸ë¶€ ë„êµ¬ ì‹œë®¬ë ˆì´ì…˜ êµ¬í˜„
- [ ] Agentê°€ ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì—¬ ì‚¬ìš©
- [ ] ì—¬ëŸ¬ ë„êµ¬ë¥¼ ì¡°í•©í•œ ë³µì¡í•œ ì‘ì—… ìˆ˜í–‰
- [ ] ì—ëŸ¬ ì²˜ë¦¬ êµ¬í˜„

**í•´ë‹µ**: [solutions/exercise_03.py](../src/part08_rag_mcp/solutions/exercise_03.py)

---

## ğŸ’¡ ì‹¤ì „ íŒ

### íŒ 1: ì²­í‚¹ ì „ëµ ìµœì í™”

```python
# âŒ ë‚˜ìœ ì˜ˆ: ë„ˆë¬´ ì‘ì€ ì²­í¬
splitter = RecursiveCharacterTextSplitter(chunk_size=100)
# ë¬¸ì œ: ë¬¸ë§¥ ì†ì‹¤, ê²€ìƒ‰ í’ˆì§ˆ ì €í•˜

# âœ… ì¢‹ì€ ì˜ˆ: ì ì ˆí•œ í¬ê¸°ì™€ ê²¹ì¹¨
splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,     # í•œ ë¬¸ë‹¨ ì •ë„
    chunk_overlap=200    # ë¬¸ë§¥ ìœ ì§€
)
```

**ìµœì  ì²­í¬ í¬ê¸° ì°¾ê¸°**:
1. ë¬¸ì„œ íƒ€ì…ì— ë”°ë¼ ì¡°ì • (FAQ: 200-500, ê¸°ìˆ  ë¬¸ì„œ: 1000-2000)
2. ì‹¤í—˜ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ì—¬ ê²€ìƒ‰ í’ˆì§ˆ ì¸¡ì •
3. LLMì˜ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ê³ ë ¤

### íŒ 2: Hybrid ê²€ìƒ‰ ì‚¬ìš©

```python
# ë²¡í„° ê²€ìƒ‰ + í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°í•©
from langchain.retrievers import BM25Retriever, EnsembleRetriever

# ë²¡í„° ê²€ìƒ‰
vector_retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

# í‚¤ì›Œë“œ ê²€ìƒ‰
bm25_retriever = BM25Retriever.from_documents(documents)
bm25_retriever.k = 5

# ì•™ìƒë¸”
ensemble_retriever = EnsembleRetriever(
    retrievers=[vector_retriever, bm25_retriever],
    weights=[0.5, 0.5]  # ë™ì¼ ê°€ì¤‘ì¹˜
)
```

### íŒ 3: MCP ì„œë²„ ì¬ì‚¬ìš©

```python
# ì—¬ëŸ¬ Agentì—ì„œ ë™ì¼í•œ MCP ì„œë²„ ì¬ì‚¬ìš©
class MCPManager:
    def __init__(self):
        self.client = MultiServerMCPClient({...})
        self._tools_cache = None

    async def get_tools(self):
        if not self._tools_cache:
            self._tools_cache = await self.client.get_tools()
        return self._tools_cache

# ì „ì—­ ë§¤ë‹ˆì €
mcp_manager = MCPManager()

# Agent 1
agent1 = create_agent("gpt-4o-mini", await mcp_manager.get_tools())

# Agent 2 (ê°™ì€ ë„êµ¬ ì¬ì‚¬ìš©)
agent2 = create_agent("gpt-4o-mini", await mcp_manager.get_tools())
```

### íŒ 4: Embedding ë¹„ìš© ì ˆê°

```python
# ìºì‹±ìœ¼ë¡œ ì¤‘ë³µ ì„ë² ë”© ë°©ì§€
from langchain.embeddings import CacheBackedEmbeddings
from langchain.storage import LocalFileStore

cache = LocalFileStore("./embedding_cache")
embeddings = CacheBackedEmbeddings.from_bytes_store(
    underlying_embeddings=OpenAIEmbeddings(),
    document_embedding_cache=cache
)

# ê°™ì€ í…ìŠ¤íŠ¸ëŠ” ìºì‹œì—ì„œ ë¡œë“œ (API ë¹„ìš© 0)
```

### íŒ 5: ë©”íƒ€ë°ì´í„° í™œìš©

```python
# ë©”íƒ€ë°ì´í„°ë¡œ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ
documents = [
    Document(
        page_content="...",
        metadata={
            "source": "manual.pdf",
            "page": 5,
            "section": "authentication",
            "date": "2024-01-01",
            "author": "John Doe"
        }
    )
]

# í•„í„°ë§ ê²€ìƒ‰
results = vectorstore.similarity_search(
    "ë¡œê·¸ì¸ ë°©ë²•",
    filter={"section": "authentication"}  # ì¸ì¦ ì„¹ì…˜ë§Œ ê²€ìƒ‰
)
```

---

## â“ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸

<details>
<summary><strong>Q1: RAG vs Fine-tuning ì–¸ì œ ì‚¬ìš©í•˜ë‚˜ìš”?</strong></summary>

- **RAG ì‚¬ìš©**: ë°ì´í„°ê°€ ìì£¼ ë³€ê²½ë˜ê±°ë‚˜, ìµœì‹  ì •ë³´ í•„ìš”, ì¶œì²˜ ì¶”ì  í•„ìš”
- **Fine-tuning ì‚¬ìš©**: íŠ¹ì • ìŠ¤íƒ€ì¼/í†¤ í•™ìŠµ, ë„ë©”ì¸ íŠ¹í™” ì–¸ì–´, ê³ ì •ëœ ì§€ì‹

ëŒ€ë¶€ë¶„ì˜ ê²½ìš° RAGê°€ ë” ì í•©í•©ë‹ˆë‹¤. ë¹„ìš©ì´ ë‚®ê³  ì—…ë°ì´íŠ¸ê°€ ì‰½ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

</details>

<details>
<summary><strong>Q2: Vector Store ì–´ë–¤ ê²ƒì„ ì„ íƒí•˜ë‚˜ìš”?</strong></summary>

- **í”„ë¡œí† íƒ€ì…/ê°œë°œ**: FAISS (ë¬´ë£Œ, ë¹ ë¦„)
- **ì¤‘ì†Œê·œëª¨ í”„ë¡œë•ì…˜**: Chroma (ê´€ë¦¬ ì‰¬ì›€)
- **ëŒ€ê·œëª¨ í”„ë¡œë•ì…˜**: Pinecone, Weaviate (í™•ì¥ì„±)
- **ì˜¨í”„ë ˆë¯¸ìŠ¤ í•„ìš”**: Qdrant, Weaviate

</details>

<details>
<summary><strong>Q3: MCP vs ì¼ë°˜ API í˜¸ì¶œì˜ ì°¨ì´ëŠ”?</strong></summary>

**MCP ì¥ì **:
- í‘œì¤€í™”ëœ ì¸í„°í˜ì´ìŠ¤
- ë„êµ¬ ë©”íƒ€ë°ì´í„° ìë™ ì œê³µ
- ì—¬ëŸ¬ ì„œë²„ í†µí•© ê´€ë¦¬
- ë²„ì „ ê´€ë¦¬ ë° ìŠ¤í‚¤ë§ˆ ê²€ì¦

**ì¼ë°˜ API**:
- ë” ê°„ë‹¨í•œ êµ¬í˜„
- ì™¸ë¶€ ì˜ì¡´ì„± ì—†ìŒ

ë³µì¡í•œ ì‹œìŠ¤í…œì€ MCP, ê°„ë‹¨í•œ í†µí•©ì€ ì¼ë°˜ API ê¶Œì¥

</details>

<details>
<summary><strong>Q4: ì²­í‚¹ í¬ê¸°ë¥¼ ì–´ë–»ê²Œ ê²°ì •í•˜ë‚˜ìš”?</strong></summary>

1. **ë¬¸ì„œ íƒ€ì… ê³ ë ¤**:
   - FAQ, ì§§ì€ ë‹µë³€: 200-500
   - ì¼ë°˜ ë¬¸ì„œ: 1000-1500
   - ê¸´ ê¸°ìˆ  ë¬¸ì„œ: 1500-2000

2. **ì‹¤í—˜ì  ì ‘ê·¼**:
   ```python
   for chunk_size in [500, 1000, 1500, 2000]:
       # ê²€ìƒ‰ í’ˆì§ˆ ì¸¡ì •
       # ìµœì  í¬ê¸° ì„ íƒ
   ```

3. **LLM ì»¨í…ìŠ¤íŠ¸ ê³ ë ¤**: ê²€ìƒ‰ ê²°ê³¼ kê°œ x ì²­í¬ í¬ê¸°ê°€ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°ë¥¼ ë„˜ì§€ ì•Šê²Œ

</details>

<details>
<summary><strong>Q5: RAG ê²€ìƒ‰ í’ˆì§ˆì´ ë‚®ì„ ë•Œ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?</strong></summary>

1. **ì²­í‚¹ ì „ëµ ê°œì„ **: í¬ê¸°, ê²¹ì¹¨ ì¡°ì •
2. **Hybrid ê²€ìƒ‰ ì‚¬ìš©**: ë²¡í„° + í‚¤ì›Œë“œ
3. **ì¿¼ë¦¬ ê°œì„ **: Agentic RAGë¡œ ì¿¼ë¦¬ ì¬ì‘ì„±
4. **Embedding ëª¨ë¸ ë³€ê²½**: ë” ê°•ë ¥í•œ ëª¨ë¸ ì‹œë„
5. **ë©”íƒ€ë°ì´í„° í•„í„°ë§**: ê²€ìƒ‰ ë²”ìœ„ ì¢íˆê¸°
6. **ì¬ìˆœìœ„í™”(Reranking)**: ê²€ìƒ‰ í›„ ê²°ê³¼ ì¬ì •ë ¬

</details>

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

ì´ íŒŒíŠ¸ë¥¼ ì™„ë£Œí–ˆë‹¤ë©´ ë‹¤ìŒì„ í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤:

### RAG
- [ ] RAGì˜ ê°œë…ê³¼ ì‘ë™ ì›ë¦¬ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤
- [ ] ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³  ì ì ˆí•˜ê²Œ ì²­í‚¹í•  ìˆ˜ ìˆë‹¤
- [ ] Vector Storeë¥¼ êµ¬ì¶•í•˜ê³  ê²€ìƒ‰í•  ìˆ˜ ìˆë‹¤
- [ ] Retrieverë¥¼ Agentì˜ ë„êµ¬ë¡œ í†µí•©í•  ìˆ˜ ìˆë‹¤
- [ ] Agentic RAG íŒ¨í„´ì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤

### MCP
- [ ] MCPì˜ ê°œë…ê³¼ ì•„í‚¤í…ì²˜ë¥¼ ì´í•´í•œë‹¤
- [ ] FastMCPë¡œ MCP ì„œë²„ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤
- [ ] Tool, Resource, Promptë¥¼ ì œê³µí•  ìˆ˜ ìˆë‹¤
- [ ] MCP í´ë¼ì´ì–¸íŠ¸ë¡œ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ìˆë‹¤
- [ ] Agentì™€ MCPë¥¼ í†µí•©í•  ìˆ˜ ìˆë‹¤

### í†µí•©
- [ ] RAGì™€ MCPë¥¼ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” ì‹œìŠ¤í…œì„ ì„¤ê³„í•  ìˆ˜ ìˆë‹¤
- [ ] ì—¬ëŸ¬ MCP ì„œë²„ë¥¼ ê´€ë¦¬í•  ìˆ˜ ìˆë‹¤
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§ì„ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤

---

## ğŸ”— ë‹¤ìŒ ë‹¨ê³„

âœ… Part 8 ì™„ë£Œ!
â¡ï¸ [Part 9: Productionìœ¼ë¡œ ì´ë™](./part09_production.md)

**í•™ìŠµ ì§„ë„**: â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘ 80% (Part 8/10 ì™„ë£Œ)

---

## ğŸ”— ì‹¬í™” í•™ìŠµ

### ê³µì‹ ë¬¸ì„œ
- [LangChain Retrieval ê°€ì´ë“œ](https://docs.langchain.com/oss/python/langchain/rag)
- [Model Context Protocol ê³µì‹ ì‚¬ì´íŠ¸](https://modelcontextprotocol.io/)
- [FastMCP ë¬¸ì„œ](https://github.com/jlowin/fastmcp)

### ê³ ê¸‰ ì£¼ì œ
- **RAG ìµœì í™”**: Reranking, Query Expansion, Hybrid Search
- **MCP ê³ ê¸‰**: Interceptors, Callbacks, Stateful Sessions
- **í”„ë¡œë•ì…˜**: ìºì‹±, ëª¨ë‹ˆí„°ë§, ì—ëŸ¬ ë³µêµ¬

### ì‹¤ì „ ì˜ˆì œ
- ê¸°ì—… ë¬¸ì„œ Q&A ì‹œìŠ¤í…œ
- ì½”ë“œë² ì´ìŠ¤ ê²€ìƒ‰ ë° ë¶„ì„
- ê³ ê° ì§€ì› ì±—ë´‡
- í†µí•© ê°œë°œ í™˜ê²½ Agent

---

*ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: 2026-02-18*
