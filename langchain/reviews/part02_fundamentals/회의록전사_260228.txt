새로운 녹음 41
2026.02.28 토 오전 11:47 ・ 84분 45초
송태영


참석자 1 00:00
들어서 시작을 해볼까요? 우선은 저거부터 드릴게요.
일단 갈무리부터 빠르게 할게요. 한 번 근데 이게 빠르게 하는 거라 내용이 많고 그래도 한 번 보고 오시는 게 좋을 것 같긴 해요.
그래서 이제 빠르게 갈무리 드리고 코드도 빠르게 갈무리를 하고 빠르다는 일에 너무 강조를 많이 하네.
일단은 이제 우리가 이제 파트 2 첫 번째죠. 이게 그래서 이제 기본적으로 파트 1에서는 이제 랭체인 랭그래f 딥 에이전트의 어떤 서로 상호 간의 갭이라든가 이게 뭔지에 대한 설명을 드렸고 이제 랭체인에서 본격적으로 이제 랭체인에 대한 설명이 나오는데 특히 이제 여기서는 기본적인 핵심 요소가 나오고 있어요.
근데 이제 그 랭체인이 사실은 1.0 버전이 나오면서 좀 많이 바뀌었더라고요.
이것저것 근데 그 본격적인 1.0에 대한 개념 이 이제 아직은 이제 뒤에서 차차 나오는데 잠깐만요.

참석자 1 01:10
이게 왜 이렇게 돼 있지 그걸 보여드리려고 했던 건데 아 이거구나 그래서 이제 뒤에 뒤에 쭉 나오죠.
미드웨어 특히 미드웨어 이런 거 되게 생소하더라고요.
이번에 보니까 그래서 뭐 이런 1.0에 대한 내용은 뒤에 나오고 이제 그전에 이제 앞선 부분에 대한 어떤 압축 같은 것들이라고 제가 느끼기엔 그랬어요.
이 기초 단계 이 파트 2 3 부분이 그래서 1.0 이전의 내용들과 그런 다음에 본격적인 이제 1.0에 바뀐 내용이라든가 좀 고급 기술들이 이어지는 어 그래서 따라서 이 부분은 랭체인 기초는 제일 기본적인 내용이라서 이걸 모르면 뒤에가 어려워지는 거죠.
근데 그만큼 또 쉽기도 해요. 그렇게 어렵진 않더라고요.
근데 이제 문제는 이제 내용 자체 구성은 그렇게 해놨는데 그 난이도도 이 두 개 별 2개라고 돼 있긴 한데 이게 설명드리겠지만 좀 현재 완성된 교환은 좀 과하게 어려운 부분이 갑자기 그 난이도가 퀀텀 점프한 부분이 있어요.
그 얘기를 이따 드릴 거고요.

참석자 1 02:19
기본적으로 이제 이거를 이 교환에서 전달하고자 하는 내용은 요 니트 이니트 챗 모델 이거를 사용해서 이제 기본적인 LLM 모델을 만드는 거랑 그리고 메시징이 이제 여러 가지가 있죠.
뭐 시스템 휴먼 AI 툴 메시지 이렇게 해서 역할 이거에 대한 설명 이걸 알아야 이제 기본적으로 렌체인이 어떻게 메시지를 만드는지를 알 수 있고 그리고 툴 콜을 하는데 이 툴 데코레이터를 써가지고 기본 도구를 만들거든요.
이 방법 그리고 그때 툴이 어떤 형식을 인풋 아웃풋으로 받는 아규먼트에 대해서 타입을 좀 강제할 수 있는 타입을 lam한테 알려주는 목적과 뭔가 틀렸을 때 거기에 대해서 에러 밸리데이션 할 수 있는 그런 목적을 가지고 이제 파이덴틱 스키마를 쓰거든요.

참석자 1 03:09
거기에 대한 설명 여기까진 괜찮아 괜찮은가 기초 치고 약간 여기까지도 약간 높은 것 같은데 이제 이게 이제 뒤에 이제 툴 런 타임이라는 게 나와요.
여기 이것도 생소하더라고요. 이게 아마 예전엔 못 봤던 건데 그 툴 런 타임이라는 게 나오면서 이 에이전트의 상태를 툴 내에서 알 수가 있어요.
그런 기능 그래서 유용해 보이는데 여기에 맞는지는 조금 아리까리했고 그리고 툴 콜에 대한 이 호출에 대한 원리와 도구 선택하는 거 이거는 괜찮았던 것 같아요.
그래서 근데 이 위치가 여기가 맞나 싶긴 해요. 툴 얘기를 한참 한 다음에 갑자기 여기서 다시 나오니까 하여튼 좀 그렇다 요 위치가 제 인상평은 그랬고 아무튼 그래서 시작하면 이제 빠르게 훅훅 가보면 랭체인 에이전트를 호출하는 핵심 구성하는 핵심인 챗 모델 메시지 툴에 대한 어떻게 보면 이게 솔직히 말하면 이것만 알아도 그 에이전트를 만들 수가 있거든요.
기본적인 거는 그래서 조금 고도화된 것까지 만들 수 있어요.

참석자 1 04:10
그래서 어떻게 보면 이 전체 교환에 있어서 거의 거의 액기스가 아닌가 가장 중요한 부분이 아닌가 싶은데 그래서 여기에서 이제 배우려고 하는 게 이 부분이 왜 중요하냐면 이 모델을 이제 다양하게 어떤 프로바이더와 상관없이 모델을 선언을 해가지고 하는 방법 배우고 또 이제 대화를 이제 메시징 객체 클래스를 사용해서 이제 대화를 구성하는 방법 그리고 이제 툴 사용하는 방법 이게 있으면 결국 이제 프로덕션 레벨로 갈 수 있는 어떻게 보면은 핵심이라고 볼 수 있죠.
네 그래서 이제 우선 그래서 한 단계 단계별로 설명을 빠르게 드릴게요.
우선 책 모델은 이렇게 요 랭체인이 모델을 ll 모델을 불러오는데 이 위에 뒤에 부분이 뭐가 됐더라도 이거 기반으로 이제 이게 바뀌더라도 혹은 용도에 따라서 얘를 바꿔가면서 쓸 수 있게 해주는 그게 바로 이제 랭체인의 챗 모델인 거죠.
그래서 이제 표준화된 인터페이스를 갖고 있어요.

참석자 1 05:10
얘네가 이제 기본적으로 러너블이라는 걸 러너블 객체를 상속받아서 만드는 것들인데 이제 그러면 이제 인보이 시스트인 배치와 같은 이런 이게요.
함수로 호출할 수 있어요. 그래서 인버크로 호출하면 그냥 한 방에 실행을 하는 거고 엔드 투 엔드로 스트림은 이제 얘를 이걸로 호출하면은 중간에 청크를 받아서 찍어볼 수가 있어요.
중간중간 결과물을 LNM이 이제 그 결과물을 한 번에 내뱉어서 리턴하는 경우도 있지만 중간 결과물을 리턴하게 함으로 여보세요.
네 송정원 차 네

참석자 2 05:48
죄송합니다.

참석자 1 05:49
중간 결과물을 리턴하게 함으로써 중간 답답함을 덜하게 할 때 이걸 쓰는 거고 배치는 이제 동일한 그런 일을 여러 개의 데이터에 대해서 한 방에 처리할 때 이렇게 하는데 이런 식의 것이 여기 없는 게 어싱크도 빠졌네.
어싱크가 빠졌네요. a 인버크 뭐 이런 게 있는데 a 익스트리밍 어싱크 기능까지 해가지고 이런 걸 받을 수 있어 다 쓸 수 있게 해줘요.
근데 툴도 그러니까 이게 실제로는 그러니까 어떤 AI 모델을 호출하는 용도가 아니라 이 안에서 러너블 객체로 상속받은 객체 내에서는 그냥 얘가 그 해당한 함수를 호출해 주는 역할을 한다고 보시면 돼요.
그리고 이제 다양한 프로바이더를 해주고 이렇게 툴 콜 스트럭티드 아웃풋 뭐 여기 파이덴틱이 여기에 해당하는 거예요.
그 멀티 모달 리즈닝 이런 것들을 해결해준다. 그래서 그 이니챗 모델이라는 함수를 제공해서 여기에다가 이렇게 모델을 쓰면 이렇게 인보크로 실행하는 거다라는 거고요.

참석자 1 06:56
프로바이더를 이렇게 막 바꿔가면서 할 수도 있어요.
그래서 이 사실 여기서부터 여기까지는 그냥 다 그냥 종목이거든요.
그러니까 프로바이더 별로 이렇게 할 수 있습니다라는 거고요.
그리고

참석자 3 07:08
캐시라는 함수를 예전에 썼었나요? 그냥 모델을 선언한 다음에 인버커 때렸던 걸로 기억하는데

참석자 1 07:14
네 근데 이번에

참석자 2 07:16
완전히 바뀌었네요.

참석자 1 07:17
네 바뀌었어요. 좀 더 기능이 들어가는 것 같더라고요.
뒤에서 설명이 나오지 않을까요? 그리고 이제 템플라우처 설정이 당연히 가능하죠.
이 안에서 템플라우처를 이제 높이면 좀 더 창의적인 게 나온다 이런 거고 이건 뭐 그렇고 그리고 이제 얘가 이제 파라미터를 이렇게 세팅을 할 수가 있어요.
맥스 토큰이랑 타임아웃이랑 제시도 횟수 그 템플러치 세팅을 이렇게 할 수 있다.
그리고 이게 좀 새로운데 이게 있어요. 그래서 요 이니챗 모델에는 이 베타 버전이긴 한데 모델 프로파일이라는 거를 제공해요.
그래서 사용하고 있는 모델에 대한 이 프로파일을 가져올 수 있거든요.
근데 이게 베타파인이기도 하고 이게 초급에 맞는지는 잘 모르겠어요.
그래서 아무튼 요 밑에부터 설명은 이 이 프로파일에 어떤 것들이 들어 있는가인데 이게 그 사람들이 이 사이트에다가 사이트가 있거든요.

참석자 1 08:24
이 사이트에다가 이제 정리 그러니까 오피셜한 문서가 아니야 그러니까 사람들이 이제 이렇게 여기다가 적어주는 거를 파싱해서 하는 걸로 되어 있거든요.
근데 이게 틀릴 수도 있대요. 왜냐하면 모델 프로바이더가 직접 제공하는 정보가 아니니까 어느 날 바뀔 수도 있잖아요.

참석자 3 08:42
아무튼 모델한테 물어보고 하는 게 아닌

참석자 1 08:45
아니에요. 그 모델이 그런 제공을 하지 않고 사람들이 이제 그거를 이제 어떻게 어떻게 알게 돼서 여기다 적은 거를 가지고 제공하는 거예요.
그래서 틀릴 수도 있다. 누락도 있다 뭐 이런 얘기가 있어서 이게 이 초보 단계에서 이걸

참석자 3 09:01
굉장히 이게 초보 고급 중급 난이도로 정리된 순서가 아니라 기능별로 정리돼 있다 보니까 그런 거 아니에요?

참석자 1 09:10
기능별인데 기능 중에서 이제 단계별로 설명하려고 하다 보니까 초급이라는 이름이 붙을 뿐이지 실제로 초급은 아닌 것 같거든요.
근데 여하튼 이격이 이게 오는 게 맞는지는 잘 모르겠어요.
아무튼 프로

참석자 3 09:24
관련 클래스에 있는 기능들을 쫙 다 설명하는 느낌이네요.

참석자 1 09:28
네 그래서 이거를 좀 고민 저는 고민이에요. 이거 넣을까 뺄까 쫙 다 설명하는 거에 들어가.
근데 이게 사실 뒤에 왜 여기 있냐면 뒤에 멀티 모델 할 때 이걸 갖다 써요.
왜냐하면 멀티 모델 지원 여부를 모델 프로바이더가 프로필 프로필에 그걸 사용해서 그게 이제 트리콜링이나 아니면 모델이 멀티 모델을 할 때 그걸 기반으로 이제 뭐 에러 메시지를 낸다거나 아니면 적절한 모델을 선택한다거나 이런 식의 구현이 가능해지거든요.
그런 용도로 들어간 게 아닌가

참석자 3 10:00
에어 예전에 멀티 모델은 그냥 누가 또 구현해 놓은 거 가져다가 써갖고 그때 했던 것 같은데 테디 노트

참석자 1 10:09
여기 있더라고요. 그 내용이 있는데 랭크에

참석자 3 10:11
근데 그거를 이렇게 그러니까 그냥 하지 않고 프로파일을 가져다가 하게 해놨네.
신기하게

참석자 1 10:18
프로파일은 프로파일은 그냥 멀티 모더를 하기 위한 기능이 있는지 확인하는 용도로만 쓰고요.
실제로 멀티 모더는 또 랭체인 쪽에서 제공해 주는 게 있을 거예요.
그렇죠 혹시 여기까지 의견 있으세요? 리뷰어 두 분 말씀 혹시 의견 있으세요?
아니 다 듣고 얘기하실래요? 아니면 중간중간 말씀하실래요?

참석자 4 10:40
송 책임님 얘기한 것처럼 저는 그거 봤을 때 사실 기능을 초급이다 이런 생각을 안 했어요.
그냥 그냥 얘는 그 세팅에 대한 설명이라고 생각했거든요.
그래서 사실 초고가 고급이라는 느낌으로 접근하지 않았어서 그냥 스퀵했거든요.
사실 저는 그냥 이런 기능도 추가됐구나 이렇게 그냥 하고 말았어서

참석자 1 11:02
그냥 그러면 놔두는 걸로

참석자 4 11:05
저는 저는 상관없는 것 같아요. 사실 그냥 기능에 대한 설명이라서 뭔가 걔를 근데 아까 말씀하신 거 제가 멀티 모델까지 다 못 읽었는데 그런 언급이 조금 있으면 좋을 것 같긴 해요.
어떤 사실 거기서 추가된다는 그런 것들이 좀 있으면 찾아볼 수 있을 것 같긴 하거든요.

참석자 2 11:27
알겠습니다. 지금 피드백은 컨셉 자체는 이렇게 이렇게 되는구나 읽어보면은 딱 그냥 와닿긴 하는데 이제 파이썬 코드들이 있으니까 거기에서부터 이제 이게 따라 하게끔 돼 있잖아요.
네 근데 실제 따라 해 보면은 다 막혀요. 그러니까 예를 들어서 막혀요.
뭐가요? 처음에는 이제 오픈 AI 거를 연결을 했었어.
근데 보니까 이제 오픈 AI 쪽에 API 키를 넣으면 이게 또 API를 쓸 수 있도록 결제를 해놔야 되잖아요.

참석자 1 12:09
근데 그거는 기본적으로 돼 있어야 돼요. 왜냐하면 거의 모든 강의는 다

참석자 2 12:13
그래갖고 그래가지고 이제 저는 또 그걸로 바꿨어.
제미나이로 바꿨어요. 그래서 제미나이 기준으로 또 따라갔는데 하다 보니까 또 뭔가 버전이 안 맞아 그러니까 이 자료가 이제 굉장히 좀 아러브 데이트 돼가지고 1.5 기준으로 돼 있는데 그게 이제 지금은 2.5예요.
그래서 2.5로 바꾸고 또 이제 진행을 하다가 보면 코드가 다 오픈 AI 쪽 아니면은 그런 식으로 연결이 돼 있어가지고 이게 싱크가 좀 안 맞더라고요.
그래서 하다가 뭐 어쨌건 저런 문제가 있구나 뭐 그냥 그 정도까지만 파악이 됐는데 그러면 이게 교환이니까 교환을 만든다는 관점에서는 그거를 흐름을 세 가지를 만들어야 될지 아니면은 그냥 뭐 하나로 딱 픽스해가지고 클로드 코드 아니면은 오픈 AI 이렇게 픽스를 해서 진행을 해야 될지 그런 이거를 만들어 놓는 의도를 정확히 모르겠더라고요.
그래서

참석자 3 13:25
옛날에는 오픈 AI API 무료 제공 같은 게 있었어요.

참석자 2 13:30
무료 제공도

참석자 3 13:32
2년 전 그러니까 이게 처음에 저도 이거 예전에 이거 공부했을 때 보니까 코드가 그러니까 모델이 다 말씀하신 것처럼 옛날 걸로 돼 있어 갖고 모델 수정해서 돌리고 막 그랬었었는데 저도 마찬가지로 재민이 제공량이 무료가 있다 보니까 그렇죠 다 오픈 AI로 되는 거 다 재민이로 다 바꿔갖고 했었거든요.

참석자 1 13:53
응 이게 제가 구글 거를 확인을 못한 게 제가 벤을 먹어도 되기 때문에 하고 싶어도 할 수가 없어 좀 고쳐주셔도 돼요.
여기 제가 확인을 진짜 하고 싶거든요. 안 하고 싶어서 안 한 게 아니야

참석자 3 14:12
이게 이제 풀린 거 아니에요

참석자 1 14:13
이게 API는 안티 그래피티는 풀렸는데 재미나 API는 아이도 맨 상태라 그거를 좀 네 그 리뷰어 님 홍정훈 체임님 이거 좀 해 주셔도 좋아.

참석자 2 14:28
그러면 이게 좀 궁금한 게 뭐냐면 그래서 저는 랭체인의 원본 소스 있잖아요.
그거를 다운 받아서 지금 여기 만들고 있는 거랑 뭔 차이가 있지 이제 그런 비교를 하기 시작했거든요.

참석자 1 14:44
랭체인의 원모크 소스가 뭐예요?

참석자 2 14:46
저기 랭차인 기업에 있는 것들

참석자 1 14:48
그러니까 그게 랭체인에 대한 소스예요 아니면 체인 예제에 대한 소스예요.

참석자 2 14:54
거기 테스트가 있으니까는 그 예제까지 봐도 되지 않을까 뭐 이렇게 생각을 하고 뭔가 이제 좀 더듬더듬 하고 있는 중인데 지금 어쨌건 교환을 이거를 아무것도 없는 상태에서 만든 건 아니잖아요.

참석자 1 15:10
그러니까 오피션 문서를 참고해서 만들긴 했는데 기본적으로 제가 이제 쿼리를 줄 때 이 오피셜 문서의 교환의 내용이 참고되게 코드를 만든 거거든요.
그래서 코드 구성이 기본적으로 이제 챕터별로 돼 있어요.
보시면 방금 우리 챗 모델에 쓰는 챗 모델 있잖아요.
그다음에 메시지 투 베이스 툴 어드벤스 툴 콜리 이렇게 돼 있거든요.
그러니까 이게 딱 맞게 돼 있어요. 그 순서 맞춰서 그래서

참석자 3 15:38
m 채널 홈페이지 그 페이지 안에 해당 페이지 안에 있는 예제 코드 긁어왔고 한 게 아니고 그거를 새로 만든 거예요.

참석자 1 15:47
그러니까 이제 보면 들고 가시면 이렇게 이런 게 있거든요.
이게 지금 지금 보시는 이게 제가 긁어온 거예요. 그 사이트에서 이게 지금 긁어온 마크 다운이거든요.
이걸 참고해서 교환을 만들고 여기에 있는 내용을 참고해서 이제 아까 보시면 요 템플렛이 있잖아요.
이렇게 이걸 기반으로 만든 거예요. 그래서 아예 무관하진 않지만 또 아예 똑같지도 않다.
예를 들어 메시지 같은 경우도 보면 이제 메시지도 이렇게 좀 이따 보시겠지만 이런 식의 코드가 나오거든요.
설명을 이 코드가 나와요. 그래서 일단은 이걸 기반으로 교환을 만들었고 그걸 기반으로 코드가 만들어진 거예요.
그래서 아주 100% 똑같진 않지만 또 100% 다르지 않은 그러니까 유사하게 만들었죠.

참석자 3 16:37
이게 코드는 아마 옛날 버전 기준으로 얘가 학습되는 거랑 짬뽕해서 만

참석자 2 16:43
옛날 버전 기준으로

참석자 3 16:44
설명은 최신 기준으로 설명이 있어 갖고 지금 그게 다를 것 같긴 하네요.

참석자 1 16:50
그 문서 자체가

참석자 3 16:51
작동은 하겠지만

참석자 1 16:52
문서 자체가 또 그렇게 엄청 최신도 아니에요. 물론 최신이기도 있는데 업데이트가 이제 항상 엄청 빠르게 되는 것 같진 않더라고요.

참석자 2 17:02
네 업데이트는 문서는 빠른 것 같진 않아요.

참석자 1 17:06
아무튼 그러다 보니까는 그렇고 그런 부분은 직접 수정해 주셔도 되고 아니면 의견 주시면 이제 그걸 반영해서 하는 것도 괜찮은 것 같아요.

참석자 2 17:14
그건 어떻게 보면 결정에 대한 얘기인데 그러니까 지금 클로드 오픈 AI 저거 뭐야 저기 지금 제미나이 이 세 가지를 병렬로 제공을 할 거냐 아니면 그냥 뭐 하나로 퉁칠 것이냐

참석자 1 17:31
그게 좀 애매하게 돼 있어요. 무슨 얘기냐면 설명 자체는 여기 보시면 다 환경 설정하는 게 앞에 있거든요.
이렇게

참석자 2 17:37
그러니까 앞에는 있는데 뒤에가

참석자 3 17:39
어차피 지금 처음 지금 챕터가 모델을 선언하는 것부터가 시작이니까 지금 다양한 모델에 대해서 쓰면 래퍼가 쓰면은 얘기가 되겠지만 뒤에 가면 이거는 당연히 돼 있을 거라 생각하고 스킵할 거라서 딱 요 챕터만 모델 다른 모델 구현된 거 쓸지 말지만 결정하면 되고 사실 그 뒤는

참석자 1 18:04
근데 근데 구현은 안 어려워요. 그러니까 무슨 얘기냐면 여기에 제가 이렇게 명령하면 되거든 여기 오픈 AI로만 돼 있는 거를 멀티 벤더가 지원하도록 코드를 구현해 줘 이렇게 하면 돼.

참석자 3 18:18
그렇죠 최신 API

참석자 1 18:20
실심을 참고해서 해줘 하면 되기 때문에 어렵진 않아요.

참석자 2 18:25
그 부분이 좀 좀 그러니까 얘기를 하고 싶었고요. 어떻게 할 거냐 논의 좀 하자 그런 거 부분이 있었고 또 또 한 가지는 문서들 보면 이제 pip로 하는 것도 있고 UV로 하는 거

참석자 1 18:43
도쿄 이다 산

참석자 2 18:44
으로만 하는 것도 있고 그

참석자 1 18:45
지금 지금 다 pip로 돼 있지 않아요 여기는 환경 설정이 pip로

참석자 3 18:52
근데 사실 pip를 설치하게 돼 있으면 UV는 앞에 환경 만들 때만 쓰고 pip 똑같이 쓸 수 있어서

참석자 1 18:59
근데 아마 제가 기억은 둘 다 했던 것 같기는 한데 잠깐만 둘 다 만들어 놨을걸요

참석자 2 19:03
섞여 있던 것 같아요.

참석자 1 19:04
앞에 여기 파이썬 설치하고 네 둘 다 둘 다 써놨어요.
여기 둘 다

참석자 2 19:13
그거는 뭐 그냥 뭐든지 그냥 편하게 쓰면 돼.

참석자 1 19:17
네네네 상관없어.

참석자 2 19:19
근데 이 타깃이 그러면은 이거 강의 교환을 만들면서 타깃 오디언스가 주느냐에 따라서 어떻게 보면 pip UV u 자세도 하나로 통일해 주는 게 낫지 않나 이런 생각이 들더라고요.

참석자 1 19:32
일단 둘 다 주고 원하는 취향에 따라 사실 이게 취향의 문제지 뭐

참석자 3 19:38
그러니까 PrP로만 설명 써 있어도 상관없을 것 같고 맨 앞에 뭐 예를 들어 pip를 쓰고 콘다나 파이썬을 쓰면은 그냥 pip를 쓰고 아니면 저기 UV를 쓰고 싶으면 UV 띄고 pip를 쓰십시오.
그렇게 써 있어도 되지 않을까 명령어는 다 똑같아서 어차피

참석자 1 20:03
일단 일단 그 오피셜 문서 자체가 둘 다 있어요. 그래 가지고 둘 다 반영하려고 하다 보니까 그렇게 된 것 같고 근데 일단 기본적으로 뭐 그거는 원하는 대로 찾아 쓰라고 하면 될 것 같긴 한데

참석자 2 20:18
그쵸 근데 하다가 이제 어떤 케이스가 있었냐면은 이제 파이썬 커맨드로 해갖고 뭔가 또 실행을 해보려고 하니까 emv 파일 그거 로딩 안 돼가지고 물론 또 전체적으로 로딩을 해놓으면 되지만 또 그거 UV에서는 emv 읽어오는 포맷이 있더라고요.
그래서 그런 걸로 해서 또 하니까

참석자 1 20:43
그럼 emv emv는 그냥 다 emv 로딩해서 그거 그거 똑같아요.
pip도 pip로 하든 UV로 하든 똑같은데 뭐 그렇죠

참석자 2 20:55
그러니까 그런 거에 대한 이제 설명은 저기 없으니까

참석자 1 20:58
그렇죠. 그래서 이게 이게 랭 체인에 대한 인문서지 파이썬에 대한 인문서는 아니기 때문에 물론 물론 물론 그래서 제 생각에는 일단 이 정도 셋업 가이드 정도는 이해하고 있는 사람이 보지 않을까 싶긴 하거든요.

참석자 3 21:15
셋업 가이드가 있네요. 네 있어요. 그럼 셋업 가이드 보면 되겠네

참석자 1 21:21
여기 여기 있어요. 그래서 이거는 제가 이제 나중에 여기도 있을걸요.
여기 실전 요 셋업 가이드 환경 셋업 가이드가 있긴 한데 그거를 좀 더 더 드러나 보이게 해놓을게요.
그래서 이거 따라 하면 되게 스트레이트 포드하게 쌓여 있기 때문에 이렇게 설치부터 심지어 파이썬 설치부터 이렇게 돼 있어서 아까 말씀하신 부분이 다 여기 커버가 되거든요.

참석자 3 21:56
근데 지금 우리가 리뷰를 하는 게 강의 교환이라서 그냥 설명하는 말만 체크를 할 건지 당연히 코드도 돌아가는지 체크할 건지도 얘기를 해야 될 것 같긴 한데

참석자 1 22:13
그래 그거는 이제 그래서 이제 그 얘기는 이제 여기에 해당하는데 그래서 뭘 이제 얘기를 하냐 무슨 얘기 이제 코드를 읽고 방금 이제 두 종훈 책임님들이 말씀해 주신 교환이나 예제에 대한 얘기들이고 그리고 이제 그거에 대해서 이제 내용적인 부분과 뭔가 문제가 있거나 아니면 또 이게 너무 어렵거나 아니면 너무 설명이 부족하거나 아니면 또 이게 또 길이가 너무 길거나 이게 지금 2천 줄이거든요.
길이가 너무 길거나 아니면 너무 당황하거나 이런 것들의 의견을 적극적으로 주시면 좀 다이어트를 시켜야 될 필요가 있다고 생각하거든요.
그래서 이 내용을 이제 같이 보고 이런 부분은 좀 덜어내자 이런 부분은 조금 설명이 좀 부실하다 이런 식의 의견을 주시면은 그거를 반영해서 약간 좀 최적화를 시켜야 되지 않나 그런 생각이 드네요.

참석자 2 23:13
그리고 다른 질문이요. 지금 이게 랭체인 1.0 기준이에요 아니면은 1.0 기준 구형 버전 기준이에요.

참석자 1 23:20
1.0 기준으로 만들고 있어요. 왜냐하면 현재 오피셜 도큐먼트가 1.0이거든요.
그래서 그걸 다 긁어와서 만든 거라서 1.0 기준이에요.
계속할까요? 그래서 그 모델 하나 끝났고 그다음에 이제 메시지인데 메시지가 굉장히 중요하죠.
메시지가 크게 네 가지 메시지가 있어요. 시스템 메시지 휴먼 메시지 AI 메시지 툴 메시지 그래서 시스템 메시지는 시스템한테 시스템의 어떤 역할이라든가 기본적인 요구 사항 뭐 따라야 될 아주 기본적인 클로드 코드로 치면은 클로드 점 MD 같은 느낌이죠.
그래서 걔를 계속 계속 주는 거예요. 기본적으로

참석자 3 24:09
그리고 이게 시스템 프롬프트랑 다른 거예요.

참석자 1 24:12
시스템 프롬프트인 거죠. 얘가 그 시스템 프롬프트를 주는 거고 그래서 이런 식의 느낌인 거죠.
너는 뭐 역할이라든가 응답 스타일 뭐 아무튼 반드시 모든 메시지마다 지켜야 될 어떤 가이드 같은 걸 주는 거예요.
그래서 이런 식으로 주고 거기에다가 이제 휴먼 메시지를 이렇게 리스트를 묶어서 얘를 메시지를 딱 던지면은 요 기반으로 그 맥락을 잡은 상태에서 이 질문에 해당하는 레스폰스가 나와 있게 되는 거예요.
휴먼 메시지에 따른 레스폰스를 휴먼 메시지 뭐 설명 전에 미리 여기 나왔는데 휴먼 메시지는 이제 사용자 인풋인 거죠.
그래서 이렇게 사용자 인풋을 이제 휴먼 메시지를 넣어서 던지면 거기에 대한 답이 나오는데 여기는 히트 메시지가 없었지만 없지만 뭐 알아서 그 사전 학습된 걸로 답을 주겠죠.
근데 여기 이제 이제 보시면 아시겠지만 얘네들이 그 랜체인 메시지의 클래스예요.

참석자 1 25:18
그래서 기본적으로 메시지 객체들이 갖고 있는 기본 파라미터라든가 이런 거를 상속을 받아서 쓸 수 있는데 휴먼 메시지 같은 경우에 이게 콘텐츠 이게 이제 이 부분이고 여기에 이제 사용자 식별용 이름 혹은 뭐 고유 아이디 이런 것들을 넣어서 그 AI와 그것도 툴들이 혹은 다 얘를 추적해서 쓸 수 있게 해줘요.
그런 특징이 있다. 그래서 이런 식으로 멀티 모델 앞에서 나와 뒤에 또 자세히 나와요.
멀티 모델도 이렇게 지원을 하고요. AI 메시지는 이제 AI가 이제 답을 할 때 리스펀스가 나오는 이게 이제 AI 메시지가 되는 거예요.
그래서 이제 이거를 좀 보기 편하게 이런 식으로 정리를 해놨고 안녕하세요 하면 이게 이제 찍어보면은 이제 응답하고 뭐 그런 것들이 나오고 아이디를

참석자 3 26:12
이거 인보크 하면 출력되는 것 자체가 AI 메시지 타입으로 돼 있는 거

참석자 1 26:17
그렇죠 네 응답이 그래서 이거를 한번 이렇게 넣을 수도 있어요.
수동으로 해서 AI가 안 줘도 내가 이렇게 왜냐하면 이제 이게 기본적으로 모델은 스테이트 리스잖아요.
과거 기억을 못해 기억을 못해 그래서 줄 때마다 사실 이런 식으로 대화를 재구성해서 주게 돼 있거든요.

참석자 3 26:39
이게 지금 컨텍스트 지금 저장하는 메모리 하는 거죠.
결국에 그 쌓아가

참석자 1 26:44
실제로 그러니까 그게 이런 식으로 돌아가는 거예요.
그러니까 대화를 계속하면은 이렇게 과거의 대화 내용을 이 메시지를 쌓아가지고 던지는 식으로 해서 느낌에는 우리가 멀티 톤으로 얘기하는 것 같지만은 내부적으로는 이런 식의 거를 계속 해줘야 되는 거죠.
투입 메시지는 보시는 것처럼 이렇게 투입 메시지도 그 AI가 이제 어떤 툴을 쓸지를 이렇게 줘야 되는 거예요.
그래서 AI 메시지가 그러니까 기본적으로 여기 그러니까 좀 더 여기는 이제 순서가 AI가 이미 정해주는 건데 앞뒤가 좀 안 맞다 여하튼 그 대화를 할 때 AI와 대화를 이렇게 했는데 그럼 AI가 어떤 대화를 응답을 내기 위해서 어떤 툴을 써야 되는지를 알려주는 게 요 이 AI가 이제 리턴할 때 이 툴 콜이 들어가 있는 결과거든요.

참석자 1 27:37
그러면 이제 AI가 어 그래 알았어 니 응답을 하려면 이 2를 호출해라고 AI가 응답을 줬을 때 거기에 맞춰서 이제 툴 메시지가 이제 실행 결과가 툴이 호출된 다음에 그러니까 로컬에 있는 에이전트가 거의 AI 메시지를 받아서 2를 호출해 가지고 그 결과를 여기다 받아주는 거예요.
콘텐츠에다가 이때 근데 AI가 이 아이디를 정해서 주거든요.
이 툴을 호출할 때 이 아이디에 왜냐하면 이걸 알아야 이제 요 맥락을 다 같이 받을 텐데 이 질문에 대한 이 툴을 호출을 했고 그 아이디를 보고 아 요 툴과 요 아이디에 대해 왜냐하면 같은 툴에 대해서도 그 아이디어가 다를 수 있으니까 호출된 순서가 다르거나 아이디가 다를 수도 있으니까

참석자 3 28:23
좀 이상한데 옛날에 인보크 할 때 그 메시지 쿼리랑 같이 AI 도구 넣어서 보내면은 받은 메시지에 뭐 이런 내용이 들어 있어야 되는데 지금은

참석자 1 28:34
아니요. 이거는 그거를 그거 지금도 그런데 그거를 이해하기 편하게 다 풀어서 써준 거예요.
이 교환 이 교환이 어떤 식으로 작동하는지를 보여주기 위해서 지금 그냥 쭉 보여주는 것뿐이거든요.
실제로는

참석자 3 28:48
타스 콘텐츠에 이 내용이 들어 있는 게 차라리 이해가 더 쉬울 것 같은

참석자 1 28:51
아 지금 이게 실제 툴 콜에 대한 결과를 보여주는 게 아니라 그건 뒤에 나오고 실제로 돌아갈 때 이런 식으로 돌아간다는 예제를 보여주는 것뿐이거든요.
툴 콜 이렇게 좀 그러니까 그걸 이해하고 이걸 보면은 아 이거 툴 콜의 과정을 이해하기 위해서 알려주기 위해서 이게 있구나라고 이해를 했지만 그 툴 콜에 대한 설명이 저 맨 뒤에 나와요.
맨 뒤에 나와서 그걸 모르는 상태에서 이거 보면은 이게 뭐야라고 하기 쉽죠.

참석자 3 29:22
그런 거는 뭔가 순수

참석자 1 29:24
그래서 제가 순서 조정이 필요할 것 같다고 말씀을 드렸어요.
그래서 이게 그러니까 그거 잠깐 볼까요? 차라리 밑에 볼 거 투콜이 여기 있어요.
맨 뒤에 보면은

참석자 3 29:37
모델 인보크랑 시스템 메시지랑 AI 메시지 이런 내용 한 다음에 이제 툴 메시지 얘기하고 툴 콜링 얘기하고 그래야 될 것 같네.

참석자 1 29:47
툴 콜리 그러니까 툴 콜리 맨 뒤에 있는 거예요. 그래서 모든 설명 다 했으니까 이제 너희 다 알지 그다음에 툴 콜 알려줄게 왜냐하면 앞에 설명했던 게 나오거든.
그래서 에이전트하게 질문을 하면 이제 LLM한테 질문과 함께 어떤 툴을 쓸 수 있는지 알려주고 그럼 얘가 어떤 툴을 쓸지를 결정해서 이 툴을 이 아규먼트를 박아서 실행해라고 하면 에이전트가 실제로 이제 병렬로 지금 이제 부산과 서울과 부산의 날씨를 물어봤으니까 각각에 대해서 날씨를 병렬로 이 2를 호출해서 그 결과를 받아가지고 그거를 다시 LNM한테 줘서 응답을 만들게 해가지고 이 텍스트를 스트링을 만들면 답변을 주고 이런 식의 흐름이거든요.
근데 이 과정에서 아까 그 툴 콜 메시지라든가 이런 것들이 여기에 이제 생성이 돼서 왔다 갔다 하는 데 쓰인다는 거죠.

참석자 3 30:35
조금 다른 내용인데 지금 이 트루콜링이 병렬로 돼요.
순차적인 거 아니었어요.

참석자 1 30:43
근데 생각해 보면은 병렬

참석자 3 30:47
돌릴 때도 툴 콜링인데 MCP가 동시에 여러 개 못 쓰고 하나 잡고 있으면 그거 계속 돌고 있고 그랬다고 했던 것 같은데

참석자 1 30:55
내부적으로 q 이렇게 관리하지 않을까요? 그건 뭐 하여튼 그래서 그걸 설명하기 위해서 필요한 토요일 메시지에 대해서 설명하려고 이게 있는 거예요.
그러니까 결국에 여기는 이제 질문을 이미 했고 아까 웨더를 얘가 이제 AI가 이제 이거 호출해라고 했을 때 그걸 받아가지고 툴을 호출한 다음에 AI한테 호출 결과를 알려주기 위해 툴 메시지라는 걸 사용해서 리턴을 한다는 거죠.
아까 플로우 차트를 보고 나서 이걸 보니까 좀 더 이해가 쉽지 않아요.
플로우 차트 맨 뒤에 있어 그래가지고 근데 또 그걸 가져오자니 모든 설명이 앞에 있어서 그걸 모르는 상태에서 프로 차트를 설명해야 되나 아무튼 뭐 좀 그런 고민이 있는데

참석자 3 31:38
아니 근데 플로우 차트를 봐도 지금 최종적으로 인보크를 보내는 메시지에 아웃풋으로 놔야 된 내용이 다 포함돼 있잖아요.
입으로 마치 프린트를 뽑아 찍어놔야 되는 내용이 앞에 선언돼 있으니까 이상한 거 아닌가라고 생각하는데

참석자 1 31:58
이게 지금 이거는 맨 요 지금 인보크 있잖아요. 이거는 어떤 단계냐면 맨 마지막에 요 단계인 거예요.
요

참석자 3 32:08
답변 답

참석자 1 32:10
요 단계 이 단계 이 단계 그래서 답변 다 받고 이제 호출하면 요걸 줘요.
요거 요거 받는 단계 그러니까 여기를 하는 인보크인 거예요.
방금 보신 거는 다 하고 그 결과를 이제 메시지에 담아가지고 툴 리졸트를 받기 위한 인보크를 한 거예요.
그러면 레스폰스로 요게 날아와요. 그런 다음에 이걸 주게 돼 있어요.
그 단계거든요. 그러니까 그 방금 보신 예제의 인보크는 여기다.
그래서 앞에 부분은 보여주기 위해서 객체를 선언해 가지고 뭐 보여준 거다라고 생각하시면 돼요.

참석자 3 32:48
이해하기가 좀 어렵긴 한데

참석자 1 32:50
그러니까 이해하기가 좀 힘들게 돼 있어요. 이게 이게 아무튼 요즘 좀 이 좀 그렇다.
아마 이게

참석자 3 32:58
이게 어쨌든 그 공식 가이드에도 이런 식으로 설명되어 있던 거잖아요.
그렇죠 무슨 의도로 이렇게 써놓은 건지 모르겠네.

참석자 1 33:06
공식 가이드도 이게 미디어 거의 같아요. 잠깐만 여기에 메시지 투 메시지 여기 돼 있잖아요.
똑같이 했던 거라서 그리고 토요일 어디까지 했지 토요일 콜링 너무 허확 지나가서 죄송해요.
정신이 없어서 메시지 툴 휴먼 여기까지 설명드렸고 그리고 이제 이거를 이거 설명할까 말까 이것도 넣을까 말까 고민인데 이렇게 안 하고 그냥 디렉터리 구조로 딕셔너리 구조로 할 수도 있어요.
그래서

참석자 3 33:47
이게 사실 예전에 이렇게 했잖아요.

참석자 1 33:49
근데 이렇게 하면 이 메시지 객체가 갖고 있는 특성 있잖아요.
아까 파라미터나 뭐 이런 거를 못 써요. 후끈하고 이런 거 그런 거 써가지고 근데 그게 써야 되나 싶은데 뭐 필요하면은

참석자 3 34:04
더 구조화돼 있으니까 저 방향으로 가는 게 좋기는 하겠는데

참석자 1 34:09
그렇죠. 그래서 이제 이렇게 보면 타입 안정성 아이디 자동 완성 멀티 모델 메타 데이터 이런 거 아 부가 기능 쓰면 이거 쓰고 아니면 간단하게 쓰면 이렇게 해라라는 거고요.
멀티 모델 얘기가 여기 나오는데 멀티 모델이 아까 설명드린 이 프로필을 가지고 각 입력된 모델별로 지원하는 여부를 알 수 있게 이렇게 돼 있어요.
그러니까 아까 그 홈페이지에서 끌고 오는 거예요.

참석자 3 34:33
근데 생각해 보니까 지금 AI 메시지든 시스템 메시지든 결국 최종적으로 LLL 모델한테 보낼 때는 텍스트로 보낼 거 아니야 보낼 거잖아요.
이게 지금 우리가 말한 객체 되어 있어 갖고 툴을 못 쓰고 콜 아이디는 뭐고 막 이렇게 줄줄이 다 답을 넣을 수 있는데 결국은 LLM한테 보낼 때는 그냥 텍스트로 보내는 거잖아요.
그 이게 그러니까 최종적으로 메시지를 보낼 때 콘텐츠를 같이 볼 수 있으면

참석자 1 35:07
그래서 그 방법을 밑에 설명 했는데 일단 이미지 같은 경우에는 요 URL 형식으로 던져서 이게 이제 외부에서 접속 가능한 URL이어야 되고 그 저쪽에서 서버 단 LLM 서버 단에서 당겨가지고 처리를 하는 걸로 보이고 두 번째 방법은 이제 베이스 64로 컨버팅 하는 거예요.
이미지를 그래서 이렇게 베이스 64로 컨버팅 해가지고 그 컨버팅한 텍스트 열을 던지는 거죠.
그리고 이제 파일 아이디라고 이제 오픈 AI 같은 경우에는 파일 API라는 걸 제공해요.
그래서 파일을 크리에이터에서 업로드를 하면 그 파일 아이디가 제공되거든요.
그럼 그 파일 아이디를 줘서 뭔가 요청을 하면 되는 건데 이게 돈을 더 먹죠.
그리고 이제 PDF 문서도 이런 식으로 베이스 64로 컨버팅해서 보내는 방법이 있고요.
이렇게

참석자 2 35:58
근데 멀티 모델이 요 스텝에서 꼭 나와야 되나요?

참석자 1 36:03
복잡해지는 거 아니야 왜냐면은 멀티 모델이 요새 중요하기 때문에 필요할 것 같긴 한데 이렇게까지 자세히 해야 되는지 잘 모르겠어요.
왜냐하면 지금 보시면은 PDF도 했죠. 오디오 심지어 오디오도 하죠.
비디오도 하죠. 그리고 이제 그거 실제 코드가 나오거든요.
어떤 식으로 쓰는지 이 이미지를 기반으로 하는 코드가 한 번 더 나오고 그다음에 여기 주의 사항 파일 사이즈 뭐 이런 게 나오고 그리고 모델별로 비용 고려 이런 게 나와서 이게 조금 너무 과해요.
그러니까 소개를 하는 건 좋은데 좀 과하다.

참석자 3 36:35
실제 멀티 모델로 챗봇을 구현한다고 하면 지금 오픈 AI 모델을 썼을 때 내가 파일 API로 파일 업로드하는 것까지 구현을 해서 집어넣어야 돼요.
베이스 64 압축 안 하면

참석자 1 36:49
페이스 6 14로 하거나 그러니까 여기에 있는 게 다예요.
현재 선택지가

참석자 3 36:54
제 말은 이제 여기는 사실 파일 API를 사용한 내용은 없잖아요.
업로드한 아이디를 입력

참석자 1 37:01
이 파이 API가 돈을 먹거든요.

참석자 3 37:04
그래서 제 말은 이게 구현하려면 파일 업로드를 해서 이거 파일 IP까지 뽑아내는 파일 아이디까지 뽑아내는 파일 ipi 구현체까지 넣어야 되는 내용이면은

참석자 1 37:17
여기에는 필요 없다고 생각해요. 저는

참석자 3 37:20
멀티 모델 챗봇을 만일 구현하려고 한다고 하면 내가

참석자 1 37:23
멀티버드 체스포는 근데 그거는 어떤 식으로 예를 들어서 이게 파일 아이디 같은 경우에는 그 파일을 많이 쓰는 경우 그런 거 예를 들어 특정 파일이 있고 얘를 빈번하게 써야 돼라고 하면 이제 구현의 편의성 때문에 이걸 쓰는 거지 왜냐하면 베이스 피터를 컨버팅 할 때마다 컨버팅하는 시간이 들고 그리고 그때마다 토큰을 쓰잖아요.
근데 파일 아이디는 이제 한 번 올라가는 데 좀 돈이 들지만 그다음부터는 물론 추가 비용이 들긴 하지만 그래도 구현이 편하잖아요.
근데 베이스 64 그렇지 않고 속도 같은 것도 이게 더 빠르겠죠.
파이라이트를 쓰는 게

참석자 2 37:54
일단 그러면은 파일 아이디가 저거 오픈 AI 서버에 올려버리고 거기 저 아이디만 가지고 계속 그걸 조회해서 쓰겠다는 그런 얘기가 되는 거죠.

참석자 1 38:04
네 그 비용이 더 받아요. 그 해당 커리에 대해서는

참석자 2 38:07
그렇지 그렇겠지 근데 대신에 올라가는 비용은 안 들 거잖아요.
그다음에는

참석자 3 38:13
올라마는 파일 API가 없겠죠.

참석자 1 38:16
아니 올라가는

참석자 2 38:17
그러니까 올라가는 것도 원래는 다 비용인데

참석자 1 38:20
그게 그러니까 이게 아까 말씀드렸듯이 이걸 반복해서 쓰면 괜찮아 보이는데 할 때마다 새로운 걸 주면은 좋은지 모르겠어요.
뭐 그러겠죠.

참석자 3 38:31
그게 지금 이제 AI 모델 서비스하는 프로바이더마다 API가 서로 다 다르기 때문에 달라요.
그래서 사실 랭 체인에서 그거를 규격화해서 지금 인보크나 그런 식으로 우리가 쓸 수 있게 시스템 메시지나 이런 것도 파라미터나 그런 키 값이 다를 텐데 그것도 다 동일하게 쓸 수 있게 만드는 것처럼 근데 해놓은 거라서 그런

참석자 1 38:56
잘 보시면 얘는 달라요. 그 메시지를 쓰는 게 아니라 이렇게 이렇게 디셔널이 돼 있어요.
왜냐하면 이게 이 오픈 AI에서 지원하기 때문에 그렇고 아까 말씀 우리 같이 봤던 앞에 메시지 객체를 쓰지 않아요.
그래서 거기 써 있어요.

참석자 2 39:13
그러면 저것도 예를 들어서 클로드나 제미나이에서도 저걸 똑같이 지원을 할까요?
아니면은

참석자 1 39:19
요 형식은 아니더라도 요새 재미나는 오히려 더 잘하잖아요.
근데 펜 아이디를 지원하는지 잘 모르겠어요. 제가 확인하는 거는 얼마전 확인한 건 오픈ai 것만 확인했어서 파이 아이디 자체를 지원하는지는 모르겠지만 기본적으로 멀티 모델 자체는 지원하는 걸로 알아요.

참석자 3 39:36
뭔가 그 AI 프로바이더에 맞춰진 그것보다는 모든 AI 프로바이더에 다 적용할 수 있게 냉체인이 추상화해 놓은 최종적으로 엔드 유저용으로 만들어놓은 인터페이스 기준으로 설명을 쓰는 게 좋지 않을까

참석자 2 39:56
그렇죠

참석자 3 39:57
프로바이버 특화 내용을 따로 빼든가 뭐 그냥 알아서 찾아보세요 하고 참조 링크 같은 걸 놔두는 게 나을 수도 있고

참석자 1 40:07
그래서 제가 생각에는 그냥 오디오 이미지 여기서 멀티 모델에서 그냥 이미지 하나만 다뤄도 되지 않을까 이미지 보면 이제 기본적인 요거랑 이것만 다루고 나머지 파일 아이디라든가 뭐 PDF까지는 괜찮으려나 근데 오디오 근데 멀티 모델을 살면서 오디오 비디오를 안 하면 또 애들한테

참석자 2 40:25
멀티 모덜 세션 멀티모덜 일종의 블록을 쫙 빼갖고 챕터를 별도로 해갖고 뒤로 넘겨버린다든가 앞에서 펀더멘탈에서는 가장 기본적인 것만 설명

참석자 1 40:38
뒤에서 받을 데가 없어요. 뒤에 뒤에 이걸 받을 데가 없어요.
그

참석자 3 40:42
더 설명할 건 없을 것 같아요.

참석자 1 40:44
건덕지가 없어가지고 그냥 이거를 여기를 하되 그냥 확 줄였으면 좋겠어요.
저는 너무 길어

참석자 3 40:49
프로바이더 특화 내용 다 빼버리고 랭체인에서 다 엔드 유형으로 엔드 유저형으로 다 만들어놓은 인터페이스 기준으로만 설명 딱 하면 될 것 같은데

참석자 1 41:00
이게 너무 길어서 좀 줄였으면 좋겠고요. 제가 그거는 그래서 그냥 기본적인 멀티 모델 뭐 어떤 거고 요 요 요 URL이랑 이미지 이미지 하는 정도만 남겨도 되지 않을까 나머지야 뭐

참석자 3 41:16
근데 이거 모델 선언할 때 멀티 모델 모델로 선언을 옛날에 했던 것 같은데 이제는 그 선언 필요가 없는 거죠.

참석자 1 41:25
여기서 지금 그것 때문에 이게 나오는 거죠. 여기 보시면은 프로파일 설명이 왜 나왔냐면 사실 이 프로파일 이것 때문에 나온 건데 그래서 이제 이 모델이 멀티 모델을 지원하는지 확인하고 쓰라 그거죠.

참석자 3 41:38
그러면은 제가 만일 멀티 모델 지원 안 하는 모델에다가 이 이미지를 포함한 메시지를 집어넣으면

참석자 1 41:45
에러 나는 거죠. 리턴을

참석자 3 41:48
이거 넣을 때 아예 프로파일 체크해서 안 됩니다 하고 날려주는 건지 아니면 인보크로 얘가 그거는 애를 밑에까지 보낸 다음에 에러가 나는 건

참석자 1 41:58
그거는 구현을 어떻게 하시겠느냐에 따라 다른 거죠.
이거 이렇게 구현

참석자 3 42:02
내가 그거를 구현해 놨나 그게 궁금해서 그걸 구현해 놓지 않았나 보네.

참석자 1 42:06
구현을 하기 위한 기능은 여기 있지만 구현을 할지는 이제 은행제가 알아

참석자 3 42:12
로크 안에 이렇게

참석자 1 42:13
없는 것 같아요. 그리고 그거는 그렇고 이제 여기가 2장 끝났어요.
그래서 3장은 툴이에요. 이게 사실 근데 툴이 여기에 아까 맨 뒤에서 보신 이 기본 편이 여기 있긴 해요.
아주 간단하게 이게 있으니까 괜찮으려나 그래서 이제 아까 설명드린 내용은 간단하게 설명해 놨고 여기에서 이제 핵심적으로 설명하는 거는 이 스키마하고 펑션을 어떻게 만드느냐거든요.
이 툴 콜을 할 때 인풋 아웃풋을 받을 수 있는 그 아규먼트의 스키마 뭐 툴에 대한 스키머 여기 이거는 툴에 대한 스키머구나 툴에 대한 스키머하고 함수에 대한 설명이 이제 핵심이고요.
그리고 이제 데코레이터를 어떻게 쓰는가 데코레이터가 랭체인의 트위스의 툴이라는 그 함수로 클래스로 정의돼 있어서 얘가 이제 데코레이터를 앞에 붙이면 이 함수를 이 파이썬 함수를 이제 랩핑 해가지고 툴로 만들어줘요.
그러면 이제 이런 기능들을 아규먼트를 쓸 수가 있죠.

참석자 1 43:25
그래서 이 툴을 만들 때 반드시 핵심 요구 사항이 요 우선 타입 힌트 주고받을 때 타입 힌트랑 그리고 이 안에 이제 딱 스트링을 잘 써야 돼요.
이게 어떤 목적으로 쓰이고 어떤 걸 하는지 그리고 아규먼트가 뭐고 여기는 없지만 리턴이 뭔지 이렇게 나와 있어야 돼요.
그래서 거기에 대한 예지가 이거 뭐 시간 좀 시간 타임 존에 따른 시간에 반하는 그런 함수를 한번 만들어 본 거고 그래서 보시면 이게 LM이 전혀 없어요.
그냥 이걸 만들어서 이 데코레이팅을 하면은 러너블이라는 클래스를 상속을 받아서 인보이스로 그냥 인보크를 쓸 수가 있어요.
그래서 이 인풋에 맞는 걸 이렇게 던지면은 계산해서 준다.

참석자 1 44:11
그리고 더 스트링은 아까 설명드린 것처럼 이렇게 성의 없이 쓰지 말고 AI나 사람이 봐서 AI가 읽어서 뭐 하는 놈이고 목적이 뭐고 뭘 줘야 되고 리턴이 뭔지 알 수 있게 써라라는 거고 타이 힌트는 이제 이게 결국에는 어떤 툴을 만들 때 이제 뭘 주고 뭘 봤는데 이 주는 거에 대해서 이렇게 좀 더 아규먼트를 이제 타입을 명확하게 이렇게 알려주는 거죠.
이거는 이제 타입을 알려주면서 이제 초기 것까지 세팅하는 거고 요거 요거 그래서 이제 이게 중요하긴 하거든요.
이게 왜냐하면 이걸 잘못 그러니까 이런 걸 잘 만들면 만들어야 이제 LNM이 잘 맞춰서 요구를 하니까 근데 이제 뒤에서 나오지만 이게 이제 파이덴틱이 나오면서 좀 까리해진다 뭐 필요하긴 한데 좀 너무 어려워지는 느낌이 좀 들어서

참석자 3 45:15
그리고 여기 사람이 잘 열 2를 잘 쓰려면은 저 타이 피트가 중요하다고 그러더라고요.

참석자 1 45:22
중요하죠. 그래서 이제 파이덴틱을 그래서 쓰는 거고요.
그 설명은 뒤에 나와요. 그래서 여기는 뭐 조금 간 느낌이 살짝 있긴 한데 뭐 그냥 짧아서 그냥 기초 정도면 사실 저는 이 챕터에서는 파트에서는 이것만 설명해도 될 것 같긴 한데 근데 이제 문제는 문제는 문제 이 툴 런 타임이라는 게 이제 들어가서 저도 이번에 처음 봤거든요.
이게 이제 이제 툴 런 타임이라는 게 이 같은 요 랭체인 점 투스 밑에 있는 툴 런 타임이 있는데 얘를 런 타임이라는 객체로 이제 넘겨줘요.
이렇게 이렇게 넘겨주면 이게 이 툴 내에서 툴에 대해서 그 모델이나 컨텍스트나 뭐 성체 메시지 아까 메시지 주고받는 스테이트 이게 이게 이제 메시지 주고받는 스테이트가 이 안에 들어 있는 거거든요.
그러니까 과거 메시지들이나 유저 아이디라든가 이런 에이전트에 대한 정보를 툴 내에서 쓸 수 있게 해주더라고요.
그래서 이거는 유용하긴 할 것 같아 할 것 같은데 여기에 와야 되는지 잘 모르겠어요.

참석자 1 46:27
그래서 이제 그 런 타임의 속성들이 나오는데 예를 들어 안에 스테이트 대화 메시지들을 볼 수 있다거나 아니면 뭐 사용자 정보나 유저 아이디나 혹은 사용자가 세팅해 놓은 언어라든가 왜냐하면 이 언어 세팅에 맞춰서 이제 텍스트가 나오면 좋잖아요.
결과가 그리고 또 장기 메모리 그러니까 예를 들어 장기 메모리라고 함은 여기 이제 유저 아이디를 받아서 이제 그 스토어라는 밑에 들어 있거든요.
소 객체 밑에 거기 안에 이제 이런 식으로 지금 집어넣는 거예요.
그러니까 장기 메모리는 보통 어떤 사용자의 어떤 특성이라든가 뭐 취향이라든가 뭐 이런 것들이 반영되는 거잖아요.

참석자 1 47:11
개성이라든가 그래서 여기 보면 뭐 어떤 멤버 프리퍼런스에다가 어떤 툴에 의해서 결과물에 나오면 그걸 기반으로 그 아이디 유저는 프리퍼런스가 어떻다 뭐 이런 식으로 저장할 수 있는 그리고 스트림 마이터는 그 툴이 이제 그 어떤 내부적으로 뭔가 오랜 시간이 걸리는 처리일 때 에이전트한테 그 현재 상태를 알려주는 거예요.
현재 진행률이 몇 퍼센트입니다. 뭐 이런 거 어디서 없으면 답답하잖아요.
그리고 런탈 툴 콜 아이디 이거는 이제 그 툴 콜 하는 아이디를 리턴하는 거 그거 이런 식의 건데 중요해 보이거든요.
그리고 게다가 뒤에 막 더 있어 심지어 여기가 아니라 근데 이게 막 너무 길어서 이제 그래서 일단 너무 길다 그래서 이거를 소개할지 안 할지도 고민인데 너무 길고 내용이 너무 과하다라는 느낌을 저는 받아요.
그래서 이거를

참석자 3 48:10
따로 빼는 게 좋을 수도 있겠네요. 방금 말씀하셨던 고기까지 거기까지 적절하다고 말했던 또 툴 내용 따로 있지 않아요

참석자 1 48:22
이게 툴이 전체 과정에서 중요하긴 한데 이게 뒤로 갈수록 더 중요한 게 많이 있거든요.
그래서 특히 이제 레그나 MCP 쪽에서 한번 해도 되지 않을까 생각은 들긴 하는데

참석자 3 48:38
그래서 MCP랑 풀을 묶어서 따로 뒤에 빼는 게 지금 풀 런 타임 내용 나오는 건

참석자 1 48:45
그래서 내용

참석자 3 48:47
않을까 싶기도 한데 지금 MPP랑 지금 같은 맥락에서 지금 툴을 설계하잖아요.
그 툴 클래스나 함수를 설계하는 게 저기 독스트링 쓰는 거랑 그런 게 다 같은 맥락인데

참석자 1 49:01
그래서 그거는 좀 일단 일단 지금 여기서는 좀 더 축약을 하고 뒤쪽으로 보낼 수 있으면 찾아보고 보내보는 건 좋은 것 같아요.
2 런 타임이 좀 너무 과하다라는 거고 그래서 막 보면 그리고 이제 툴 고급이 또 있어요.

참석자 3 49:23
그니까 너무 따로 따로 빼야 되겠네. 지금까지 런 타임도 고급인데 또 고급이

참석자 1 49:28
아니 런 타임은 고급이 아니에요. 그거는 어드벤스예요.

참석자 3 49:32
그래요. 어드벤스가 고구마 아닌가 거의 없지

참석자 1 49:37
아무튼 그래서 여기는 이제

참석자 3 49:40
뭐라고 쓰여 있는 거예요? 어드벤트 아니에요 둘 다

참석자 1 49:43
그냥 툴 런 타임이라고 돼 있어. 이제 고급은 뭘 배우냐면 여기는 파이덴틱이에요.
파이덴틱이 이제 결국에는 툴한테 주는 파라미터들 예를 들어 로케이션 유닛 이런 게 있으면 이거를 이제 이런 식으로 파이드앤틱의 베이스 모델을 상속받아서 클래스를 만들고 여기다가 아그스 이렇게 주면 이제 이거를 이제 여기 똑같이 써 있거든요.
주는데 이게 이제 콜이 콜을 할 때 얘를 잘못 호출 타입에 안 맞거나 막 이렇게 호출을 하면 여기서 에러를 내요.
얘 너 잘못했어 다시 해 여기서 LLM이 이제 생성을 할 때 이제 요 에러를 보고 이제 다시 한 번 제대로 맞춰서 이렇게 할 수 있고 또 이게 이제 스키마를 가져가기 때문에 이게 이제 정보가 넘어가기 때문에 거기에 맞춰서 이제 호출을 잘 하겠죠.
되게 되게 중요한 부분이야 되게 중요한 부분 맞는데 이렇게 이제 근데 이제 이제 그 방법을 이제 되게 디테일하게 설명을 하고 있어요.

참석자 1 50:50
그래서 그렇게 하는데 여기에 이제 그 요소들이 써 있어요.
일단 필드가 있어서 이 필드가 요 쿼리에 디스크립션이 있는 거죠.
이 필터 디스크립션 이런 식으로 그리고 여기에다가 조건도 걸 수 있어요.
무슨 얘기냐면 그 어떤 나이 예를 들어 뭐 나이 같은 거가 있었던 것 같은데

참석자 3 51:12
어디 있더라 이게 지금

참석자 1 51:14
네

참석자 3 51:15
이게 지금 냉 체인에 있는 인터페이스가 아니고 API가 아니고 랭체인에 있는 인터페이스에 파이덴틱을 붙인 거죠.
붙이는 거잖아요. 붙인 거예요. 당연히 뒤로 갈 수밖에 없는 내용 같은데 따로 뺄 수밖에 없는 내용 같은데 근데 이게 왜냐하면 이걸 해서 더 잘 해야 그러니까 앞에까지 하면 내가 기본적인 툴을 만들 수 있고 그 툴을 만든 걸 붙여볼 수 있는 것까지 해서 툴을 잘 만드는 것까지 써봤네요.
했는데 많이 작동 잘 안 하시면 뒤에 충주 챕터를 가셔서 내용들을 체크해서 너한테 부족한 걸 확인해 봐라 이런 식으로 뒤로 넘길 수 있잖아요.

참석자 2 51:56
아니 그러니까 이게 이게

참석자 1 51:58
왜 그러냐면 사실은 이게 저도 이게 하나의 파트로 새로 만들어야 될 것 같다는 생각도 들긴 하는데 문제는 다른 파트 이게 내용이 만만치가 않거든요.
특히 이제 뒤에 에이전트 같은 경우에는 그냥 뚫고 설명을 제대로 안 해요.
그냥 너 알지 하고 넘어가거든요. 이게 어떻게 보면은

참석자 3 52:17
전에 그러면 툴이 잘 설명돼 있어

참석자 1 52:20
그렇죠 보시면 여기 보면 바인더 트리 이미 나오잖아요.
그러니까 투코의 설명이 뒤에서 할 데가 없어요. 이게 마지막이야.
그리고 사실은 이게 이 챕터 하나가 지난번 랭체인의 거의 한 3분의 2 정도를 이 챕터 하나로 커버하는 거예요.
그러니까 그렇게 양이 많고 내용이 이러는 거예요.

참석자 3 52:37
1 2.5를 만들어야 되겠네요.

참석자 1 52:39
근데 이게 너무 많아. 근데 뒤에가 그래서 일단 제 생각에는 이거를 그 파트를 만들기보다는 그냥 줄이고 내용을 좀 줄이고 그러니까 뒤에서 이해 뒷 파트들에서 이해할 수 있는 수준으로만 줄이면 어떨까라는 생각이 드는 거죠.
너무 그리고 만약에 뒤에서 만약에 그러니까 만약에 커버 안 되는 부분이 있으면 거기서 다시 툴을 좀 더 설명한다거나

참석자 3 53:05
내용 작동하는 데는 파이던틱하고 풀 런타임 이런 건 필요 없지 않아요 팩트로 작동하잖아요.

참석자 1 53:13
그러니까 보시면 이제 툴 콜이 있고 파이덴틱이 있는지는 잠깐만요.
파이덴틱

참석자 3 53:20
하이렌팅 올 게 아니라 잘 작동하게 만들기 위한 도구인 거지 작동 자체는 파이렌트 없어도 되는 거 아닌가요?

참석자 1 53:29
작동 자체는 되죠. 근데 이제 그게 이제 이제 그러니까 뒤에서도 실제로 쓰진 않는데 바이더틱을 쓰진 않는데 그냥 소개하는 정도인 거죠.
그리고 실제로 쓸 때 근데 그 구현을 할 때는 필요하니까 그냥 소개하는 정도인 거죠.
그래서 그렇게 디테일하게 다루기보다는 아 이런 게 있습니다 하고 그냥 고급 내용으로 있습니다 하고 설명해도 괜찮을 것 같아요.

참석자 2 53:57
그냥 파이덴틱은 수단일 뿐이고 풀콜린 툴 런타임

참석자 3 54:04
사실 사실 파이드 킥 없어도 독스트링 잘 쓰고 타이 핀트 잘 줬으면 잘 돌아가겠

참석자 1 54:09
잘 돌아가야죠.

참석자 3 54:12
그렇게 하라고 정하

참석자 1 54:13
그런데 이제 혹시 모를 거를 위해서 커버를 하려고 하는 거죠.
아무튼 그래서 이제 이런 경우에 이제 파이덴틱의 디스크립션 기능으로 툴한테 이 각 필드의 설명을 주고 심지어 저는 이번에 처음 알았는데 이런 식의 조건도 줘서 여기 이제 밸리데이션 베리피케이션도 할 수 있게 해놨더라고요.
뭐보다 크고 적다. 근데 이게 좀 너무 과하다. 그래서 이 부분 좀 덜어내야 될 것 같고 투콜 아까 설명드렸고 그래서 이제 투콜이 근데 툴콜이 그래서 이게 그래서 툴 코를 좀 이제 이제까지 앞에 설명한 걸 다 모아가지고 싸그리 모아서 이제 다음 챕터에 나오는 이제 바인딩부터 시작해가지고 이제 최종 최결집편이라고 보면 돼요.
여기 앞에 내용을 다 정리해 싸그리 모아가지고 그럼 실제로 어떻게 쓰냐 그래서 모델을 세팅한 다음에 이제 그 래퍼 함수로 콜 툴을 만들었으면 걔를 바인드라는 걸 해요.
그래서 이 바인드는 뭐냐 하면 모델한테 내가 쓸 수 있는 툴이 이거야라고 등록을 해 주는 거거든요.

참석자 1 55:20
그래서 실제로 쓸 땐 요거를 써요. 이거를 그러니까 모델을 선언한 다음에 바인드를 한 이 객체에다가 인보크를 때려요.
그러면 이 질문을 할 때마다 이 툴에 대한 정보가 같이 넘어가요.
그래서 LM이 이제 그러면 이걸 호출해라고 AI 메시지를 주면 그러면 그 AI 메시지를 보고 에이전트가 2로 호출을 해가지고 그 리턴을 한 걸 다시 그러니까 리턴을 한 걸 다시 이제 AI가 결과를 주는 이런 식으로 작동을 한다.

참석자 3 55:51
예전 예제에서는 그냥 인보크 할 때 툴 리스트를 쫙 줬던 것 같은데 다르네요.

참석자 1 55:59
그래서 이제 그거를 스텝 바이 스텝을 다 보여준 게 이 코드예요.
그래서 이제 뭐 스쿨 등록해서 바인딩 여기까지 똑같거든요.
근데 이제 이거를 이제 그 사람 아까 보스 넷이 뭐야라고 하면 이제 거기에 대해서 이렇게 주면은 이게 이제 그 결과가 여기에 딱 들어와요.
그러면 그거를 이제 툴 콜 부분을 보면 이렇게 생겼고

참석자 3 56:20
메시지 안에 다 들어 있네.

참석자 1 56:22
그래서 이제 그걸 포르폴 돌면서 이제 그러면 그걸 받아서 다시 또 인보크 웨더를 인보크를 해요.
여기다가 그러면 이제 툴 콜에 대해서 요 툴이 호출이 되면서 그 결과를 다시 이제 AI한테 주는 거예요.
이걸로 그래서 이 메시지를 넣어서 그래서 메시지를 이제 그 인보크 그 보면은 이제 이렇게 써 있고 그걸 최종 결과물을 이제 움버크를 하면 여기 요거 던질 때는 이제 이 메시지 안에는 이 보스 n이 뭐야 그런 다음에 AI가 툭 서 그다음에 툴의 결과 그게 다 들어 있어요.
과거 히스토리가 그럼 그걸 보고 AI가 이렇게 보스턴의 현재 날씨는 이렇게 요게 문장이 이제 딱 나오는 거죠.

참석자 3 57:03
요 앞에 잠깐 겟 웨더의 인보크를 하는 게

참석자 1 57:07
네 이 함수를 호출하는 거예요.

참석자 3 57:10
개도 이게 툴 저게 돼 있어서 그렇구나

참석자 1 57:14
이거 호출하는 게 그냥 그냥 하면 호출하는 거예요.
그러면 이제 그 결과가 이거에 맞춰서 딱 오는 거고 그거를 줘서 이제 그 2의 메시지가 나오는 거죠.
그러면 이제 2의 메시지는 AI한테 네가 시킨 2를 호출했더니 이 메시지를 받았어라고 주는 거고 그럼 그걸 가지고 이제 전체 맥락을 처음부터 끝까지 다 주는 거죠.
그러니까 할 때마다 AI한테 줄 때는 할 때마다 처음부터 다 주는 거예요.
그 처음 질문부터 시작해서 경위까지 어떤 툴을 니가 호출하라고 했고 그걸 호출했더니 결과가 뭐였고 이거 다 주는 거죠.
굉장히 비효율적이죠. 아무튼 그거를 설명을 이제 이걸 보고 할 수 있는 거고 근데 심지어 이제 이거 병렬로도 할 수 있다.
아까 얘기 나온 그래서 근데 내부적으로는 뭐 순차적이지만 보기에는 병렬적으로 보이겠죠.

참석자 1 58:02
근데 이게 병렬적으로 얘기한 이유는 제 생각에는 이제 이거를 두 번에 나눠서 하는 게 아니라 이게 얘 한 번만 딱 호출해 주면 알아서 이 안에서 두 번을 호출해 주는 네요.
그쵸 돌리니까 그

참석자 3 58:13
근데 이게 저 물어보고 나서 생각했던 게 요게 어시크 들어가 있으면 되는 거 아니에요

참석자 1 58:20
뭐 그렇죠 그렇게 싱크에도 똑같고 근데 근데 이걸로 해주니까 제 입장에서는 어차피

참석자 3 58:28
이거는 이제 제 말은 병렬이 아니라 그냥 퓨죠 그렇죠 그렇죠 그렇죠 그렇죠 그러니까 근데 이제 제 말은 어싱크로 걸면 그냥 누가 두 개 다 던져놓고

참석자 1 58:40
근데 그러면 그러려면 툴 자체도 또 어싱크로 구현이 돼 있어야 되잖아요.

참석자 3 58:44
물론 그렇긴 하죠. 근데 보통 툴은 이게 인디펜던트 하게 돼 있을 거 아니야 툴이 그전 툴 결과에 디펜던트 하게 돼 있지는 않을 거니

참석자 1 58:53
그러니까 그래서 스토리 자체를 어싱크로 구현을 어떻게 할지 잘 모르겠어요.

참석자 2 58:57
근데 저게 다 파이프라인 구성 아니에요

참석자 1 59:03
파이프랑 구항

참석자 2 59:04
오프라인 구성이면은 싱크로 해야 되는 거 아니에요

참석자 3 59:07
그러니까 그게 이제 순차적으로 파이프라인이라서 순차적으로 연관성이 있는 거면은 시스템이

참석자 1 59:14
연관성이 없어요.

참석자 3 59:15
의존성이 있어야지만 지금 개도에너는 그냥 하나하나가 독립적으로 돌아가잖아요.
그렇죠 그러니까 그냥 병렬로 따로 두 개 동시에 뛰어도 상관이 없다는 거죠.
그러니까 그거 써도 되는 거 아닌가 이렇게 말씀 그말도 맞긴 한 것 같은데 이제 그게 경우에 따라서 싱크가 왔다 갔다 하고 연관되기 때문에 싱크를 해야 되겠습니다.

참석자 1 59:35
그렇고 그리고 실습 과제가 있어요. 그래서 이제 이렇게 간단하게 한번 해보는 거지 그냥 돌려보는 거에 지나지 않아요.
앞에 있는 거 그리고 대화 기록 관리 이것도 이제 앞에 있던 코드 그냥 그대로거든요.
그래서 이제 시스템 메시지 휴먼 메시지 인보크 하면 나오는 거 그리고 툴 만드는 거 앞에 이제 파이덴틱으로 정의한 이 스키마를 주면서 이 간단하게 툴을 만드는 거고 그리고 이제 기본적인 팁 같은 거 뭐 이런 모델 설렉션하는 방법이나 템플렛을 설정하는 거라든가 그리고 시스템 메시지 설정하는 거 그리고 뭐 투 디버깅 하는 방법들 찍어보는 거죠.
뭐 다 프린트로 그리고 비용 최적화 질문에 따라서 비용 최적화하는 거 이런 거고요.
그런 다음에

참석자 3 1:00:21
지역 최적화를 어떻게

참석자 1 1:00:23
질문에 어려운 거나 어려운 거 쓰고 뭐 간단한 건

참석자 3 1:00:26
그냥 내가

참석자 1 1:00:28
근데 여기는 거 아니 저렴한 거랑 비싼 게 있고 그 선택에 맞춰서 보면 심플한 거는 저렴한 거 쓰고 그런 게 있고요.
여기는 또 보니까 또 맥스 토큰을 제안을 걸어 가지고 뭐 제안을 한다거나 그리고 오픈 AI나 이런 데는 재미나도 마찬가지인데 동일한 질문을 계속하면은 자동으로 캐싱을 해가지고 무슨 캐싱인데 그거 프롬프트 캐싱 프롬프트 캐싱 뭐 이런 거 아니었어요

참석자 3 1:00:55
어떻게 하지 그랬던 것 같아 이게 예전에는 인보크 할 때 동일 질문 물어보면은 답변 캐시된 걸로 바로

참석자 1 1:01:03
아니 그거 아니에요 그 얘기를 하는 게 아니라 동일한 시스템 프롬프트를 던져요.
이 시스템 프롬프트가 동일한 긴 프롬프트를 던진 상태에서 질문만 바뀌는 경우에 자동으로 그 시스템 프롬프트에 해당하는 부분에 대한 처리 결과를 옛날 거를 쓰게 돼 있대요.
그래서 그 부분에 돈을 적게 받아요. 그래서 지금 여기 말하는 지금 그 캐싱이거든요.
그래서 이게 그 캐싱이고 근데 이제 오픈 AI가 문제가 그게 자도 지들이 마음대로 해 그래서 저희 돈을 받아봐야 알 수 있는데 엔트로픽은 그게 명시적으로 캐싱이 돼 있다고 하네요.
저도 이번에 알았는데 그리고 배치에 배치를 쓰면은 이제 질문을 여러 개를 한 방에 던져가지고 이제 결과를 한 방에 받는 건데 이게 성능이 똑같이 나오는지는 해봐야 알 것 같아요.
왜냐면

참석자 3 1:01:51
그게 시스템 프롬프트만 한 번 쓰면 되는 거라서 그 할인되는 것밖에 없는 거 아니에요

참석자 1 1:01:58
그러니까 이 위에 거랑 다른 게 뭐냐면 얘는 시스템 프롬프트를 동일한 질문에 여러 번 반복했을 때 앞에 있는 시스템 프롬프트와 연속되는 질문들이 시스템 프로트가 동일하면 그거를 처리하는 비용을 안 받겠다는 거고 이 게는 시스템 프롬프트는 같은데 거기에 해당하는 질문 시스템 없다 상관도 없어요.
그냥 질문 자체가 여러 개가 동시에 한 방에 가는 거예요.
그냥 그래서 예를 들어 고객 정보가 a b c d e 있으면 이거를 하나씩 하나씩 순차적으로 하는 게 아니라 고객 정보를 이제 5개를 한 방에 이제 처리해 달라고 요청하는 거죠.
그러면 한 방에 리턴이 오는데 이게 성능이 똑같은지 모르겠어요.
이게 고민이긴 예전에 왜냐하면 이게 예를 들어 고객 정보가 10억 건이야 그러면 이거를 배치를 하게 되면은 5개로 하면 5배가 빨라지고 10개 하면 10개 빨라질 거 아니에요.
근데 과연 그게 근데 정말 성능이 똑같을까 하나하나 했을 때랑 뭐 그런 생각이 좀 들더라고요.

참석자 3 1:02:52
이게 원래는 원래는 우리 저기 컨텍스트 윈도우 이게 질문을 보내면은 답변 받는 거가 컨텍스트 사이즈에서 질문 답변용 콘텍스트 사이즈를 남겨놓고 질문을 보낸다 뭐 그런 내용이 있었던 것 같은데

참석자 1 1:03:11
아닌데 그냥 답변 답변이고 보내는 거 보내는 거고 왜냐하면 LM에 줄 때 과거 정보를 기반으로 다 주지 않거든요.

참석자 3 1:03:20
판수에서 질문 내용도 포함되지 않아

참석자 1 1:03:22
그게 설정에 따라 달라요. 설정할 수도 있고 안 할 수도 있어요.

참석자 2 1:03:28
근데 저게 한 번 콜 해갖고 50% 할인이 됐는지는 그거 어떻게 알아요?

참석자 1 1:03:33
이거는 어디 서 있겠죠? 거기

참석자 3 1:03:37
그래서 지금 할인된다는 얘기를 해서 생각해 보니까 원래 답변 받을 때 질문도 포함돼서 받을 텐데 질문을 생략해서 질문이 여러 개 한 번에 보내니까 질문을 생략해서 해준다는 얘기인 건가 뭐 이렇게 지금 생각한 건데 그렇군요.
뭔지 잘 모르겠네.

참석자 1 1:03:56
좀 더 운영을 효율적으로 할 수 있지 않을까요? 그러니까 GPU 안내물 전표 처리를 할 때 이게 한 번에 처리를 안 하고 일정 정도 응답이 쌓이면 처리하는 식으로 진행을 하잖아요.
우리 예전에 그럴 수도 있네요. 근데 배치를 던져

참석자 3 1:04:11
채워갖고 보낸다든가

참석자 1 1:04:15
그래서 그렇고 이제 코드 한번 돌려볼까요? 코드를 간단하게 보면은 코드가 기본적으로 근데 아까 보지 않았나 안 봤나 코드가 돌긴 해요.
그래서 볼게요. 에이

참석자 3 1:04:31
키가 있어요.

참석자 1 1:04:33
제가 환경 emv를 넣어놨고요. 저는 로컬에 쓰려고 그래서 이제 첫 번째 요 차트 챗 모델이니까 기본적인 챗 모델 쓰는 법을 설명하는데 이게 이제 예전에 우리가 예전에 했을 때는 챗 오픈 에이 이런 거 썼잖아요.
옛날에 이런 거 썼는데

참석자 3 1:04:51
클로바 이미이 아니네 이제

참석자 1 1:04:53
예 잠깐만요. 처음부터 볼게요. 그래서 보면은 이제 실행을 하면 이제 요게 요게 떠요.
첫 번째 거 첫 번째 거 뜨고 질문하면 응답 나오는 간단한 거고

참석자 3 1:05:07
잠깐 그러면 지금 유니챗 모델은 그냥 랭 체인에서 인폴트하고 유니챗에다가 GPT나 제밀이나 모델명만 쓰면 알아서 그 모델에 해당하는 API 가져다가 SDK 가져다가 쓰는 거예요.

참석자 1 1:05:25
무슨 말이에요?

참석자 3 1:05:26
이니챗 모델에다가 그냥 모델명을 쓰잖아요. 근데 여기에 GPT를 써도 GPT를 쓰면 알아서 GPT 거 모델

참석자 1 1:05:36
GPT를

참석자 3 1:05:38
쓰고 재민이라고 쓰면 재민이 거 가져다 쓰고 해서 아예 모두 선

참석자 1 1:05:43
환경 변수에 세팅이 돼 있어야 돼요.

참석자 3 1:05:45
그 키가

참석자 1 1:05:46
예 그래서 이런 식으로 저는 이렇게 넣어 놓으셔야 얘를 가지고 이제 로딩을 하면서 이제 다 mv에서 로딩을 하면서 여기 다 emv 있잖아요.
로딩을 하면서 가져와서 이제

참석자 3 1:06:03
그럼 지금 이제 인니체 모델 쓰면은 지금 위에 이제 냉체인 오픈 AI 이런 애들 따로 인포트할 필요가 없다는 거네요.

참석자 1 1:06:12
그렇죠 맞아요. 그냥 요거 하나

참석자 3 1:06:14
좋게 잘했네

참석자 1 1:06:16
그건 편하죠. 왜냐하면 요건

참석자 3 1:06:17
통합 인터페이스가

참석자 1 1:06:18
그러니까 이거 하나로 그냥 이거 따로따로 다 옛날에 따로따로 다 골랐는데 얘 하나로 다니까 편하긴 하죠.
모델만

참석자 3 1:06:26
좀 전에 종훈 님 해터 안 됐다고 재민이 거로 바꿨다고 한 것도 여기서는 모델명만 재민이 모델로

참석자 1 1:06:35
맞아요. 대신 다 emv에 들어가 있어야죠. 그래서 이제 두 번째 거 실행해 보면 이제 방금 말씀하신 두 번째 거 실행하면은 이제 이런 식으로 질문을 하면은 응답을 나오게 할 수 있고 그래서 이 모델 파라미터에 이렇게 이름이 찍혀 나와요.
어떤 모델을 썼는지가 이런 콘텐츠가 나오고 세 번째는 이제 템플로트 세팅하는 거 그래서 이제 여기에 질문을 하면 요 템플라우치가 0 1에 따라서 뭐 잘 모르겠어 똑같이 나가는 하하 이런 이걸 보면 좀 더 창의적이려나 창의적이긴 하

참석자 3 1:07:11
1.0이니까 완전 이제 새롭게 말을 해주고 0.0은 그냥 그러네요.
딱 엄근진하게 답하네요.

참석자 1 1:07:22
그리고 이제 네 번째는 스트리밍 기능이에요. 스트리밍을 이렇게 포르포르 돌면서 이렇게 청크를 가져다가 찍는 방금 보셨죠?
그리고 이제 프로바이더를 이제 이렇게 아까 송정훈 대표님이 말씀하신 이런 식으로 세팅하면 돼요.
이렇게 해서 이제 그 종류별로 세팅을 해가지고 나오는데 이게 왜 나오지 이상한데 안 나와야 되는데

참석자 3 1:07:48
책이 다 있어요.

참석자 1 1:07:49
안 나왔던 것 같은데 구글은 구글은 안 되는 줄 알았었는데 되네요.
또 전에는 안 됐던 것 같은데 하여튼 뭐 이런 식으로 세팅을 하면 된다라는 거고요.
두 번째는 이제 아이 두 번째는 이제 메시지죠. 메시지 쓰는 법인데 메시지 쓰는 법은 이제 기본적으로 이렇게 휴먼 시스템 메시지 휴먼 메시지 AI 메시지를 이런 식으로 이렇게 만들어 가지고 타입하고 콘텐츠를 찍어볼 수 있어요.
그래서 안에 이런 에츠리뷰2를 접근 가능하고 그다음에 실제로 대화를 한번 만들어 보면은 여기는 이걸 썼네요.
그래서 모델을 가지고 히스타하고 시 메시지를 구해서 찍어보면은 이렇게 되는데 이 두 개를 그런 다음에 LLM을 호출한 다음에 리스폰스를 찍어보면 이렇게 응답이 나오고 타입을 보면은 뭐 응답 타입이 AI 메시지라고 뜨죠.
그리고 이제 롤이 AI 이런 식으로 이제 안에 있는 걸 확인하면서 할 수 있다.

참석자 1 1:09:03
그리고 아까 나온 딕셔널이랑 그 객체 메시지 객체 쓰는 거는 이렇게 메시지 객체를 하나 딕셔널이를 하나 그리고 이제 유사하게 나오죠.
근데 이제 이렇게 찍어서 내용을 본 거예요. 그래서 응답이 이렇게 나오죠.
응답이 살짝 다를 수밖에 없죠. 왜냐면은 이게 기반이 확률 기반이기 때문에 그리고 메시지 메타 데이터 속성을 보는 것도 요건 이제 메시지에 대한 메타 데이터가 쭉 나오는 거고 그리고 멀티턴 대화 멀티턴 대화는 이제 결국 말이 멀티턴이지 대화를 할 때마다 그거를 다 에이디 어펜드해서 과거 모든 기록을 다 던지는 거죠.
그거를 이제 보여주는 것뿐이에요. 그래서 이제 대화를 쭉 했던 거를 이거 찍는 거는 최신 대화만 찍지만 실제로 던질 때는 왜냐하면 최신 대화고 마이너스 1로 인덱싱해서 맨 마지막 걸 보여주지만 던질 때는 모든 걸 던진다.
그리고 이제 그거고 투 베이직은 너무 많네. 그냥 쭉 그냥 빠르게 볼게요.
그래서 호출 실행되는 것만 보고 빠르게 넘어갈게요.

참석자 1 1:10:15
툴은 이렇게 툴에 대한 데코레이터 설명이 있고 그런 다음에 이제 뭐 연도를 받아서 뭐 이렇게 태어난 연도를 받으면 나이 계산한다 라는 툴이 있고 파라미터가 있는 그래서 이제 한번 실행을 해보면은 잠깐만 실행은 어디서 해 그래서 이걸 실행한 거죠.
이거는 이제 도구를 이렇게 실행한 거고 두 번째는 이제 파라미터가 있는 툴 이거를 이제 호출하는 코드는 맨 밑에 있어요.
그래서 이제 이렇게 유해를 호출해 보는 거고 인보크로 호출한 거고요.
그래서 보면은 이제 도구 설명이라든가 이런 것들이 넘어가요.
도구 이름이라든가 그러니까 이 데코레이팅을 하게 되면 AI한테 이제 도구 이름 설명 이런 것들이 넘어간다는 걸 찍어서 보여드리는 거고요.
그리고 세 번째는 그 날씨 정보로 주는 이 API를 그 툴을 만들어서 질문을 하면은 거기에 맞춰서 호출되는 거 보여드리는 거고 그리고 여러 페라미터 여러 개 보시면 이제 툴에 이제 파라미터가 여러 개 있죠.

참석자 1 1:11:23
쿼리라든가 맥스 리조트 이렇게 이거에 맞춰서 호출을 하면 호출할 수도 있다 뭐 이런 사실 이게 에러 핸들링 같은 경우에는 여기 에러가 나거든요.
에러를 나게 이렇게 그래서 그걸 제가 봤을 때 이게 의미가 있는지 모르겠어요.
그냥 후추만 하거든요. 툴을 만들어서 의미가 있는지 잘 모르겠어요.
툴 어드벤스는 툴 어드벤스도 그냥 쭉 보기만 할게요.
이게 그 파이드앤틱이 여기 나오거든요. 파이드앤틱 해서 요 하는 거 그런데 실행은 한번 해봐야지 실행은 한번 잘 되나 실행 한번 해볼게요.
아이고 다시 왔네. 그래서 아무튼 이런 식으로 파이덴틱 나오고 여기 파이드앤틱

참석자 2 1:12:07
질문 있는데 2는 기본적으로 저 내부 함수 그냥 지정해서 내가 필요한 거 함수화해놓는 딱 그냥 그렇게만 생각하면 돼.

참석자 1 1:12:18
그렇죠. 그럼 파이썬 함수를 그냥 AI가 쓰기 편하게 이게 일종의 메타 데이터거든요.
AI가 볼 수 있는 메타 데이터를 이렇게 적용해서 만든 거다 이렇게 생각하시면 돼요.
그래서 이제 이 경우에 이제 에러가 나게 만드는 게 있는데 이렇게 지금 예제 2번에 요거 보면 나이가 반드시 0에서 100보다 크고 150보다 작게 만들어야 되는데 이 질문을 할 때 이 나이를 일부러 일부러 음수로 넣어준 경우거든요.
그러면 이제 보시는 것처럼 오류가 발생했다고 밸리데이션이 에러가 떠요.
그래서 이 파이덴틱이 이 역할을 한다 라는 거고 그다음에 이제 옵셔널인데 옵셔널은 뭐냐면 요거 함수를 만들 때 이게 지금 요게 요 함수의 그 아규먼트에 대한 설명인데 여기에 저런 게 있어요.
이렇게 조건을 이렇게 줄 수도 있고 그리고 초기 값을 초기 값을 줄 수 있거든요.
어디 있냐면 왜 그게 없지 한국하고 뭐

참석자 3 1:13:33
디폴트가 쪼개 값 아니야 디폴트

참석자 1 1:13:38
잠깐만 이게 지금 3번이 너무 많아 그리고 이게 내용이 너무 많아요.
이게 옵션을 이 옵션 필수 디스크립션 옵션 옵션 포이스 아무튼 뭐 옵션을 주는데 아무튼 이게 파라미터 줘서 검색을 하면은 이렇게 쓰면 얘가 나오고 얘가 나오고 이렇게 나온다.
그래서 이게 지금 보면은 여기가 지금 옵셔널이로 돼 있잖아요.
얘를 줘도 되고 안 줘도 되는 거예요. 근데 쿼리 같은 건 반드시 줘야 되거든요.
그래서 허리 이런 건 반드시 줘야 되고 여기 호출할 때 그때 또 쿼리 같은 건 반드시 줘야 되고 그리고 요런 요런 옵셔널 같은 거는 줘도 되고 안 줘도 되고 이런 거를 이렇게 파이덴틱에서 쓴다라는 걸 보여드리는 거고 이유 이넘이라든가 뭐 리트 이런 것도 되고 너무 길게 넘어갈게요.
그리고 중첩된 파일에 이것도 넘어갈게요. 이건 너무

참석자 3 1:14:47
앞에보다 더 많은 설명보다 더 많은데 예제가

참석자 1 1:14:50
좀 줄여야 될 것 같아요. 그리고 이제 툴 콜은 이제 이게 마지막이야 길다 투코 이게 마지막인데 이제 여기 지금 웨더가 있고 이렇게 여러 개의 툴을 만든 상태에서 AI한테 가지고 있는 툴들을 바인딩을 시켜준 다음에 질문을 하면 거기에 맞는 툴이 호출된다라는 걸 보여주는 게 요 예제예요.
에이전트가 이런 기능이 있어야겠죠 당연히 있어야겠죠.
근데 그 설명을 여기서 해야 되는지 잘 모르겠어. 아무튼 뭐 이런 식으로 맞게 한다.
그래서 툴 코를 이렇게 질문들이 있으면 거기에 맞춰서 얘가 이제 알아서 이렇게 호출을 하는데 여기에 오류가 나면 오류 나는 것도 검증을 해준다.
이게 잠깐만 예제가 틀렸네. 내가 뭘 실행한 거지

참석자 3 1:15:50
지금 API로 이렇게 쓰는 게 이미 저쪽에서 만들어 놓은 툴이 있어서 걔가 알아서 만들어 놓은 툴을 가져다 쓰고 그러지

참석자 1 1:16:02
그게 시스템 쪽에 요새 툴이 또 있다고 요새 생겼어.
예를 들어 뭐 검색하는 툴 이런 것들이 요새 속속 생기고 있거든요.
그걸 호출하는 방법도 있는데 아직 여기에서는 커버가 안 돼 있어요.
그게 그래서 뭐 이런 식으로 툴 코를 이제 상세적으로 찍어보면은 이제 지문에 맞춰서 어떤 툴이 호출됐는지 그래서 이 날씨 알려주는 질문을 하면 웨더 툴이 호출되고 계산하는 걸 하면 툭 계산하는 툴이 호출되는 걸 보실 수가 있죠.
그리고 이제 투코 실행하기 머랭 체인이 뭐야 그러면 이제 해당하는 어떤 도구 웹 서칭 나오면서 인재가 나와서 거기에 대한 도구를 선택했다라는 걸 보여주는 예제예요.
그리고 그러니까 앞에서 다이어그램이 이제 여기 시대 구현이 되죠.
그래서 이제 한 번에 이제 부산과 날씨 알려주고 두 번째 평균 원칙 계산 이러면 이제 이때 이제 보시면 이제 그 지문에 맞춰서 나오죠.

참석자 1 1:17:00
그러면서 이제 서울 우선 서울 날씨 어때 여기서 서울 날씨 어때 그러면 하나만 나오는데 여러 도구 동시에 호출하면 이제 토하고 부산 날씨를 알려주고 이렇게 이렇게 하면 토 도구가 이제 두 개가 호출되면서 이제 각각의 다른 파라미터가 넘어가면서 결과가 나온다 하는 거고 그리고 에러 핸들링은 이제 툴 콜을 하는데 여기 내에서 이제 에러가 0으로 나누는 이런 게 나오면은 이런 식으로 라이즈를 해가지고 그래서 이렇게 에러가 나오는 거를 이렇게 나오고 이제 LLM이 그걸 받아가지고 만들어줘요.
그러니까 에러 메시지를 보고 보고 LNM이 이제 만들어주는 거죠.
이렇게 해서 끝났어요. 여기서 전체적으로 설명을 다 드렸고 이게 생각보다 너무 기네.
그래서 이거를 일단은 한 지금의 한 3분의 2 정도 이하로 좀 줄였으면 좋겠다라는 거고 어떻게 줄일지에 대해서는 앞에 말씀을 드렸어요.
그래서 각 파트별로 좀 내용을 좀 축약해서 정리해서 다시 공유를 드릴게요.
네 끝입니다. 길었다.

참석자 2 1:18:09
지금 단순 따라하기로는 처음에 설치하고 초반까지는 단순 따라하기로 의미가 있는 것 같은데 뒤로 갈수록 이제 컨셉에 대한 거랑 뭔가 이걸 왜 쓰는지 뭐 이런 게 없으면 왜 하는지를 의미를 모를 것 같아서 좀 컨셉들이 좀 들어가 주면 좋을 것 같다는 생각이 드네요.

참석자 1 1:18:34
그 컨셉은 사실 여기 앞에 있긴 하거든요. 이게

참석자 2 1:18:38
그것만 갖고는 딱히 보이지가 않아서

참석자 1 1:18:40
그러니까 이거가 그거죠. 사실은 왜냐하면 이거 왜 배워야 돼 그러면 AI 에이전트에 어떻게 돌아가는지를 알기 위해서 배우는 건 이 부분이고 챕터 2 3 4 5 6에서 이제 그거를 할 때마다 주지시킨다는 게 사실은 왜냐하면 안 그래도 양이 많은데

참석자 2 1:18:57
예를 들어서 아까 좀 찾아봤는데 툴 콜링이랑 툴 런타임이랑 차이가 뭐냐 그리고 이건 MCP랑 또 뭐가 어떻게 다른 거냐 뭐 이런 측면의 다이어그램이라든가 그런 것만 좀 있으셔도 어디에다가 어떻게 쓰는 물건인가라는 관점에서 좀 좀 더 에스트렉트 된 버전이 뭔가 그런 게 있었으면 사실

참석자 1 1:19:24
사실 툴 콜링은 그러니까 툴 런 타임은 사실 별게 아니라 그냥 툴 내부에서 에이전트가 돌아가는 거를 알 수 있게 해주는 어떤 건데 거기에 대한 다이어그램은 오피셜 문서에도 없거든요.

참석자 2 1:19:40
그러니까 찾아보니까 툴 콜링이랑 툴 런 타임은 차이가 뭐야 해서 찾아보니까 결국에는 스테이트 리스랑 스테이트 풀 이런 관점도 있더라고요.
그래서

참석자 1 1:19:52
툴 컬링은 스테이스 리스고 툴 런 타임은 스테이트 풀 스테이트 풀이기는 한데 툴 내에서 어떤 에이전트에 쓰는 거긴 한데 쓰는 거죠.
하여튼 뭔가 좀 깔끔한 다이어그램이 있으면 저기 리뷰 페이지에 좀 넣어주세요.
여기 여기 여기 여기다가

참석자 2 1:20:17
이거 비교 테이블이라도

참석자 1 1:20:19
아무튼 여기다가 좀 넣어주세요. 이렇게 여기다가 여기다가 내용 그럼 이제 그걸 반영해서 그래서 다음 주에는 다음 주에도 두 분이잖아요.
근데 두 분인데 여기다 좀 채워주세요. 여기다가 이렇게 여기다가 그러니까 이렇게 하셔도 돼요.
이거를 읽으면서 생각나는 걸 녹음을 하세요. 그런 다음에 그거를 그냥 텍스트로 전사를 시켜서 이 형식에 맞춰줘라고 AI 하면은 그냥 해주거든요.

참석자 3 1:20:50
녹음을 해서 오디오 파일을 노트북 LM에 넣으면 안 들어주지 않나요?

참석자 1 1:20:57
이거를 준 다음에 만들어 달라고 하면 만들어 주죠.
그러니까 노드

참석자 3 1:21:01
영상 링크 했던 것처럼 오디오도 올릴 수 있어

참석자 1 1:21:03
오디오는 못 올리는 거

참석자 3 1:21:05
그럼 유튜브로 올린 다음에 유튜브 링크를 줘야 되겠네.

참석자 1 1:21:08
근데 이제 요새 무료로 네이버 그런 거 노트나 그런 거 거기다 던지면 그냥 해줘요.
하여튼 뭐 이렇게까지 그러니까 내용을 정리했고요.
오늘 얘기 나온 거를 좀 제가 지금 녹음하고 있거든요.
그래서 좀 정리해 가지고 어떻게 날지 어느 부분을 어떻게 정리할지를 좀 다시 공유를 드릴게요.
그래서 그거를 이제 앞으로 워크 플로우가 어떻게 되냐면 이제 방금 얘기한 거랑 이거를 여기다 정리할 거고 그걸 기반으로 그걸 어떤 식으로 수정할지에 대한 최종 결과가 여기에 나와요.
그래서 그걸 이제 요구 사항이 나오면 그걸 기반으로 AI한테 이걸 기반으로 지금 걸 수정해라고 할 거거든요.
그러니까 그거를 컨펌을 해 주시면 되겠습니다.

참석자 2 1:21:58
혹시 그 자료 좀 찾아보니까는 테리 노트 쪽 보니까 랭체인 KR이라는 소스가 있던데

참석자 1 1:22:06
그게 옛날 버전의 한글 버전 아니에요

참석자 3 1:22:09
그게 1.0 나오기 전이에요. 작년 재작년에 만든 거라

참석자 1 1:22:13
예전 거야

참석자 3 1:22:15
작년 2월에 릴리즈 한 거거든요. 이게

참석자 1 1:22:17
2.0이 아니에요. 그게

참석자 3 1:22:19
그리고 우성 님하고 저하고 그렇게 참여되 있었었고 KR을 영어로 번역한 이게 KR이 더 옛날이고 KR 다음 이게 위키 덕스 기준인가요?
아마 그래서 이거 갖고 영문 튜토리얼 랭체인 튜토리얼을 만들어갖고 랭체인 튜토리얼을 영어로 번역한 KR을 영어로 번역하면서 내용 업데이트했는데 그게 1.0선이고 그러고 나서 지금 1.0 이후에 또 업데이트된 내용들을 한 걸 자동으로 AI로 번역시켜갖고 복수로 만들어 놓긴 했던데 지금 이제 미스터리에서 그걸 다시 아예 하는 거죠.
리뷰를 하는 거죠. 거기는 자동 번역이었고

참석자 2 1:23:03
네

참석자 1 1:23:05
사실 근데 여기가 내용이 이것도 만

참석자 3 1:23:09
그러면 한 설명은 3분의 1도 안 되고 대부분 코드 그냥 갖고 와서 코드 설명이라서

참석자 2 1:23:17
그럼 딱 와닿지가 않겠네요.

참석자 3 1:23:20
그런 내용을 알면 그럴 수도 있는데 그리고 이건 지금 레그 베이스라서 에이전트는 뒤에 조금밖에 없어요.
레그 주로 레그 내용이어 갖고

참석자 1 1:23:36
그렇습니다. 하여튼 생각보다 길었는데 목표는 한 30분 안에 끝내는 건데 거의 하여튼 하여튼 그래서 이거를 좀 오늘 오늘 제가 좀 시간을 좀 내주시면 여기다가 좀 채워주시면 지금이라도 생각나는 거라든가 링크라든가 좀 채워주시면은 그걸 반영을 해가지고 이거를 만들고 그걸로 이거를 만들어서 AI한테 수정을 시킬 거예요.
그래서 그런 다음에 그거 최종본을 컨펌을 요청을 드릴게요.
읽어 보시고 오케이 하면 다음 넘어가는 걸로 됐을까요?

참석자 2 1:24:15
네

참석자 1 1:24:16
하여튼 장시간 고생하셨고요. 다음 주는 좀 더 더 빠르게 할 수 있게 고민을 좀 해볼게요.
너무 오래 걸린다. 이거 진도 빠지고 네 하여튼 오늘 올 장시간 함께해 주셔서 감사하고 오늘 즐거운 주말 보내시고 다음에 뵙겠습니다.
네

참석자 3 1:24:33
이번 주말 되세요

참석자 1 1:24:35
고 네 다음 주에 봬요.

참석자 2 1:24:37
좋은 하루 되세요.


clovanote.naver.com